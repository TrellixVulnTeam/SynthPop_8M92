{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.9\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Users\\glede\\anaconda3\\envs\\py37\\lib\\site-packages\\tensorpack\\callbacks\\hooks.py:17: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Users\\glede\\anaconda3\\envs\\py37\\lib\\site-packages\\tensorpack\\tfutils\\optimizer.py:18: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Users\\glede\\anaconda3\\envs\\py37\\lib\\site-packages\\tensorpack\\tfutils\\sesscreate.py:20: The name tf.train.SessionCreator is deprecated. Please use tf.compat.v1.train.SessionCreator instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from modules.datgan import DATWGAN\n",
    "\n",
    "import networkx as nx\n",
    "import json\n",
    "import beepy\n",
    "\n",
    "# For the Python notebook\n",
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'LPMC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/{}/data.csv'.format(dataset), index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>travel_mode</th>\n",
       "      <th>purpose</th>\n",
       "      <th>fueltype</th>\n",
       "      <th>faretype</th>\n",
       "      <th>bus_scale</th>\n",
       "      <th>survey_year</th>\n",
       "      <th>travel_year</th>\n",
       "      <th>travel_month</th>\n",
       "      <th>travel_date</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>dur_pt_access</th>\n",
       "      <th>dur_pt_rail</th>\n",
       "      <th>dur_pt_bus</th>\n",
       "      <th>dur_pt_int</th>\n",
       "      <th>pt_n_interchanges</th>\n",
       "      <th>dur_driving</th>\n",
       "      <th>cost_transit</th>\n",
       "      <th>cost_driving_fuel</th>\n",
       "      <th>cost_driving_con_charge</th>\n",
       "      <th>driving_traffic_percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>drive</td>\n",
       "      <td>HBO</td>\n",
       "      <td>Petrol_Car</td>\n",
       "      <td>child</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.134444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.052222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.111702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>drive</td>\n",
       "      <td>HBO</td>\n",
       "      <td>Petrol_Car</td>\n",
       "      <td>free</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.241389</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.122222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.132222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.065126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>drive</td>\n",
       "      <td>HBO</td>\n",
       "      <td>Petrol_Car</td>\n",
       "      <td>full</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.257500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.873889</td>\n",
       "      <td>0.089444</td>\n",
       "      <td>1</td>\n",
       "      <td>0.508333</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.356831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pt</td>\n",
       "      <td>HBW</td>\n",
       "      <td>Average_Car</td>\n",
       "      <td>full</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.123889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.208056</td>\n",
       "      <td>0.091667</td>\n",
       "      <td>1</td>\n",
       "      <td>0.115556</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pt</td>\n",
       "      <td>HBO</td>\n",
       "      <td>Average_Car</td>\n",
       "      <td>free</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.171389</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.334444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.196389</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.035361</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  travel_mode purpose     fueltype faretype  bus_scale  survey_year  \\\n",
       "0       drive     HBO   Petrol_Car    child        0.0            1   \n",
       "1       drive     HBO   Petrol_Car     free        0.0            1   \n",
       "2       drive     HBO   Petrol_Car     full        1.0            1   \n",
       "3          pt     HBW  Average_Car     full        1.0            1   \n",
       "4          pt     HBO  Average_Car     free        0.0            1   \n",
       "\n",
       "   travel_year  travel_month  travel_date  day_of_week  ...  dur_pt_access  \\\n",
       "0         2012             4            1            7  ...       0.134444   \n",
       "1         2012             4            1            7  ...       0.241389   \n",
       "2         2012             4            1            7  ...       0.257500   \n",
       "3         2012             4            1            7  ...       0.123889   \n",
       "4         2012             4            1            7  ...       0.171389   \n",
       "\n",
       "   dur_pt_rail  dur_pt_bus  dur_pt_int  pt_n_interchanges  dur_driving  \\\n",
       "0          0.0    0.016667    0.000000                  0     0.052222   \n",
       "1          0.0    0.122222    0.000000                  0     0.132222   \n",
       "2          0.0    0.873889    0.089444                  1     0.508333   \n",
       "3          0.0    0.208056    0.091667                  1     0.115556   \n",
       "4          0.0    0.334444    0.000000                  0     0.196389   \n",
       "\n",
       "   cost_transit  cost_driving_fuel  cost_driving_con_charge  \\\n",
       "0           0.0               0.14                      0.0   \n",
       "1           0.0               0.50                      0.0   \n",
       "2           3.0               1.59                      0.0   \n",
       "3           3.0               0.33                      0.0   \n",
       "4           0.0               0.53                      0.0   \n",
       "\n",
       "   driving_traffic_percent  \n",
       "0                 0.111702  \n",
       "1                 0.065126  \n",
       "2                 0.356831  \n",
       "3                 0.033654  \n",
       "4                 0.035361  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset is 'Chicago':\n",
    "    continuous_columns = [\"distance\", \"age\", \"departure_time\"]\n",
    "elif dataset is 'LPMC':\n",
    "    continuous_columns = ['start_time_linear', 'age', 'distance', 'dur_walking', 'dur_cycling', 'dur_pt_access', 'dur_pt_rail', 'dur_pt_bus', 'dur_pt_int', 'dur_driving', 'cost_transit', 'cost_driving_fuel', 'driving_traffic_percent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# personalised graph\n",
    "graph = nx.DiGraph()\n",
    "\n",
    "if dataset is 'Chicago':\n",
    "    graph.add_edges_from([\n",
    "        (\"age\", \"license\"),\n",
    "        (\"age\", \"education_level\"),\n",
    "        (\"gender\", \"work_status\"),\n",
    "        (\"education_level\", \"work_status\"),\n",
    "        (\"education_level\", \"hh_income\"),\n",
    "        (\"work_status\", \"hh_income\"),\n",
    "        (\"hh_income\", \"hh_descr\"),\n",
    "        (\"hh_income\", \"hh_size\"),\n",
    "        (\"hh_size\", \"hh_vehicles\"),\n",
    "        (\"hh_size\", \"hh_bikes\"),\n",
    "        (\"work_status\", \"trip_purpose\"),\n",
    "        (\"trip_purpose\", \"departure_time\"),\n",
    "        (\"trip_purpose\", \"distance\"),\n",
    "        (\"travel_dow\", \"choice\"),\n",
    "        (\"distance\", \"choice\"),\n",
    "        (\"departure_time\", \"choice\"),\n",
    "        (\"hh_vehicles\", \"choice\"),\n",
    "        (\"hh_bikes\", \"choice\"),\n",
    "        (\"license\", \"choice\"),\n",
    "        # Non necessary links\n",
    "        (\"education_level\", \"hh_size\"),\n",
    "        (\"work_status\", \"hh_descr\"),\n",
    "        (\"work_status\", \"hh_size\"),\n",
    "        (\"hh_income\", \"hh_bikes\"),\n",
    "        (\"hh_income\", \"hh_vehicles\"),\n",
    "        (\"trip_purpose\", \"choice\")\n",
    "    ])\n",
    "elif dataset is 'LPMC':\n",
    "    graph.add_edges_from([\n",
    "        (\"travel_year\", \"survey_year\"),\n",
    "        (\"travel_date\", \"day_of_week\"),\n",
    "        (\"day_of_week\", \"purpose\"),\n",
    "        (\"purpose\", \"start_time_linear\"),\n",
    "        (\"purpose\", \"cost_driving_con_charge\"),\n",
    "        (\"purpose\", \"distance\"),\n",
    "        (\"day_of_week\", \"driving_traffic_percent\"),\n",
    "        (\"day_of_week\", \"cost_driving_con_charge\"),\n",
    "        (\"start_time_linear\", \"driving_traffic_percent\"),\n",
    "        (\"start_time_linear\", \"cost_driving_con_charge\"),\n",
    "        (\"driving_traffic_percent\", \"cost_driving_con_charge\"),\n",
    "        (\"female\", \"driving_license\"),\n",
    "        (\"age\", \"bus_scale\"),\n",
    "        (\"age\", \"car_ownership\"),\n",
    "        (\"age\", \"driving_license\"),\n",
    "        (\"age\", \"faretype\"),\n",
    "        (\"driving_license\", \"car_ownership\"),\n",
    "        (\"car_ownership\", \"fueltype\"),\n",
    "        (\"fueltype\", \"cost_driving_con_charge\"),\n",
    "        (\"fueltype\", \"cost_driving_fuel\"),\n",
    "        (\"distance\", \"cost_driving_fuel\"),\n",
    "        (\"distance\", \"dur_driving\"),\n",
    "        (\"distance\", \"dur_walking\"),\n",
    "        (\"distance\", \"dur_cycling\"),\n",
    "        (\"distance\", \"dur_pt_access\"),\n",
    "        (\"distance\", \"dur_pt_rail\"),\n",
    "        (\"distance\", \"dur_pt_bus\"),\n",
    "        (\"distance\", \"dur_pt_int\"),\n",
    "        (\"dur_pt_bus\", \"cost_transit\"),\n",
    "        (\"dur_pt_rail\", \"cost_transit\"),\n",
    "        (\"pt_n_interchanges\", \"dur_pt_int\"),\n",
    "        (\"pt_n_interchanges\", \"cost_transit\"),\n",
    "        (\"faretype\", \"cost_transit\"),\n",
    "        (\"bus_scale\", \"cost_transit\"),\n",
    "        (\"car_ownership\", \"travel_mode\"),\n",
    "        (\"age\", \"travel_mode\"),\n",
    "        (\"cost_driving_con_charge\", \"travel_mode\"),\n",
    "        (\"driving_traffic_percent\", \"travel_mode\"),\n",
    "        (\"female\", \"travel_mode\"),\n",
    "        (\"purpose\", \"travel_mode\"),\n",
    "        (\"cost_transit\", \"travel_mode\"),\n",
    "        (\"cost_driving_fuel\", \"travel_mode\"),\n",
    "        (\"dur_driving\", \"travel_mode\"),\n",
    "        (\"dur_walking\", \"travel_mode\"),\n",
    "        (\"dur_cycling\", \"travel_mode\"),\n",
    "        (\"dur_pt_access\", \"travel_mode\"),\n",
    "        (\"dur_pt_rail\", \"travel_mode\"),\n",
    "        (\"dur_pt_bus\", \"travel_mode\"),\n",
    "        (\"dur_pt_int\", \"travel_mode\")\n",
    "    ])\n",
    "    graph.add_node(\"travel_month\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = '../output/' + dataset + '/TEST1/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "datgan = DATWGAN(continuous_columns, max_epoch=1000, batch_size=500, output=output_folder, gpu=0, learning_rate=2e-4)#, noisy_training='OR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1119 20:45:26 @DATSGAN.py:169]\u001b[0m Preprocessing the data!\n",
      "\u001b[32m[1119 20:45:26 @data.py:391]\u001b[0m Encoding categorical variable \"travel_year\"...\n",
      "\u001b[32m[1119 20:45:26 @data.py:391]\u001b[0m Encoding categorical variable \"travel_date\"...\n",
      "\u001b[32m[1119 20:45:26 @data.py:391]\u001b[0m Encoding categorical variable \"female\"...\n",
      "\u001b[32m[1119 20:45:26 @data.py:378]\u001b[0m Encoding continuous variable \"age\"...\n",
      "\u001b[32m[1119 20:45:26 @data.py:240]\u001b[0m   Fitting model with 10 components\n",
      "\u001b[32m[1119 20:45:36 @data.py:267]\u001b[0m   Predictions were done on 8 components => Fit with 8 components!\n",
      "\u001b[32m[1119 20:45:44 @data.py:267]\u001b[0m   Predictions were done on 6 components => Fit with 6 components!\n",
      "\u001b[32m[1119 20:45:51 @data.py:272]\u001b[0m   Predictions were done on 6 components => FINISHED!\n",
      "\u001b[32m[1119 20:45:51 @data.py:275]\u001b[0m   Train VGM with full data\n",
      "\u001b[32m[1119 20:46:04 @data.py:391]\u001b[0m Encoding categorical variable \"pt_n_interchanges\"...\n",
      "\u001b[32m[1119 20:46:04 @data.py:391]\u001b[0m Encoding categorical variable \"travel_month\"...\n",
      "\u001b[32m[1119 20:46:04 @data.py:391]\u001b[0m Encoding categorical variable \"survey_year\"...\n",
      "\u001b[32m[1119 20:46:04 @data.py:391]\u001b[0m Encoding categorical variable \"day_of_week\"...\n",
      "\u001b[32m[1119 20:46:04 @data.py:391]\u001b[0m Encoding categorical variable \"driving_license\"...\n",
      "\u001b[32m[1119 20:46:04 @data.py:391]\u001b[0m Encoding categorical variable \"bus_scale\"...\n",
      "\u001b[32m[1119 20:46:04 @data.py:391]\u001b[0m Encoding categorical variable \"faretype\"...\n",
      "\u001b[32m[1119 20:46:04 @data.py:391]\u001b[0m Encoding categorical variable \"purpose\"...\n",
      "\u001b[32m[1119 20:46:04 @data.py:391]\u001b[0m Encoding categorical variable \"car_ownership\"...\n",
      "\u001b[32m[1119 20:46:04 @data.py:378]\u001b[0m Encoding continuous variable \"start_time_linear\"...\n",
      "\u001b[32m[1119 20:46:04 @data.py:240]\u001b[0m   Fitting model with 10 components\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-2074cc1cca3e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatgan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\EPFL\\PhD\\SynthPop\\code\\modules\\datgan\\DATSGAN.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, data, dag)\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPreprocessor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontinuous_columns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontinuous_columns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns_order\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvar_order\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 172\u001b[1;33m             \u001b[0mtransformed_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m             \u001b[1;31m# Save the preprocessor and the data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\EPFL\\PhD\\SynthPop\\code\\modules\\datgan\\data.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, data, fitting)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    380\u001b[0m                 \u001b[0mcolumn_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 381\u001b[1;33m                 \u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_modes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontinous_transformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumn_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    382\u001b[0m                 \u001b[0mtransformed_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\EPFL\\PhD\\SynthPop\\code\\modules\\datgan\\data.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    254\u001b[0m             \u001b[0msamples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 256\u001b[1;33m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m             \u001b[1;31m# Check that BGM is using all the classes!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\glede\\anaconda3\\envs\\py37\\lib\\site-packages\\sklearn\\mixture\\_base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    191\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m         \"\"\"\n\u001b[1;32m--> 193\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\glede\\anaconda3\\envs\\py37\\lib\\site-packages\\sklearn\\mixture\\_base.py\u001b[0m in \u001b[0;36mfit_predict\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    243\u001b[0m                 \u001b[0mprev_lower_bound\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlower_bound\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 245\u001b[1;33m                 \u001b[0mlog_prob_norm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_resp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_e_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    246\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_m_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_resp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m                 lower_bound = self._compute_lower_bound(\n",
      "\u001b[1;32mD:\\Users\\glede\\anaconda3\\envs\\py37\\lib\\site-packages\\sklearn\\mixture\\_base.py\u001b[0m in \u001b[0;36m_e_step\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    296\u001b[0m             \u001b[0mthe\u001b[0m \u001b[0mpoint\u001b[0m \u001b[0mof\u001b[0m \u001b[0meach\u001b[0m \u001b[0msample\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m         \"\"\"\n\u001b[1;32m--> 298\u001b[1;33m         \u001b[0mlog_prob_norm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_resp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_estimate_log_prob_resp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    299\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_prob_norm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_resp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    300\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\glede\\anaconda3\\envs\\py37\\lib\\site-packages\\sklearn\\mixture\\_base.py\u001b[0m in \u001b[0;36m_estimate_log_prob_resp\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    501\u001b[0m             \u001b[0mlogarithm\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mresponsibilities\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    502\u001b[0m         \"\"\"\n\u001b[1;32m--> 503\u001b[1;33m         \u001b[0mweighted_log_prob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_estimate_weighted_log_prob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    504\u001b[0m         \u001b[0mlog_prob_norm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogsumexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweighted_log_prob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    505\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ignore'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\glede\\anaconda3\\envs\\py37\\lib\\site-packages\\sklearn\\mixture\\_base.py\u001b[0m in \u001b[0;36m_estimate_weighted_log_prob\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    454\u001b[0m         \u001b[0mweighted_log_prob\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_component\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    455\u001b[0m         \"\"\"\n\u001b[1;32m--> 456\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_estimate_log_prob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_estimate_log_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    457\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    458\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\glede\\anaconda3\\envs\\py37\\lib\\site-packages\\sklearn\\mixture\\_bayesian_mixture.py\u001b[0m in \u001b[0;36m_estimate_log_prob\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    699\u001b[0m         \u001b[1;31m# the precision matrix is normalized\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    700\u001b[0m         log_gauss = (_estimate_log_gaussian_prob(\n\u001b[1;32m--> 701\u001b[1;33m             X, self.means_, self.precisions_cholesky_, self.covariance_type) -\n\u001b[0m\u001b[0;32m    702\u001b[0m             .5 * n_features * np.log(self.degrees_of_freedom_))\n\u001b[0;32m    703\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\glede\\anaconda3\\envs\\py37\\lib\\site-packages\\sklearn\\mixture\\_gaussian_mixture.py\u001b[0m in \u001b[0;36m_estimate_log_gaussian_prob\u001b[1;34m(X, means, precisions_chol, covariance_type)\u001b[0m\n\u001b[0;32m    410\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprec_chol\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmeans\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprecisions_chol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    411\u001b[0m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprec_chol\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprec_chol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 412\u001b[1;33m             \u001b[0mlog_prob\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    413\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    414\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mcovariance_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'tied'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msum\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\glede\\anaconda3\\envs\\py37\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36msum\u001b[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m   2258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2259\u001b[0m     return _wrapreduction(a, np.add, 'sum', axis, dtype, out, keepdims=keepdims,\n\u001b[1;32m-> 2260\u001b[1;33m                           initial=initial, where=where)\n\u001b[0m\u001b[0;32m   2261\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2262\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\glede\\anaconda3\\envs\\py37\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[1;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[0;32m     84\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test = datgan.fit(df, graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datgan.save('trained', force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beepy.beep(6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
