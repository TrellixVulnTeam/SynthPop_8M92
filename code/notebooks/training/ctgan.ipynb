{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import ctgan\n",
    "from ctgan import CTGANSynthesizer\n",
    "\n",
    "# For the Python notebook\n",
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'Chicago'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/{}/data.csv'.format(dataset), index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>choice</th>\n",
       "      <th>travel_dow</th>\n",
       "      <th>trip_purpose</th>\n",
       "      <th>distance</th>\n",
       "      <th>hh_vehicles</th>\n",
       "      <th>hh_size</th>\n",
       "      <th>hh_bikes</th>\n",
       "      <th>hh_descr</th>\n",
       "      <th>hh_income</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>license</th>\n",
       "      <th>education_level</th>\n",
       "      <th>work_status</th>\n",
       "      <th>departure_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>drive</td>\n",
       "      <td>7</td>\n",
       "      <td>HOME_OTHER</td>\n",
       "      <td>3.93477</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>detached</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>PTE</td>\n",
       "      <td>20.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>drive</td>\n",
       "      <td>2</td>\n",
       "      <td>SHOPPING</td>\n",
       "      <td>0.31557</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>detached</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>FTE</td>\n",
       "      <td>17.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>drive</td>\n",
       "      <td>2</td>\n",
       "      <td>SHOPPING</td>\n",
       "      <td>0.28349</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>detached</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>PTE</td>\n",
       "      <td>9.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>drive</td>\n",
       "      <td>2</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>0.69417</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>detached</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>FTE</td>\n",
       "      <td>13.783333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>passenger</td>\n",
       "      <td>1</td>\n",
       "      <td>SHOPPING</td>\n",
       "      <td>4.30666</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>detached</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>11.566667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      choice  travel_dow trip_purpose  distance  hh_vehicles  hh_size  \\\n",
       "0      drive           7   HOME_OTHER   3.93477            2        3   \n",
       "1      drive           2     SHOPPING   0.31557            3        3   \n",
       "2      drive           2     SHOPPING   0.28349            1        1   \n",
       "3      drive           2        OTHER   0.69417            2        2   \n",
       "4  passenger           1     SHOPPING   4.30666            2        2   \n",
       "\n",
       "   hh_bikes  hh_descr  hh_income  gender  age  license  education_level  \\\n",
       "0         3  detached          6       0   30        1                4   \n",
       "1         3  detached          7       0   54        1                5   \n",
       "2         0  detached          3       0   80        1                3   \n",
       "3         0  detached          5       1   42        1                5   \n",
       "4         1  detached          4       0   32        0                3   \n",
       "\n",
       "  work_status  departure_time  \n",
       "0         PTE       20.166667  \n",
       "1         FTE       17.500000  \n",
       "2         PTE        9.333333  \n",
       "3         FTE       13.783333  \n",
       "4  Unemployed       11.566667  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset is 'Chicago':\n",
    "    discrete_columns = [\n",
    "        'choice',\n",
    "        'travel_dow',\n",
    "        'trip_purpose',\n",
    "        'hh_vehicles',\n",
    "        'hh_size',\n",
    "        'hh_bikes',\n",
    "        'hh_descr',\n",
    "        'hh_income',\n",
    "        'gender',\n",
    "        'license',\n",
    "        'education_level',\n",
    "        'work_status'\n",
    "    ]\n",
    "elif dataset is 'LPMC':\n",
    "    discrete_columns = [\n",
    "        'travel_mode',\n",
    "        'purpose',\n",
    "        'fueltype',\n",
    "        'faretype',\n",
    "        'bus_scale',\n",
    "        'survey_year',\n",
    "        'travel_year',\n",
    "        'travel_month',\n",
    "        'travel_date',\n",
    "        'day_of_week',\n",
    "        'female',\n",
    "        'driving_license',\n",
    "        'car_ownership',\n",
    "        'pt_n_interchanges',\n",
    "        'cost_driving_con_charge'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = '../output/' + dataset + '/CTGAN/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctgan = CTGANSynthesizer(verbose=True, cuda=True, batch_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\glede\\anaconda3\\envs\\py37\\lib\\site-packages\\sklearn\\mixture\\_base.py:269: ConvergenceWarning: Initialization 1 did not converge. Try different init parameters, or increase max_iter, tol or check for degenerate data.\n",
      "  % (init + 1), ConvergenceWarning)\n",
      "D:\\Users\\glede\\anaconda3\\envs\\py37\\lib\\site-packages\\sklearn\\mixture\\_base.py:269: ConvergenceWarning: Initialization 1 did not converge. Try different init parameters, or increase max_iter, tol or check for degenerate data.\n",
      "  % (init + 1), ConvergenceWarning)\n",
      "D:\\Users\\glede\\anaconda3\\envs\\py37\\lib\\site-packages\\sklearn\\mixture\\_base.py:269: ConvergenceWarning: Initialization 1 did not converge. Try different init parameters, or increase max_iter, tol or check for degenerate data.\n",
      "  % (init + 1), ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss G:  1.7106,Loss D: -0.4491\n",
      "Epoch 2, Loss G:  1.1326,Loss D: -0.0852\n",
      "Epoch 3, Loss G:  0.8236,Loss D:  0.0227\n",
      "Epoch 4, Loss G:  0.9873,Loss D:  0.1244\n",
      "Epoch 5, Loss G:  0.9938,Loss D:  0.0196\n",
      "Epoch 6, Loss G:  0.8368,Loss D:  0.0018\n",
      "Epoch 7, Loss G:  0.8826,Loss D: -0.0690\n",
      "Epoch 8, Loss G:  0.7938,Loss D:  0.0137\n",
      "Epoch 9, Loss G:  0.7936,Loss D: -0.0679\n",
      "Epoch 10, Loss G:  0.6183,Loss D: -0.0173\n",
      "Epoch 11, Loss G:  0.5654,Loss D: -0.0580\n",
      "Epoch 12, Loss G:  0.4273,Loss D:  0.0883\n",
      "Epoch 13, Loss G:  0.4489,Loss D:  0.0301\n",
      "Epoch 14, Loss G:  0.3530,Loss D: -0.0021\n",
      "Epoch 15, Loss G:  0.1621,Loss D:  0.0441\n",
      "Epoch 16, Loss G:  0.2969,Loss D: -0.1108\n",
      "Epoch 17, Loss G:  0.0533,Loss D:  0.0562\n",
      "Epoch 18, Loss G:  0.1880,Loss D: -0.0207\n",
      "Epoch 19, Loss G: -0.1661,Loss D:  0.0211\n",
      "Epoch 20, Loss G: -0.1124,Loss D: -0.1804\n",
      "Epoch 21, Loss G: -0.2071,Loss D:  0.1388\n",
      "Epoch 22, Loss G: -0.3756,Loss D: -0.0311\n",
      "Epoch 23, Loss G: -0.3761,Loss D: -0.0586\n",
      "Epoch 24, Loss G: -0.4168,Loss D: -0.0485\n",
      "Epoch 25, Loss G: -0.4858,Loss D: -0.0024\n",
      "Epoch 26, Loss G: -0.6315,Loss D:  0.0735\n",
      "Epoch 27, Loss G: -0.5443,Loss D: -0.1162\n",
      "Epoch 28, Loss G: -0.7014,Loss D:  0.0266\n",
      "Epoch 29, Loss G: -0.7045,Loss D: -0.0367\n",
      "Epoch 30, Loss G: -0.7574,Loss D:  0.0115\n",
      "Epoch 31, Loss G: -0.8855,Loss D: -0.0872\n",
      "Epoch 32, Loss G: -0.7793,Loss D: -0.1015\n",
      "Epoch 33, Loss G: -0.9347,Loss D: -0.1055\n",
      "Epoch 34, Loss G: -1.0784,Loss D: -0.0410\n",
      "Epoch 35, Loss G: -0.9555,Loss D:  0.0064\n",
      "Epoch 36, Loss G: -0.9853,Loss D:  0.0403\n",
      "Epoch 37, Loss G: -1.0463,Loss D:  0.0365\n",
      "Epoch 38, Loss G: -1.0829,Loss D: -0.0388\n",
      "Epoch 39, Loss G: -1.1049,Loss D: -0.2321\n",
      "Epoch 40, Loss G: -1.0089,Loss D: -0.0007\n",
      "Epoch 41, Loss G: -1.1887,Loss D: -0.0448\n",
      "Epoch 42, Loss G: -1.2253,Loss D: -0.1993\n",
      "Epoch 43, Loss G: -0.9527,Loss D:  0.0013\n",
      "Epoch 44, Loss G: -1.1992,Loss D: -0.2212\n",
      "Epoch 45, Loss G: -1.2180,Loss D: -0.2082\n",
      "Epoch 46, Loss G: -1.2736,Loss D: -0.1969\n",
      "Epoch 47, Loss G: -1.1153,Loss D: -0.1595\n",
      "Epoch 48, Loss G: -1.0701,Loss D: -0.3117\n",
      "Epoch 49, Loss G: -1.2427,Loss D:  0.0673\n",
      "Epoch 50, Loss G: -1.2028,Loss D: -0.2397\n",
      "Epoch 51, Loss G: -1.2315,Loss D: -0.0874\n",
      "Epoch 52, Loss G: -0.9404,Loss D: -0.3850\n",
      "Epoch 53, Loss G: -0.9336,Loss D: -0.3006\n",
      "Epoch 54, Loss G: -1.1599,Loss D: -0.4053\n",
      "Epoch 55, Loss G: -0.8253,Loss D: -0.2649\n",
      "Epoch 56, Loss G: -0.8763,Loss D: -0.1223\n",
      "Epoch 57, Loss G: -0.7347,Loss D: -0.3422\n",
      "Epoch 58, Loss G: -1.0161,Loss D: -0.2813\n",
      "Epoch 59, Loss G: -1.1076,Loss D: -0.2285\n",
      "Epoch 60, Loss G: -0.9289,Loss D: -0.2262\n",
      "Epoch 61, Loss G: -0.6081,Loss D: -0.2886\n",
      "Epoch 62, Loss G: -0.7641,Loss D: -0.1123\n",
      "Epoch 63, Loss G: -0.9599,Loss D: -0.3581\n",
      "Epoch 64, Loss G: -0.8474,Loss D: -0.1335\n",
      "Epoch 65, Loss G: -0.4756,Loss D: -0.1352\n",
      "Epoch 66, Loss G: -0.6936,Loss D:  0.0273\n",
      "Epoch 67, Loss G: -0.8025,Loss D: -0.5499\n",
      "Epoch 68, Loss G: -1.0423,Loss D: -0.0663\n",
      "Epoch 69, Loss G: -0.5028,Loss D: -0.2290\n",
      "Epoch 70, Loss G: -0.8797,Loss D: -0.0195\n",
      "Epoch 71, Loss G: -0.8931,Loss D: -0.1622\n",
      "Epoch 72, Loss G: -0.9515,Loss D: -0.4327\n",
      "Epoch 73, Loss G: -0.6886,Loss D: -0.2081\n",
      "Epoch 74, Loss G: -0.7074,Loss D: -0.1813\n",
      "Epoch 75, Loss G: -0.9575,Loss D: -0.2318\n",
      "Epoch 76, Loss G: -0.7420,Loss D: -0.2792\n",
      "Epoch 77, Loss G: -0.6744,Loss D:  0.1110\n",
      "Epoch 78, Loss G: -0.8283,Loss D: -0.1673\n",
      "Epoch 79, Loss G: -1.1935,Loss D: -0.0227\n",
      "Epoch 80, Loss G: -1.1590,Loss D: -0.4980\n",
      "Epoch 81, Loss G: -0.9700,Loss D:  0.0783\n",
      "Epoch 82, Loss G: -0.5567,Loss D: -0.2765\n",
      "Epoch 83, Loss G: -0.9505,Loss D: -0.0519\n",
      "Epoch 84, Loss G: -0.7369,Loss D: -0.0641\n",
      "Epoch 85, Loss G: -1.1179,Loss D: -0.0532\n",
      "Epoch 86, Loss G: -0.9609,Loss D: -0.1038\n",
      "Epoch 87, Loss G: -0.8436,Loss D: -0.0055\n",
      "Epoch 88, Loss G: -0.7734,Loss D:  0.0519\n",
      "Epoch 89, Loss G: -1.2130,Loss D: -0.2676\n",
      "Epoch 90, Loss G: -1.1914,Loss D:  0.0200\n",
      "Epoch 91, Loss G: -1.0041,Loss D: -0.2894\n",
      "Epoch 92, Loss G: -0.9997,Loss D:  0.0370\n",
      "Epoch 93, Loss G: -1.3949,Loss D: -0.1181\n",
      "Epoch 94, Loss G: -0.9560,Loss D:  0.1505\n",
      "Epoch 95, Loss G: -1.2716,Loss D:  0.0232\n",
      "Epoch 96, Loss G: -1.0416,Loss D: -0.1506\n",
      "Epoch 97, Loss G: -0.8570,Loss D: -0.2043\n",
      "Epoch 98, Loss G: -1.0728,Loss D:  0.0182\n",
      "Epoch 99, Loss G: -1.0587,Loss D: -0.2304\n",
      "Epoch 100, Loss G: -1.0764,Loss D: -0.0081\n",
      "Epoch 101, Loss G: -1.2102,Loss D: -0.0886\n",
      "Epoch 102, Loss G: -1.1889,Loss D: -0.0731\n",
      "Epoch 103, Loss G: -0.8658,Loss D: -0.2482\n",
      "Epoch 104, Loss G: -1.1585,Loss D: -0.1372\n",
      "Epoch 105, Loss G: -1.0644,Loss D: -0.0712\n",
      "Epoch 106, Loss G: -0.7955,Loss D: -0.0690\n",
      "Epoch 107, Loss G: -0.9625,Loss D: -0.0390\n",
      "Epoch 108, Loss G: -1.0960,Loss D:  0.0389\n",
      "Epoch 109, Loss G: -0.8559,Loss D:  0.1079\n",
      "Epoch 110, Loss G: -0.9662,Loss D:  0.0192\n",
      "Epoch 111, Loss G: -1.0008,Loss D: -0.1457\n",
      "Epoch 112, Loss G: -1.1937,Loss D: -0.1940\n",
      "Epoch 113, Loss G: -0.9954,Loss D: -0.5045\n",
      "Epoch 114, Loss G: -0.8437,Loss D:  0.3146\n",
      "Epoch 115, Loss G: -0.9457,Loss D: -0.2714\n",
      "Epoch 116, Loss G: -1.3471,Loss D:  0.2558\n",
      "Epoch 117, Loss G: -1.1277,Loss D:  0.0365\n",
      "Epoch 118, Loss G: -0.9997,Loss D:  0.1402\n",
      "Epoch 119, Loss G: -0.8613,Loss D: -0.1185\n",
      "Epoch 120, Loss G: -0.9600,Loss D:  0.0076\n",
      "Epoch 121, Loss G: -1.0451,Loss D: -0.2787\n",
      "Epoch 122, Loss G: -1.0521,Loss D:  0.1537\n",
      "Epoch 123, Loss G: -0.7408,Loss D:  0.0256\n",
      "Epoch 124, Loss G: -0.8901,Loss D: -0.0819\n",
      "Epoch 125, Loss G: -0.6985,Loss D: -0.1801\n",
      "Epoch 126, Loss G: -1.0112,Loss D:  0.1335\n",
      "Epoch 127, Loss G: -1.1402,Loss D: -0.3020\n",
      "Epoch 128, Loss G: -1.0301,Loss D:  0.1349\n",
      "Epoch 129, Loss G: -0.7960,Loss D: -0.2539\n",
      "Epoch 130, Loss G: -0.6034,Loss D: -0.0461\n",
      "Epoch 131, Loss G: -0.8818,Loss D: -0.1377\n",
      "Epoch 132, Loss G: -0.7923,Loss D:  0.2077\n",
      "Epoch 133, Loss G: -0.8645,Loss D: -0.2737\n",
      "Epoch 134, Loss G: -1.0187,Loss D: -0.2535\n",
      "Epoch 135, Loss G: -0.7971,Loss D:  0.0267\n",
      "Epoch 136, Loss G: -0.6311,Loss D: -0.3895\n",
      "Epoch 137, Loss G: -0.7703,Loss D: -0.1130\n",
      "Epoch 138, Loss G: -1.0306,Loss D: -0.1363\n",
      "Epoch 139, Loss G: -0.7857,Loss D: -0.0368\n",
      "Epoch 140, Loss G: -0.7986,Loss D: -0.2623\n",
      "Epoch 141, Loss G: -0.6593,Loss D: -0.0102\n",
      "Epoch 142, Loss G: -1.0821,Loss D: -0.0561\n",
      "Epoch 143, Loss G: -0.9159,Loss D: -0.1492\n",
      "Epoch 144, Loss G: -0.9225,Loss D: -0.0538\n",
      "Epoch 145, Loss G: -0.9071,Loss D:  0.0872\n",
      "Epoch 146, Loss G: -0.8792,Loss D:  0.2506\n",
      "Epoch 147, Loss G: -0.7688,Loss D: -0.2711\n",
      "Epoch 148, Loss G: -0.8296,Loss D: -0.1356\n",
      "Epoch 149, Loss G: -0.9070,Loss D:  0.2052\n",
      "Epoch 150, Loss G: -1.0245,Loss D: -0.2200\n",
      "Epoch 151, Loss G: -0.8317,Loss D:  0.0043\n",
      "Epoch 152, Loss G: -0.4798,Loss D: -0.4026\n",
      "Epoch 153, Loss G: -0.6865,Loss D: -0.1563\n",
      "Epoch 154, Loss G: -1.1944,Loss D: -0.0633\n",
      "Epoch 155, Loss G: -1.0409,Loss D: -0.1616\n",
      "Epoch 156, Loss G: -0.8994,Loss D:  0.0680\n",
      "Epoch 157, Loss G: -0.8292,Loss D: -0.1993\n",
      "Epoch 158, Loss G: -0.6926,Loss D: -0.2590\n",
      "Epoch 159, Loss G: -1.0358,Loss D:  0.0563\n",
      "Epoch 160, Loss G: -0.7773,Loss D: -0.0356\n",
      "Epoch 161, Loss G: -0.9658,Loss D: -0.1664\n",
      "Epoch 162, Loss G: -0.9990,Loss D: -0.1030\n",
      "Epoch 163, Loss G: -0.9877,Loss D: -0.1470\n",
      "Epoch 164, Loss G: -0.7290,Loss D: -0.2663\n",
      "Epoch 165, Loss G: -0.7875,Loss D: -0.0534\n",
      "Epoch 166, Loss G: -0.8458,Loss D: -0.0633\n",
      "Epoch 167, Loss G: -1.2020,Loss D: -0.1388\n",
      "Epoch 168, Loss G: -1.1109,Loss D: -0.0913\n",
      "Epoch 169, Loss G: -0.9326,Loss D: -0.2054\n",
      "Epoch 170, Loss G: -0.7539,Loss D: -0.0880\n",
      "Epoch 171, Loss G: -0.7833,Loss D: -0.0040\n",
      "Epoch 172, Loss G: -0.9509,Loss D:  0.1419\n",
      "Epoch 173, Loss G: -0.8345,Loss D: -0.0553\n",
      "Epoch 174, Loss G: -0.8446,Loss D: -0.0448\n",
      "Epoch 175, Loss G: -0.8921,Loss D: -0.0606\n",
      "Epoch 176, Loss G: -0.8788,Loss D: -0.2894\n",
      "Epoch 177, Loss G: -1.0693,Loss D:  0.0362\n",
      "Epoch 178, Loss G: -1.0333,Loss D:  0.0349\n",
      "Epoch 179, Loss G: -0.8850,Loss D: -0.1387\n",
      "Epoch 180, Loss G: -0.8888,Loss D:  0.1858\n",
      "Epoch 181, Loss G: -0.8416,Loss D: -0.1213\n",
      "Epoch 182, Loss G: -0.8036,Loss D:  0.4081\n",
      "Epoch 183, Loss G: -0.8586,Loss D:  0.1289\n",
      "Epoch 184, Loss G: -1.0910,Loss D: -0.1713\n",
      "Epoch 185, Loss G: -1.1152,Loss D:  0.0434\n",
      "Epoch 186, Loss G: -1.1075,Loss D: -0.1720\n",
      "Epoch 187, Loss G: -0.9814,Loss D:  0.1255\n",
      "Epoch 188, Loss G: -0.7675,Loss D: -0.1325\n",
      "Epoch 189, Loss G: -0.6277,Loss D: -0.1746\n",
      "Epoch 190, Loss G: -0.8813,Loss D: -0.0401\n",
      "Epoch 191, Loss G: -0.7379,Loss D: -0.1433\n",
      "Epoch 192, Loss G: -0.8288,Loss D: -0.0125\n",
      "Epoch 193, Loss G: -0.8571,Loss D: -0.2805\n",
      "Epoch 194, Loss G: -0.8062,Loss D:  0.1224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 195, Loss G: -0.6182,Loss D:  0.1222\n",
      "Epoch 196, Loss G: -0.5793,Loss D: -0.1916\n",
      "Epoch 197, Loss G: -0.4754,Loss D:  0.0469\n",
      "Epoch 198, Loss G: -0.8767,Loss D: -0.2368\n",
      "Epoch 199, Loss G: -0.8331,Loss D: -0.4253\n",
      "Epoch 200, Loss G: -0.7526,Loss D:  0.0032\n",
      "Epoch 201, Loss G: -0.9548,Loss D: -0.0508\n",
      "Epoch 202, Loss G: -1.0512,Loss D: -0.1565\n",
      "Epoch 203, Loss G: -0.8345,Loss D: -0.0116\n",
      "Epoch 204, Loss G: -0.5268,Loss D:  0.0465\n",
      "Epoch 205, Loss G: -0.4661,Loss D: -0.0823\n",
      "Epoch 206, Loss G: -0.8494,Loss D:  0.0436\n",
      "Epoch 207, Loss G: -1.0326,Loss D:  0.0119\n",
      "Epoch 208, Loss G: -0.7627,Loss D:  0.2193\n",
      "Epoch 209, Loss G: -0.9518,Loss D: -0.0967\n",
      "Epoch 210, Loss G: -0.9747,Loss D: -0.1383\n",
      "Epoch 211, Loss G: -1.2964,Loss D:  0.0061\n",
      "Epoch 212, Loss G: -1.1293,Loss D: -0.0308\n",
      "Epoch 213, Loss G: -1.2285,Loss D: -0.3379\n",
      "Epoch 214, Loss G: -0.8014,Loss D: -0.0429\n",
      "Epoch 215, Loss G: -1.1524,Loss D:  0.2409\n",
      "Epoch 216, Loss G: -0.8428,Loss D:  0.1024\n",
      "Epoch 217, Loss G: -0.9114,Loss D: -0.2015\n",
      "Epoch 218, Loss G: -0.9898,Loss D:  0.0214\n",
      "Epoch 219, Loss G: -0.9676,Loss D:  0.0558\n",
      "Epoch 220, Loss G: -1.5216,Loss D:  0.1833\n",
      "Epoch 221, Loss G: -0.8572,Loss D: -0.2643\n",
      "Epoch 222, Loss G: -1.0916,Loss D:  0.0303\n",
      "Epoch 223, Loss G: -1.0670,Loss D: -0.0511\n",
      "Epoch 224, Loss G: -0.9972,Loss D: -0.1693\n",
      "Epoch 225, Loss G: -0.9708,Loss D: -0.2380\n",
      "Epoch 226, Loss G: -0.8049,Loss D: -0.1867\n",
      "Epoch 227, Loss G: -0.9362,Loss D:  0.1933\n",
      "Epoch 228, Loss G: -0.9954,Loss D: -0.0934\n",
      "Epoch 229, Loss G: -0.6651,Loss D: -0.1053\n",
      "Epoch 230, Loss G: -0.8229,Loss D: -0.1845\n",
      "Epoch 231, Loss G: -0.8015,Loss D:  0.1165\n",
      "Epoch 232, Loss G: -0.9056,Loss D:  0.0009\n",
      "Epoch 233, Loss G: -1.1103,Loss D:  0.2358\n",
      "Epoch 234, Loss G: -0.7699,Loss D:  0.0617\n",
      "Epoch 235, Loss G: -0.8659,Loss D:  0.2038\n",
      "Epoch 236, Loss G: -0.7032,Loss D:  0.1425\n",
      "Epoch 237, Loss G: -0.6434,Loss D:  0.0958\n",
      "Epoch 238, Loss G: -1.0067,Loss D: -0.0556\n",
      "Epoch 239, Loss G: -0.5952,Loss D: -0.2795\n",
      "Epoch 240, Loss G: -0.4707,Loss D:  0.1718\n",
      "Epoch 241, Loss G: -0.5377,Loss D: -0.4173\n",
      "Epoch 242, Loss G: -0.8414,Loss D: -0.0613\n",
      "Epoch 243, Loss G: -0.7971,Loss D: -0.0274\n",
      "Epoch 244, Loss G: -0.8343,Loss D:  0.0441\n",
      "Epoch 245, Loss G: -0.8995,Loss D: -0.1404\n",
      "Epoch 246, Loss G: -0.8829,Loss D: -0.0346\n",
      "Epoch 247, Loss G: -0.8677,Loss D: -0.1207\n",
      "Epoch 248, Loss G: -0.7966,Loss D: -0.0679\n",
      "Epoch 249, Loss G: -0.8053,Loss D:  0.0120\n",
      "Epoch 250, Loss G: -0.7542,Loss D: -0.1994\n",
      "Epoch 251, Loss G: -0.7145,Loss D: -0.0445\n",
      "Epoch 252, Loss G: -0.6771,Loss D:  0.0811\n",
      "Epoch 253, Loss G: -1.2399,Loss D: -0.1068\n",
      "Epoch 254, Loss G: -1.0212,Loss D: -0.1611\n",
      "Epoch 255, Loss G: -1.1914,Loss D: -0.0423\n",
      "Epoch 256, Loss G: -0.6764,Loss D: -0.1410\n",
      "Epoch 257, Loss G: -0.9105,Loss D:  0.2006\n",
      "Epoch 258, Loss G: -0.8372,Loss D: -0.1614\n",
      "Epoch 259, Loss G: -0.7473,Loss D:  0.1935\n",
      "Epoch 260, Loss G: -0.7111,Loss D: -0.1558\n",
      "Epoch 261, Loss G: -0.7196,Loss D:  0.0660\n",
      "Epoch 262, Loss G: -0.8965,Loss D: -0.2194\n",
      "Epoch 263, Loss G: -0.9633,Loss D:  0.0737\n",
      "Epoch 264, Loss G: -1.0202,Loss D: -0.0325\n",
      "Epoch 265, Loss G: -1.0277,Loss D: -0.0641\n",
      "Epoch 266, Loss G: -0.9644,Loss D: -0.2015\n",
      "Epoch 267, Loss G: -1.2314,Loss D: -0.1427\n",
      "Epoch 268, Loss G: -1.3376,Loss D: -0.1275\n",
      "Epoch 269, Loss G: -1.0414,Loss D:  0.1713\n",
      "Epoch 270, Loss G: -1.2722,Loss D: -0.3339\n",
      "Epoch 271, Loss G: -1.0156,Loss D: -0.0310\n",
      "Epoch 272, Loss G: -0.9486,Loss D: -0.1729\n",
      "Epoch 273, Loss G: -1.0938,Loss D:  0.0542\n",
      "Epoch 274, Loss G: -0.8923,Loss D:  0.0621\n",
      "Epoch 275, Loss G: -0.9330,Loss D: -0.2435\n",
      "Epoch 276, Loss G: -0.9900,Loss D:  0.1763\n",
      "Epoch 277, Loss G: -0.9481,Loss D: -0.4121\n",
      "Epoch 278, Loss G: -0.9662,Loss D:  0.1109\n",
      "Epoch 279, Loss G: -1.1122,Loss D:  0.0157\n",
      "Epoch 280, Loss G: -0.8565,Loss D: -0.3241\n",
      "Epoch 281, Loss G: -0.6646,Loss D: -0.0266\n",
      "Epoch 282, Loss G: -0.5810,Loss D: -0.1627\n",
      "Epoch 283, Loss G: -0.6316,Loss D: -0.2862\n",
      "Epoch 284, Loss G: -0.8330,Loss D:  0.0384\n",
      "Epoch 285, Loss G: -0.9193,Loss D:  0.2345\n",
      "Epoch 286, Loss G: -0.6392,Loss D: -0.2313\n",
      "Epoch 287, Loss G: -0.5172,Loss D:  0.0012\n",
      "Epoch 288, Loss G: -0.7534,Loss D:  0.1049\n",
      "Epoch 289, Loss G: -0.8570,Loss D: -0.2021\n",
      "Epoch 290, Loss G: -0.7081,Loss D: -0.0131\n",
      "Epoch 291, Loss G: -0.5835,Loss D: -0.1833\n",
      "Epoch 292, Loss G: -0.6312,Loss D: -0.0917\n",
      "Epoch 293, Loss G: -0.6332,Loss D:  0.0378\n",
      "Epoch 294, Loss G: -0.8659,Loss D:  0.1129\n",
      "Epoch 295, Loss G: -0.7092,Loss D: -0.0336\n",
      "Epoch 296, Loss G: -0.4873,Loss D: -0.2422\n",
      "Epoch 297, Loss G: -0.7512,Loss D: -0.1674\n",
      "Epoch 298, Loss G: -0.6852,Loss D: -0.0538\n",
      "Epoch 299, Loss G: -0.8343,Loss D: -0.0411\n",
      "Epoch 300, Loss G: -0.6714,Loss D: -0.2013\n",
      "Epoch 301, Loss G: -0.5525,Loss D: -0.1835\n",
      "Epoch 302, Loss G: -0.9975,Loss D:  0.1042\n",
      "Epoch 303, Loss G: -1.0146,Loss D: -0.3449\n",
      "Epoch 304, Loss G: -0.8977,Loss D: -0.1443\n",
      "Epoch 305, Loss G: -0.6585,Loss D: -0.2503\n",
      "Epoch 306, Loss G: -0.8055,Loss D: -0.0247\n",
      "Epoch 307, Loss G: -1.0344,Loss D: -0.1652\n",
      "Epoch 308, Loss G: -0.8800,Loss D: -0.1276\n",
      "Epoch 309, Loss G: -1.0571,Loss D:  0.0553\n",
      "Epoch 310, Loss G: -0.7401,Loss D: -0.2344\n",
      "Epoch 311, Loss G: -0.7364,Loss D: -0.1915\n",
      "Epoch 312, Loss G: -1.0480,Loss D: -0.0213\n",
      "Epoch 313, Loss G: -0.9905,Loss D:  0.0528\n",
      "Epoch 314, Loss G: -0.9020,Loss D: -0.0803\n",
      "Epoch 315, Loss G: -0.6215,Loss D: -0.6140\n",
      "Epoch 316, Loss G: -0.5523,Loss D:  0.1523\n",
      "Epoch 317, Loss G: -0.7819,Loss D: -0.1897\n",
      "Epoch 318, Loss G: -0.6265,Loss D: -0.2727\n",
      "Epoch 319, Loss G: -1.0480,Loss D:  0.1304\n",
      "Epoch 320, Loss G: -0.8194,Loss D: -0.4533\n",
      "Epoch 321, Loss G: -0.8504,Loss D:  0.0851\n",
      "Epoch 322, Loss G: -0.8475,Loss D: -0.0045\n",
      "Epoch 323, Loss G: -0.9430,Loss D: -0.0572\n",
      "Epoch 324, Loss G: -0.7640,Loss D: -0.0482\n",
      "Epoch 325, Loss G: -0.8851,Loss D:  0.0046\n",
      "Epoch 326, Loss G: -0.3623,Loss D: -0.2110\n",
      "Epoch 327, Loss G: -0.8189,Loss D: -0.1426\n",
      "Epoch 328, Loss G: -0.9078,Loss D: -0.3867\n",
      "Epoch 329, Loss G: -0.7807,Loss D: -0.1408\n",
      "Epoch 330, Loss G: -0.9526,Loss D:  0.0527\n",
      "Epoch 331, Loss G: -0.7897,Loss D:  0.0592\n",
      "Epoch 332, Loss G: -0.6099,Loss D: -0.1299\n",
      "Epoch 333, Loss G: -0.6744,Loss D: -0.2458\n",
      "Epoch 334, Loss G: -0.8066,Loss D: -0.2108\n",
      "Epoch 335, Loss G: -0.7688,Loss D:  0.1061\n",
      "Epoch 336, Loss G: -0.9714,Loss D: -0.0206\n",
      "Epoch 337, Loss G: -0.9854,Loss D:  0.0074\n",
      "Epoch 338, Loss G: -0.5286,Loss D:  0.0819\n",
      "Epoch 339, Loss G: -0.8024,Loss D:  0.0930\n",
      "Epoch 340, Loss G: -0.6542,Loss D:  0.2600\n",
      "Epoch 341, Loss G: -0.7879,Loss D: -0.2821\n",
      "Epoch 342, Loss G: -0.7706,Loss D:  0.2363\n",
      "Epoch 343, Loss G: -0.6847,Loss D: -0.3224\n",
      "Epoch 344, Loss G: -0.6819,Loss D:  0.0812\n",
      "Epoch 345, Loss G: -0.4796,Loss D: -0.0227\n",
      "Epoch 346, Loss G: -0.7747,Loss D: -0.2707\n",
      "Epoch 347, Loss G: -1.1273,Loss D: -0.2670\n",
      "Epoch 348, Loss G: -0.7651,Loss D: -0.1855\n",
      "Epoch 349, Loss G: -0.8881,Loss D: -0.0029\n",
      "Epoch 350, Loss G: -0.6204,Loss D: -0.0244\n",
      "Epoch 351, Loss G: -0.7693,Loss D:  0.1432\n",
      "Epoch 352, Loss G: -0.4070,Loss D:  0.0053\n",
      "Epoch 353, Loss G: -0.6463,Loss D: -0.2893\n",
      "Epoch 354, Loss G: -0.9628,Loss D:  0.0846\n",
      "Epoch 355, Loss G: -1.1848,Loss D:  0.3016\n",
      "Epoch 356, Loss G: -0.7278,Loss D: -0.1745\n",
      "Epoch 357, Loss G: -0.8651,Loss D: -0.0345\n",
      "Epoch 358, Loss G: -0.7988,Loss D:  0.1318\n",
      "Epoch 359, Loss G: -1.0483,Loss D:  0.0551\n",
      "Epoch 360, Loss G: -0.9173,Loss D: -0.2246\n",
      "Epoch 361, Loss G: -0.8162,Loss D:  0.1015\n",
      "Epoch 362, Loss G: -0.6913,Loss D: -0.2881\n",
      "Epoch 363, Loss G: -0.8861,Loss D: -0.0139\n",
      "Epoch 364, Loss G: -1.1142,Loss D: -0.1804\n",
      "Epoch 365, Loss G: -1.1953,Loss D: -0.1793\n",
      "Epoch 366, Loss G: -0.9489,Loss D:  0.1387\n",
      "Epoch 367, Loss G: -0.7684,Loss D:  0.1794\n",
      "Epoch 368, Loss G: -0.4291,Loss D: -0.0409\n",
      "Epoch 369, Loss G: -0.8403,Loss D:  0.1281\n",
      "Epoch 370, Loss G: -0.8896,Loss D: -0.4816\n",
      "Epoch 371, Loss G: -1.1946,Loss D: -0.2369\n",
      "Epoch 372, Loss G: -1.1268,Loss D:  0.0176\n",
      "Epoch 373, Loss G: -1.2733,Loss D: -0.0938\n",
      "Epoch 374, Loss G: -0.8690,Loss D: -0.1889\n",
      "Epoch 375, Loss G: -1.2675,Loss D: -0.1582\n",
      "Epoch 376, Loss G: -1.1431,Loss D: -0.1109\n",
      "Epoch 377, Loss G: -1.3905,Loss D: -0.0165\n",
      "Epoch 378, Loss G: -1.1997,Loss D: -0.1914\n",
      "Epoch 379, Loss G: -1.0954,Loss D:  0.0193\n",
      "Epoch 380, Loss G: -0.8582,Loss D:  0.1226\n",
      "Epoch 381, Loss G: -1.1098,Loss D:  0.0629\n",
      "Epoch 382, Loss G: -1.2585,Loss D:  0.0321\n",
      "Epoch 383, Loss G: -1.0597,Loss D: -0.3935\n",
      "Epoch 384, Loss G: -0.9720,Loss D: -0.2794\n",
      "Epoch 385, Loss G: -0.9420,Loss D:  0.0568\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 386, Loss G: -1.1077,Loss D: -0.0194\n",
      "Epoch 387, Loss G: -0.9421,Loss D: -0.2253\n",
      "Epoch 388, Loss G: -1.0049,Loss D: -0.3170\n",
      "Epoch 389, Loss G: -0.9776,Loss D:  0.0934\n",
      "Epoch 390, Loss G: -0.8737,Loss D: -0.0264\n",
      "Epoch 391, Loss G: -1.1031,Loss D: -0.1398\n",
      "Epoch 392, Loss G: -1.1771,Loss D:  0.0382\n",
      "Epoch 393, Loss G: -1.2612,Loss D: -0.1354\n",
      "Epoch 394, Loss G: -1.2759,Loss D:  0.0984\n",
      "Epoch 395, Loss G: -0.9739,Loss D:  0.1026\n",
      "Epoch 396, Loss G: -0.8473,Loss D:  0.0843\n",
      "Epoch 397, Loss G: -1.2848,Loss D:  0.1390\n",
      "Epoch 398, Loss G: -0.9783,Loss D: -0.0247\n",
      "Epoch 399, Loss G: -1.1840,Loss D: -0.2993\n",
      "Epoch 400, Loss G: -1.2360,Loss D:  0.1269\n",
      "Epoch 401, Loss G: -1.0458,Loss D: -0.3226\n",
      "Epoch 402, Loss G: -1.4122,Loss D:  0.1003\n",
      "Epoch 403, Loss G: -1.1658,Loss D:  0.1267\n",
      "Epoch 404, Loss G: -1.1793,Loss D: -0.2634\n",
      "Epoch 405, Loss G: -1.1312,Loss D: -0.0568\n",
      "Epoch 406, Loss G: -1.2575,Loss D: -0.0868\n",
      "Epoch 407, Loss G: -1.2462,Loss D:  0.1350\n",
      "Epoch 408, Loss G: -1.2855,Loss D:  0.1178\n",
      "Epoch 409, Loss G: -1.2537,Loss D: -0.2093\n",
      "Epoch 410, Loss G: -1.4421,Loss D: -0.1648\n",
      "Epoch 411, Loss G: -1.2910,Loss D:  0.1346\n",
      "Epoch 412, Loss G: -1.1926,Loss D: -0.2596\n",
      "Epoch 413, Loss G: -1.0951,Loss D: -0.1170\n",
      "Epoch 414, Loss G: -1.0750,Loss D:  0.0128\n",
      "Epoch 415, Loss G: -1.2220,Loss D:  0.1459\n",
      "Epoch 416, Loss G: -1.1481,Loss D: -0.1618\n",
      "Epoch 417, Loss G: -1.1456,Loss D:  0.1743\n",
      "Epoch 418, Loss G: -1.0552,Loss D: -0.1158\n",
      "Epoch 419, Loss G: -1.2853,Loss D:  0.2132\n",
      "Epoch 420, Loss G: -1.4844,Loss D: -0.1216\n",
      "Epoch 421, Loss G: -1.1031,Loss D:  0.1217\n",
      "Epoch 422, Loss G: -0.9806,Loss D: -0.0085\n",
      "Epoch 423, Loss G: -1.1023,Loss D: -0.3021\n",
      "Epoch 424, Loss G: -1.1042,Loss D: -0.0141\n",
      "Epoch 425, Loss G: -1.2069,Loss D: -0.1410\n",
      "Epoch 426, Loss G: -1.0030,Loss D: -0.0927\n",
      "Epoch 427, Loss G: -0.9995,Loss D:  0.1518\n",
      "Epoch 428, Loss G: -1.1054,Loss D: -0.3102\n",
      "Epoch 429, Loss G: -1.0729,Loss D:  0.0340\n",
      "Epoch 430, Loss G: -0.8849,Loss D:  0.0984\n",
      "Epoch 431, Loss G: -0.7826,Loss D: -0.2395\n",
      "Epoch 432, Loss G: -0.9748,Loss D: -0.0509\n",
      "Epoch 433, Loss G: -0.9867,Loss D:  0.0005\n",
      "Epoch 434, Loss G: -0.8199,Loss D: -0.1013\n",
      "Epoch 435, Loss G: -0.9657,Loss D: -0.0063\n",
      "Epoch 436, Loss G: -1.0800,Loss D: -0.0077\n",
      "Epoch 437, Loss G: -1.0067,Loss D: -0.1379\n",
      "Epoch 438, Loss G: -1.1594,Loss D:  0.0022\n",
      "Epoch 439, Loss G: -0.9809,Loss D: -0.1730\n",
      "Epoch 440, Loss G: -0.7514,Loss D: -0.0606\n",
      "Epoch 441, Loss G: -0.9893,Loss D: -0.1981\n",
      "Epoch 442, Loss G: -1.0194,Loss D: -0.0056\n",
      "Epoch 443, Loss G: -0.8566,Loss D:  0.0623\n",
      "Epoch 444, Loss G: -1.0007,Loss D: -0.0609\n",
      "Epoch 445, Loss G: -1.0842,Loss D:  0.0844\n",
      "Epoch 446, Loss G: -0.8802,Loss D:  0.0201\n",
      "Epoch 447, Loss G: -0.8980,Loss D:  0.0784\n",
      "Epoch 448, Loss G: -1.1489,Loss D: -0.1544\n",
      "Epoch 449, Loss G: -0.9022,Loss D: -0.0527\n",
      "Epoch 450, Loss G: -1.0581,Loss D: -0.3940\n",
      "Epoch 451, Loss G: -0.7773,Loss D:  0.2567\n",
      "Epoch 452, Loss G: -0.7718,Loss D:  0.0113\n",
      "Epoch 453, Loss G: -0.8716,Loss D: -0.2206\n",
      "Epoch 454, Loss G: -0.8432,Loss D: -0.0993\n",
      "Epoch 455, Loss G: -0.9171,Loss D: -0.2147\n",
      "Epoch 456, Loss G: -0.6902,Loss D: -0.2439\n",
      "Epoch 457, Loss G: -0.5091,Loss D:  0.0411\n",
      "Epoch 458, Loss G: -0.6573,Loss D:  0.0757\n",
      "Epoch 459, Loss G: -0.8348,Loss D:  0.2762\n",
      "Epoch 460, Loss G: -0.8777,Loss D: -0.0764\n",
      "Epoch 461, Loss G: -0.9504,Loss D: -0.0156\n",
      "Epoch 462, Loss G: -0.7357,Loss D: -0.1318\n",
      "Epoch 463, Loss G: -0.7632,Loss D: -0.2241\n",
      "Epoch 464, Loss G: -0.5857,Loss D: -0.0802\n",
      "Epoch 465, Loss G: -0.6399,Loss D: -0.3717\n",
      "Epoch 466, Loss G: -1.0364,Loss D:  0.2064\n",
      "Epoch 467, Loss G: -0.9690,Loss D: -0.1686\n",
      "Epoch 468, Loss G: -1.0039,Loss D: -0.2175\n",
      "Epoch 469, Loss G: -0.9833,Loss D: -0.1279\n",
      "Epoch 470, Loss G: -1.1007,Loss D: -0.2823\n",
      "Epoch 471, Loss G: -1.2331,Loss D:  0.0876\n",
      "Epoch 472, Loss G: -0.9635,Loss D: -0.5188\n",
      "Epoch 473, Loss G: -1.0648,Loss D: -0.0973\n",
      "Epoch 474, Loss G: -0.6922,Loss D: -0.1430\n",
      "Epoch 475, Loss G: -0.7041,Loss D: -0.0852\n",
      "Epoch 476, Loss G: -0.6737,Loss D: -0.0014\n",
      "Epoch 477, Loss G: -1.2551,Loss D:  0.0148\n",
      "Epoch 478, Loss G: -1.0509,Loss D: -0.0806\n",
      "Epoch 479, Loss G: -0.7946,Loss D: -0.2303\n",
      "Epoch 480, Loss G: -0.9607,Loss D:  0.1608\n",
      "Epoch 481, Loss G: -0.7007,Loss D: -0.0735\n",
      "Epoch 482, Loss G: -0.8307,Loss D: -0.0743\n",
      "Epoch 483, Loss G: -0.9271,Loss D: -0.1546\n",
      "Epoch 484, Loss G: -0.8471,Loss D: -0.3021\n",
      "Epoch 485, Loss G: -0.9304,Loss D:  0.2434\n",
      "Epoch 486, Loss G: -0.7049,Loss D:  0.2087\n",
      "Epoch 487, Loss G: -0.8361,Loss D: -0.1145\n",
      "Epoch 488, Loss G: -0.9518,Loss D:  0.0290\n",
      "Epoch 489, Loss G: -0.9531,Loss D:  0.1233\n",
      "Epoch 490, Loss G: -1.1646,Loss D:  0.2141\n",
      "Epoch 491, Loss G: -1.0996,Loss D: -0.1096\n",
      "Epoch 492, Loss G: -0.7333,Loss D: -0.1501\n",
      "Epoch 493, Loss G: -0.9536,Loss D:  0.0754\n",
      "Epoch 494, Loss G: -0.9182,Loss D: -0.0127\n",
      "Epoch 495, Loss G: -1.0397,Loss D:  0.0272\n",
      "Epoch 496, Loss G: -1.0011,Loss D:  0.1218\n",
      "Epoch 497, Loss G: -1.0546,Loss D:  0.0916\n",
      "Epoch 498, Loss G: -0.8581,Loss D: -0.2013\n",
      "Epoch 499, Loss G: -0.9869,Loss D: -0.1203\n",
      "Epoch 500, Loss G: -0.8400,Loss D: -0.0247\n",
      "Epoch 501, Loss G: -1.0736,Loss D: -0.1333\n",
      "Epoch 502, Loss G: -1.0624,Loss D: -0.0824\n",
      "Epoch 503, Loss G: -0.8726,Loss D: -0.0519\n",
      "Epoch 504, Loss G: -0.9585,Loss D:  0.0916\n",
      "Epoch 505, Loss G: -0.6958,Loss D: -0.0117\n",
      "Epoch 506, Loss G: -0.9434,Loss D: -0.2050\n",
      "Epoch 507, Loss G: -1.0442,Loss D:  0.1112\n",
      "Epoch 508, Loss G: -0.8451,Loss D: -0.0647\n",
      "Epoch 509, Loss G: -0.9384,Loss D: -0.1392\n",
      "Epoch 510, Loss G: -1.0084,Loss D:  0.3752\n",
      "Epoch 511, Loss G: -0.8961,Loss D: -0.1019\n",
      "Epoch 512, Loss G: -0.8770,Loss D: -0.0616\n",
      "Epoch 513, Loss G: -1.2083,Loss D:  0.0307\n",
      "Epoch 514, Loss G: -0.9458,Loss D:  0.0580\n",
      "Epoch 515, Loss G: -1.0365,Loss D:  0.0410\n",
      "Epoch 516, Loss G: -0.7611,Loss D: -0.0228\n",
      "Epoch 517, Loss G: -0.8353,Loss D: -0.2783\n",
      "Epoch 518, Loss G: -0.8344,Loss D: -0.0966\n",
      "Epoch 519, Loss G: -0.9657,Loss D:  0.0072\n",
      "Epoch 520, Loss G: -1.0228,Loss D:  0.1472\n",
      "Epoch 521, Loss G: -0.6774,Loss D: -0.1896\n",
      "Epoch 522, Loss G: -0.6435,Loss D: -0.0888\n",
      "Epoch 523, Loss G: -0.9229,Loss D: -0.1439\n",
      "Epoch 524, Loss G: -0.8390,Loss D: -0.1371\n",
      "Epoch 525, Loss G: -0.7262,Loss D: -0.3892\n",
      "Epoch 526, Loss G: -0.5799,Loss D: -0.2434\n",
      "Epoch 527, Loss G: -0.5670,Loss D: -0.2488\n",
      "Epoch 528, Loss G: -0.8141,Loss D:  0.0899\n",
      "Epoch 529, Loss G: -0.8283,Loss D:  0.0258\n",
      "Epoch 530, Loss G: -0.9733,Loss D:  0.0627\n",
      "Epoch 531, Loss G: -0.7382,Loss D: -0.3572\n",
      "Epoch 532, Loss G: -0.7754,Loss D:  0.1299\n",
      "Epoch 533, Loss G: -0.4427,Loss D: -0.1541\n",
      "Epoch 534, Loss G: -0.7207,Loss D: -0.2189\n",
      "Epoch 535, Loss G: -0.9383,Loss D: -0.0412\n",
      "Epoch 536, Loss G: -0.9738,Loss D:  0.2206\n",
      "Epoch 537, Loss G: -0.7162,Loss D:  0.0535\n",
      "Epoch 538, Loss G: -0.6927,Loss D:  0.0135\n",
      "Epoch 539, Loss G: -0.7561,Loss D: -0.1106\n",
      "Epoch 540, Loss G: -0.8326,Loss D: -0.1534\n",
      "Epoch 541, Loss G: -0.7934,Loss D: -0.1503\n",
      "Epoch 542, Loss G: -0.9768,Loss D:  0.3190\n",
      "Epoch 543, Loss G: -1.1102,Loss D: -0.3970\n",
      "Epoch 544, Loss G: -0.9562,Loss D: -0.0265\n",
      "Epoch 545, Loss G: -0.9092,Loss D: -0.0286\n",
      "Epoch 546, Loss G: -0.5926,Loss D:  0.0846\n",
      "Epoch 547, Loss G: -0.8444,Loss D: -0.0153\n",
      "Epoch 548, Loss G: -0.7414,Loss D: -0.2136\n",
      "Epoch 549, Loss G: -0.8183,Loss D: -0.0872\n",
      "Epoch 550, Loss G: -1.2370,Loss D: -0.1160\n",
      "Epoch 551, Loss G: -1.0040,Loss D:  0.2267\n",
      "Epoch 552, Loss G: -0.8936,Loss D: -0.0376\n",
      "Epoch 553, Loss G: -0.6145,Loss D: -0.0849\n",
      "Epoch 554, Loss G: -0.6189,Loss D: -0.2102\n",
      "Epoch 555, Loss G: -0.7561,Loss D:  0.0391\n",
      "Epoch 556, Loss G: -0.9588,Loss D:  0.0972\n",
      "Epoch 557, Loss G: -1.0404,Loss D:  0.0868\n",
      "Epoch 558, Loss G: -0.8923,Loss D: -0.1736\n",
      "Epoch 559, Loss G: -0.8507,Loss D: -0.2169\n",
      "Epoch 560, Loss G: -0.5636,Loss D: -0.1481\n",
      "Epoch 561, Loss G: -0.7650,Loss D:  0.1039\n",
      "Epoch 562, Loss G: -0.9743,Loss D:  0.0950\n",
      "Epoch 563, Loss G: -0.6330,Loss D: -0.0678\n",
      "Epoch 564, Loss G: -1.0409,Loss D:  0.0242\n",
      "Epoch 565, Loss G: -0.6747,Loss D: -0.0827\n",
      "Epoch 566, Loss G: -0.7551,Loss D: -0.1519\n",
      "Epoch 567, Loss G: -0.6429,Loss D: -0.0769\n",
      "Epoch 568, Loss G: -0.3274,Loss D:  0.1064\n",
      "Epoch 569, Loss G: -0.6325,Loss D: -0.1142\n",
      "Epoch 570, Loss G: -0.8584,Loss D: -0.1318\n",
      "Epoch 571, Loss G: -1.0174,Loss D: -0.2170\n",
      "Epoch 572, Loss G: -0.8177,Loss D:  0.1135\n",
      "Epoch 573, Loss G: -0.5418,Loss D:  0.4282\n",
      "Epoch 574, Loss G: -0.8300,Loss D: -0.1516\n",
      "Epoch 575, Loss G: -0.9758,Loss D: -0.2672\n",
      "Epoch 576, Loss G: -0.8283,Loss D:  0.2270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 577, Loss G: -0.6959,Loss D:  0.0384\n",
      "Epoch 578, Loss G: -0.7470,Loss D: -0.0068\n",
      "Epoch 579, Loss G: -0.6599,Loss D:  0.0938\n",
      "Epoch 580, Loss G: -0.7343,Loss D:  0.2095\n",
      "Epoch 581, Loss G: -0.6759,Loss D: -0.2643\n",
      "Epoch 582, Loss G: -0.7185,Loss D: -0.1454\n",
      "Epoch 583, Loss G: -0.7753,Loss D: -0.2972\n",
      "Epoch 584, Loss G: -0.6775,Loss D: -0.1719\n",
      "Epoch 585, Loss G: -0.6803,Loss D: -0.0258\n",
      "Epoch 586, Loss G: -0.4093,Loss D: -0.0688\n",
      "Epoch 587, Loss G: -0.6418,Loss D:  0.1312\n",
      "Epoch 588, Loss G: -0.7087,Loss D: -0.1366\n",
      "Epoch 589, Loss G: -0.5831,Loss D:  0.0458\n",
      "Epoch 590, Loss G: -0.9809,Loss D: -0.0111\n",
      "Epoch 591, Loss G: -0.8647,Loss D:  0.0781\n",
      "Epoch 592, Loss G: -0.6297,Loss D: -0.1498\n",
      "Epoch 593, Loss G: -0.5177,Loss D: -0.0003\n",
      "Epoch 594, Loss G: -0.8794,Loss D:  0.0148\n",
      "Epoch 595, Loss G: -0.5140,Loss D: -0.1012\n",
      "Epoch 596, Loss G: -0.6064,Loss D: -0.2534\n",
      "Epoch 597, Loss G: -0.7355,Loss D: -0.3513\n",
      "Epoch 598, Loss G: -0.6906,Loss D: -0.0831\n",
      "Epoch 599, Loss G: -0.7183,Loss D:  0.1184\n",
      "Epoch 600, Loss G: -0.5485,Loss D: -0.2265\n",
      "Epoch 601, Loss G: -0.6572,Loss D: -0.3307\n",
      "Epoch 602, Loss G: -0.7036,Loss D: -0.0750\n",
      "Epoch 603, Loss G: -0.7470,Loss D: -0.2042\n",
      "Epoch 604, Loss G: -0.3252,Loss D: -0.0611\n",
      "Epoch 605, Loss G: -0.2414,Loss D: -0.0382\n",
      "Epoch 606, Loss G: -0.3945,Loss D: -0.1718\n",
      "Epoch 607, Loss G: -0.5318,Loss D: -0.1386\n",
      "Epoch 608, Loss G: -0.7780,Loss D: -0.1359\n",
      "Epoch 609, Loss G: -0.3182,Loss D: -0.0720\n",
      "Epoch 610, Loss G: -0.0917,Loss D: -0.0506\n",
      "Epoch 611, Loss G: -0.4341,Loss D: -0.2424\n",
      "Epoch 612, Loss G: -0.7401,Loss D: -0.1555\n",
      "Epoch 613, Loss G: -0.4945,Loss D: -0.1958\n",
      "Epoch 614, Loss G: -0.5309,Loss D: -0.2142\n",
      "Epoch 615, Loss G: -0.5722,Loss D:  0.0369\n",
      "Epoch 616, Loss G: -0.8571,Loss D: -0.4821\n",
      "Epoch 617, Loss G: -0.2769,Loss D: -0.1486\n",
      "Epoch 618, Loss G: -0.3297,Loss D:  0.1117\n",
      "Epoch 619, Loss G: -0.3010,Loss D: -0.2736\n",
      "Epoch 620, Loss G: -0.6081,Loss D:  0.0769\n",
      "Epoch 621, Loss G: -0.5188,Loss D:  0.0656\n",
      "Epoch 622, Loss G: -0.4829,Loss D: -0.2054\n",
      "Epoch 623, Loss G: -0.6161,Loss D: -0.0454\n",
      "Epoch 624, Loss G: -0.5989,Loss D:  0.0378\n",
      "Epoch 625, Loss G: -0.9452,Loss D: -0.0830\n",
      "Epoch 626, Loss G: -0.6334,Loss D: -0.1068\n",
      "Epoch 627, Loss G: -0.7700,Loss D: -0.0293\n",
      "Epoch 628, Loss G: -0.8627,Loss D: -0.2134\n",
      "Epoch 629, Loss G: -0.8462,Loss D: -0.2223\n",
      "Epoch 630, Loss G: -0.8151,Loss D: -0.1679\n",
      "Epoch 631, Loss G: -0.7689,Loss D:  0.1778\n",
      "Epoch 632, Loss G: -0.8555,Loss D:  0.1495\n",
      "Epoch 633, Loss G: -0.7412,Loss D:  0.0021\n",
      "Epoch 634, Loss G: -0.7539,Loss D: -0.0364\n",
      "Epoch 635, Loss G: -1.3026,Loss D:  0.1692\n",
      "Epoch 636, Loss G: -0.9533,Loss D: -0.0148\n",
      "Epoch 637, Loss G: -0.5477,Loss D: -0.3227\n",
      "Epoch 638, Loss G: -0.7680,Loss D:  0.1265\n",
      "Epoch 639, Loss G: -0.8616,Loss D: -0.1427\n",
      "Epoch 640, Loss G: -0.9584,Loss D: -0.4282\n",
      "Epoch 641, Loss G: -0.8314,Loss D: -0.0802\n",
      "Epoch 642, Loss G: -0.5527,Loss D:  0.0005\n",
      "Epoch 643, Loss G: -0.7770,Loss D:  0.0306\n",
      "Epoch 644, Loss G: -0.4643,Loss D:  0.0577\n",
      "Epoch 645, Loss G: -0.7358,Loss D: -0.0633\n",
      "Epoch 646, Loss G: -0.7020,Loss D: -0.1603\n",
      "Epoch 647, Loss G: -0.9210,Loss D:  0.0747\n",
      "Epoch 648, Loss G: -0.7785,Loss D:  0.1736\n",
      "Epoch 649, Loss G: -0.9348,Loss D:  0.1153\n",
      "Epoch 650, Loss G: -0.6147,Loss D:  0.0664\n",
      "Epoch 651, Loss G: -0.9095,Loss D: -0.1507\n",
      "Epoch 652, Loss G: -0.7063,Loss D: -0.0943\n",
      "Epoch 653, Loss G: -0.6723,Loss D:  0.3449\n",
      "Epoch 654, Loss G: -0.5161,Loss D: -0.0059\n",
      "Epoch 655, Loss G: -0.9670,Loss D: -0.1591\n",
      "Epoch 656, Loss G: -0.7810,Loss D:  0.1147\n",
      "Epoch 657, Loss G: -0.8597,Loss D:  0.1052\n",
      "Epoch 658, Loss G: -1.0384,Loss D: -0.3729\n",
      "Epoch 659, Loss G: -0.8504,Loss D:  0.0549\n",
      "Epoch 660, Loss G: -0.5306,Loss D: -0.0967\n",
      "Epoch 661, Loss G: -0.5354,Loss D: -0.0080\n",
      "Epoch 662, Loss G: -0.8690,Loss D:  0.1660\n",
      "Epoch 663, Loss G: -0.9496,Loss D: -0.0994\n",
      "Epoch 664, Loss G: -0.8091,Loss D: -0.2043\n",
      "Epoch 665, Loss G: -0.8876,Loss D:  0.1892\n",
      "Epoch 666, Loss G: -0.8190,Loss D:  0.1054\n",
      "Epoch 667, Loss G: -0.6719,Loss D: -0.0348\n",
      "Epoch 668, Loss G: -0.9244,Loss D: -0.0295\n",
      "Epoch 669, Loss G: -0.9292,Loss D:  0.0412\n",
      "Epoch 670, Loss G: -0.8043,Loss D: -0.1589\n",
      "Epoch 671, Loss G: -1.1110,Loss D: -0.1448\n",
      "Epoch 672, Loss G: -0.9617,Loss D: -0.2009\n",
      "Epoch 673, Loss G: -0.7108,Loss D: -0.2832\n",
      "Epoch 674, Loss G: -0.8905,Loss D: -0.0194\n",
      "Epoch 675, Loss G: -1.3065,Loss D: -0.0437\n",
      "Epoch 676, Loss G: -1.3374,Loss D: -0.0539\n",
      "Epoch 677, Loss G: -1.2836,Loss D:  0.1611\n",
      "Epoch 678, Loss G: -0.6784,Loss D:  0.3606\n",
      "Epoch 679, Loss G: -0.9356,Loss D:  0.1933\n",
      "Epoch 680, Loss G: -0.9926,Loss D:  0.0710\n",
      "Epoch 681, Loss G: -1.0631,Loss D: -0.1897\n",
      "Epoch 682, Loss G: -1.0025,Loss D:  0.0943\n",
      "Epoch 683, Loss G: -1.0915,Loss D:  0.4417\n",
      "Epoch 684, Loss G: -0.7575,Loss D:  0.0765\n",
      "Epoch 685, Loss G: -0.6056,Loss D:  0.0496\n",
      "Epoch 686, Loss G: -0.6881,Loss D: -0.0492\n",
      "Epoch 687, Loss G: -0.8846,Loss D:  0.2798\n",
      "Epoch 688, Loss G: -1.0760,Loss D: -0.1739\n",
      "Epoch 689, Loss G: -1.0135,Loss D:  0.0759\n",
      "Epoch 690, Loss G: -0.8689,Loss D:  0.0404\n",
      "Epoch 691, Loss G: -0.8045,Loss D: -0.1705\n",
      "Epoch 692, Loss G: -0.7685,Loss D: -0.0215\n",
      "Epoch 693, Loss G: -0.9369,Loss D: -0.2318\n",
      "Epoch 694, Loss G: -0.7484,Loss D: -0.0184\n",
      "Epoch 695, Loss G: -0.7385,Loss D: -0.1395\n",
      "Epoch 696, Loss G: -0.6027,Loss D:  0.1364\n",
      "Epoch 697, Loss G: -0.4349,Loss D: -0.3125\n",
      "Epoch 698, Loss G: -1.0719,Loss D: -0.1326\n",
      "Epoch 699, Loss G: -0.7520,Loss D: -0.1557\n",
      "Epoch 700, Loss G: -0.5900,Loss D:  0.0663\n",
      "Epoch 701, Loss G: -0.7249,Loss D: -0.4348\n",
      "Epoch 702, Loss G: -0.5251,Loss D:  0.0413\n",
      "Epoch 703, Loss G: -0.8312,Loss D: -0.1065\n",
      "Epoch 704, Loss G: -0.9666,Loss D: -0.0074\n",
      "Epoch 705, Loss G: -0.6344,Loss D: -0.2467\n",
      "Epoch 706, Loss G: -0.7983,Loss D:  0.0087\n",
      "Epoch 707, Loss G: -0.6447,Loss D: -0.1690\n",
      "Epoch 708, Loss G: -0.9896,Loss D: -0.1095\n",
      "Epoch 709, Loss G: -0.9634,Loss D: -0.0882\n",
      "Epoch 710, Loss G: -1.0883,Loss D:  0.2481\n",
      "Epoch 711, Loss G: -1.2155,Loss D: -0.2356\n",
      "Epoch 712, Loss G: -0.9631,Loss D: -0.1589\n",
      "Epoch 713, Loss G: -0.8195,Loss D:  0.1132\n",
      "Epoch 714, Loss G: -0.6637,Loss D:  0.0328\n",
      "Epoch 715, Loss G: -0.8685,Loss D: -0.1644\n",
      "Epoch 716, Loss G: -0.8628,Loss D:  0.0843\n",
      "Epoch 717, Loss G: -0.8554,Loss D: -0.0743\n",
      "Epoch 718, Loss G: -0.8094,Loss D: -0.0645\n",
      "Epoch 719, Loss G: -0.3556,Loss D: -0.0829\n",
      "Epoch 720, Loss G: -0.5635,Loss D:  0.2124\n",
      "Epoch 721, Loss G: -1.0938,Loss D: -0.3737\n",
      "Epoch 722, Loss G: -1.0518,Loss D: -0.1454\n",
      "Epoch 723, Loss G: -0.7495,Loss D: -0.1613\n",
      "Epoch 724, Loss G: -0.6005,Loss D: -0.0365\n",
      "Epoch 725, Loss G: -0.4787,Loss D:  0.0908\n",
      "Epoch 726, Loss G: -0.6192,Loss D: -0.2779\n",
      "Epoch 727, Loss G: -1.0185,Loss D: -0.0160\n",
      "Epoch 728, Loss G: -0.7171,Loss D: -0.0804\n",
      "Epoch 729, Loss G: -0.6701,Loss D:  0.0671\n",
      "Epoch 730, Loss G: -0.8215,Loss D:  0.0823\n",
      "Epoch 731, Loss G: -0.5418,Loss D: -0.0306\n",
      "Epoch 732, Loss G: -0.5139,Loss D: -0.1485\n",
      "Epoch 733, Loss G: -0.4577,Loss D: -0.1471\n",
      "Epoch 734, Loss G: -0.6350,Loss D:  0.3284\n",
      "Epoch 735, Loss G: -0.1909,Loss D: -0.1034\n",
      "Epoch 736, Loss G: -0.7036,Loss D: -0.0376\n",
      "Epoch 737, Loss G: -0.8105,Loss D:  0.1075\n",
      "Epoch 738, Loss G: -0.9164,Loss D:  0.0240\n",
      "Epoch 739, Loss G: -0.6080,Loss D:  0.1325\n",
      "Epoch 740, Loss G: -0.6249,Loss D:  0.2697\n",
      "Epoch 741, Loss G: -0.5407,Loss D: -0.0011\n",
      "Epoch 742, Loss G: -0.7481,Loss D:  0.0639\n",
      "Epoch 743, Loss G: -0.2405,Loss D:  0.2741\n",
      "Epoch 744, Loss G: -0.1667,Loss D: -0.1830\n",
      "Epoch 745, Loss G: -0.5480,Loss D: -0.0889\n",
      "Epoch 746, Loss G: -0.3638,Loss D: -0.2534\n",
      "Epoch 747, Loss G: -0.6309,Loss D:  0.0611\n",
      "Epoch 748, Loss G: -0.6366,Loss D: -0.2556\n",
      "Epoch 749, Loss G: -0.4171,Loss D: -0.1068\n",
      "Epoch 750, Loss G: -0.5604,Loss D: -0.0148\n",
      "Epoch 751, Loss G: -0.7619,Loss D: -0.3034\n",
      "Epoch 752, Loss G: -1.1123,Loss D:  0.2755\n",
      "Epoch 753, Loss G: -1.0475,Loss D:  0.2306\n",
      "Epoch 754, Loss G: -0.8555,Loss D:  0.0073\n",
      "Epoch 755, Loss G: -0.8127,Loss D: -0.1558\n",
      "Epoch 756, Loss G: -0.5332,Loss D: -0.1643\n",
      "Epoch 757, Loss G: -0.8185,Loss D:  0.0598\n",
      "Epoch 758, Loss G: -0.7282,Loss D: -0.2121\n",
      "Epoch 759, Loss G: -0.8535,Loss D: -0.1490\n",
      "Epoch 760, Loss G: -0.7047,Loss D: -0.0797\n",
      "Epoch 761, Loss G: -0.7157,Loss D: -0.1567\n",
      "Epoch 762, Loss G: -0.6957,Loss D: -0.2136\n",
      "Epoch 763, Loss G: -0.4497,Loss D:  0.0046\n",
      "Epoch 764, Loss G: -0.6856,Loss D: -0.1918\n",
      "Epoch 765, Loss G: -0.7555,Loss D: -0.2224\n",
      "Epoch 766, Loss G: -0.6261,Loss D: -0.1190\n",
      "Epoch 767, Loss G: -0.5476,Loss D: -0.0339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 768, Loss G: -0.7085,Loss D:  0.1543\n",
      "Epoch 769, Loss G: -0.6388,Loss D: -0.0695\n",
      "Epoch 770, Loss G: -0.8773,Loss D: -0.1946\n",
      "Epoch 771, Loss G: -0.6586,Loss D:  0.0626\n",
      "Epoch 772, Loss G: -0.5175,Loss D: -0.2256\n",
      "Epoch 773, Loss G: -0.8443,Loss D: -0.1296\n",
      "Epoch 774, Loss G: -0.6700,Loss D:  0.0693\n",
      "Epoch 775, Loss G: -0.8204,Loss D:  0.0750\n",
      "Epoch 776, Loss G: -0.6883,Loss D: -0.0266\n",
      "Epoch 777, Loss G: -0.8823,Loss D: -0.0127\n",
      "Epoch 778, Loss G: -0.6443,Loss D: -0.1214\n",
      "Epoch 779, Loss G: -0.5713,Loss D: -0.0693\n",
      "Epoch 780, Loss G: -0.6566,Loss D: -0.0736\n",
      "Epoch 781, Loss G: -0.5815,Loss D: -0.2373\n",
      "Epoch 782, Loss G: -0.7682,Loss D:  0.4461\n",
      "Epoch 783, Loss G: -0.9001,Loss D: -0.0793\n",
      "Epoch 784, Loss G: -0.6937,Loss D: -0.1968\n",
      "Epoch 785, Loss G: -0.7038,Loss D: -0.0586\n",
      "Epoch 786, Loss G: -0.6348,Loss D: -0.0425\n",
      "Epoch 787, Loss G: -0.7741,Loss D:  0.0924\n",
      "Epoch 788, Loss G: -0.8608,Loss D:  0.1227\n",
      "Epoch 789, Loss G: -1.2876,Loss D:  0.0047\n",
      "Epoch 790, Loss G: -1.1228,Loss D: -0.0101\n",
      "Epoch 791, Loss G: -0.6930,Loss D:  0.0605\n",
      "Epoch 792, Loss G: -0.6430,Loss D: -0.1429\n",
      "Epoch 793, Loss G: -0.9452,Loss D: -0.2249\n",
      "Epoch 794, Loss G: -0.8049,Loss D: -0.0600\n",
      "Epoch 795, Loss G: -0.7561,Loss D: -0.1506\n",
      "Epoch 796, Loss G: -1.1377,Loss D:  0.0187\n",
      "Epoch 797, Loss G: -1.3289,Loss D: -0.2063\n",
      "Epoch 798, Loss G: -1.2305,Loss D: -0.1760\n",
      "Epoch 799, Loss G: -0.8934,Loss D: -0.0119\n",
      "Epoch 800, Loss G: -0.8822,Loss D: -0.1515\n",
      "Epoch 801, Loss G: -0.8576,Loss D: -0.0191\n",
      "Epoch 802, Loss G: -0.9972,Loss D:  0.1714\n",
      "Epoch 803, Loss G: -0.9282,Loss D: -0.0519\n",
      "Epoch 804, Loss G: -0.8193,Loss D: -0.0628\n",
      "Epoch 805, Loss G: -0.8586,Loss D:  0.0014\n",
      "Epoch 806, Loss G: -0.8645,Loss D: -0.0467\n",
      "Epoch 807, Loss G: -0.8574,Loss D:  0.0132\n",
      "Epoch 808, Loss G: -0.8364,Loss D: -0.1607\n",
      "Epoch 809, Loss G: -0.7698,Loss D: -0.0475\n",
      "Epoch 810, Loss G: -0.7367,Loss D:  0.2106\n",
      "Epoch 811, Loss G: -1.0022,Loss D: -0.1450\n",
      "Epoch 812, Loss G: -0.9872,Loss D:  0.0864\n",
      "Epoch 813, Loss G: -0.9077,Loss D: -0.0619\n",
      "Epoch 814, Loss G: -0.7542,Loss D:  0.1474\n",
      "Epoch 815, Loss G: -0.9133,Loss D: -0.0619\n",
      "Epoch 816, Loss G: -0.7794,Loss D: -0.1017\n",
      "Epoch 817, Loss G: -0.8571,Loss D: -0.2560\n",
      "Epoch 818, Loss G: -1.0767,Loss D: -0.0147\n",
      "Epoch 819, Loss G: -1.0687,Loss D:  0.1123\n",
      "Epoch 820, Loss G: -1.1806,Loss D:  0.0526\n",
      "Epoch 821, Loss G: -1.1162,Loss D: -0.0310\n",
      "Epoch 822, Loss G: -0.9542,Loss D: -0.0075\n",
      "Epoch 823, Loss G: -0.9472,Loss D: -0.1689\n",
      "Epoch 824, Loss G: -0.8295,Loss D: -0.0391\n",
      "Epoch 825, Loss G: -0.8453,Loss D:  0.0891\n",
      "Epoch 826, Loss G: -0.8868,Loss D: -0.1030\n",
      "Epoch 827, Loss G: -1.0877,Loss D: -0.0648\n",
      "Epoch 828, Loss G: -1.1222,Loss D: -0.1617\n",
      "Epoch 829, Loss G: -0.9425,Loss D: -0.0761\n",
      "Epoch 830, Loss G: -0.7475,Loss D: -0.0423\n",
      "Epoch 831, Loss G: -0.7582,Loss D:  0.1250\n",
      "Epoch 832, Loss G: -0.6647,Loss D:  0.1258\n",
      "Epoch 833, Loss G: -1.0404,Loss D: -0.0771\n",
      "Epoch 834, Loss G: -1.1473,Loss D: -0.0048\n",
      "Epoch 835, Loss G: -1.2287,Loss D: -0.0707\n",
      "Epoch 836, Loss G: -1.1059,Loss D: -0.2554\n",
      "Epoch 837, Loss G: -0.8728,Loss D: -0.1474\n",
      "Epoch 838, Loss G: -0.7710,Loss D:  0.1624\n",
      "Epoch 839, Loss G: -0.6915,Loss D: -0.2105\n",
      "Epoch 840, Loss G: -0.7781,Loss D:  0.1492\n",
      "Epoch 841, Loss G: -0.7325,Loss D: -0.0737\n",
      "Epoch 842, Loss G: -1.3006,Loss D:  0.2080\n",
      "Epoch 843, Loss G: -1.2371,Loss D: -0.0661\n",
      "Epoch 844, Loss G: -0.9233,Loss D:  0.0917\n",
      "Epoch 845, Loss G: -0.7193,Loss D: -0.1044\n",
      "Epoch 846, Loss G: -1.0588,Loss D:  0.0180\n",
      "Epoch 847, Loss G: -1.2633,Loss D: -0.0587\n",
      "Epoch 848, Loss G: -1.3645,Loss D: -0.0034\n",
      "Epoch 849, Loss G: -1.2084,Loss D:  0.1357\n",
      "Epoch 850, Loss G: -1.2489,Loss D: -0.3642\n",
      "Epoch 851, Loss G: -1.1303,Loss D:  0.0030\n",
      "Epoch 852, Loss G: -1.0579,Loss D: -0.1385\n",
      "Epoch 853, Loss G: -0.9941,Loss D:  0.0085\n",
      "Epoch 854, Loss G: -0.8842,Loss D: -0.0831\n",
      "Epoch 855, Loss G: -1.2715,Loss D:  0.0308\n",
      "Epoch 856, Loss G: -1.4504,Loss D:  0.0189\n",
      "Epoch 857, Loss G: -1.1147,Loss D: -0.0123\n",
      "Epoch 858, Loss G: -1.0548,Loss D: -0.1816\n",
      "Epoch 859, Loss G: -1.0563,Loss D: -0.1769\n",
      "Epoch 860, Loss G: -1.0658,Loss D: -0.0917\n",
      "Epoch 861, Loss G: -0.8832,Loss D:  0.0566\n",
      "Epoch 862, Loss G: -1.2477,Loss D: -0.0131\n",
      "Epoch 863, Loss G: -1.2368,Loss D:  0.0792\n",
      "Epoch 864, Loss G: -1.0575,Loss D:  0.0487\n",
      "Epoch 865, Loss G: -1.1741,Loss D:  0.0448\n",
      "Epoch 866, Loss G: -1.0774,Loss D: -0.0337\n",
      "Epoch 867, Loss G: -1.0681,Loss D:  0.1241\n",
      "Epoch 868, Loss G: -1.2181,Loss D: -0.0753\n",
      "Epoch 869, Loss G: -1.3469,Loss D:  0.0640\n",
      "Epoch 870, Loss G: -1.0423,Loss D:  0.0027\n",
      "Epoch 871, Loss G: -1.1320,Loss D:  0.1768\n",
      "Epoch 872, Loss G: -1.1846,Loss D: -0.0629\n",
      "Epoch 873, Loss G: -1.0971,Loss D:  0.0232\n",
      "Epoch 874, Loss G: -1.2039,Loss D:  0.0604\n",
      "Epoch 875, Loss G: -1.3130,Loss D:  0.0277\n",
      "Epoch 876, Loss G: -1.0637,Loss D:  0.0734\n",
      "Epoch 877, Loss G: -1.1943,Loss D: -0.1491\n",
      "Epoch 878, Loss G: -1.0792,Loss D:  0.1163\n",
      "Epoch 879, Loss G: -1.0510,Loss D: -0.0699\n",
      "Epoch 880, Loss G: -1.2583,Loss D:  0.1251\n",
      "Epoch 881, Loss G: -1.1138,Loss D:  0.1299\n",
      "Epoch 882, Loss G: -1.4263,Loss D: -0.3334\n",
      "Epoch 883, Loss G: -1.2723,Loss D: -0.1508\n",
      "Epoch 884, Loss G: -1.1021,Loss D:  0.0411\n",
      "Epoch 885, Loss G: -1.1325,Loss D: -0.0346\n",
      "Epoch 886, Loss G: -1.0892,Loss D: -0.0200\n",
      "Epoch 887, Loss G: -1.3367,Loss D: -0.0886\n",
      "Epoch 888, Loss G: -1.1501,Loss D: -0.0115\n",
      "Epoch 889, Loss G: -1.3217,Loss D: -0.1906\n",
      "Epoch 890, Loss G: -1.3253,Loss D:  0.0666\n",
      "Epoch 891, Loss G: -1.2448,Loss D:  0.0027\n",
      "Epoch 892, Loss G: -1.1411,Loss D:  0.1284\n",
      "Epoch 893, Loss G: -1.3539,Loss D:  0.0437\n",
      "Epoch 894, Loss G: -1.1986,Loss D: -0.0784\n",
      "Epoch 895, Loss G: -1.3174,Loss D: -0.0858\n",
      "Epoch 896, Loss G: -1.3532,Loss D:  0.1090\n",
      "Epoch 897, Loss G: -1.2690,Loss D: -0.0398\n",
      "Epoch 898, Loss G: -1.2519,Loss D: -0.0525\n",
      "Epoch 899, Loss G: -1.2296,Loss D: -0.0524\n",
      "Epoch 900, Loss G: -1.4804,Loss D: -0.0109\n",
      "Epoch 901, Loss G: -1.3627,Loss D: -0.1437\n",
      "Epoch 902, Loss G: -1.5134,Loss D:  0.1376\n",
      "Epoch 903, Loss G: -1.3180,Loss D:  0.1315\n",
      "Epoch 904, Loss G: -1.1474,Loss D: -0.1046\n",
      "Epoch 905, Loss G: -1.2018,Loss D:  0.2037\n",
      "Epoch 906, Loss G: -1.3040,Loss D:  0.0183\n",
      "Epoch 907, Loss G: -1.4950,Loss D:  0.0093\n",
      "Epoch 908, Loss G: -1.5300,Loss D: -0.1451\n",
      "Epoch 909, Loss G: -1.4229,Loss D:  0.1846\n",
      "Epoch 910, Loss G: -1.2836,Loss D: -0.0979\n",
      "Epoch 911, Loss G: -1.2078,Loss D:  0.0061\n",
      "Epoch 912, Loss G: -1.0354,Loss D: -0.1852\n",
      "Epoch 913, Loss G: -1.1458,Loss D: -0.0387\n",
      "Epoch 914, Loss G: -0.8941,Loss D:  0.0194\n",
      "Epoch 915, Loss G: -1.2140,Loss D: -0.0489\n",
      "Epoch 916, Loss G: -1.2839,Loss D: -0.2004\n",
      "Epoch 917, Loss G: -1.2623,Loss D:  0.0066\n",
      "Epoch 918, Loss G: -0.9092,Loss D:  0.1702\n",
      "Epoch 919, Loss G: -0.6604,Loss D: -0.1214\n",
      "Epoch 920, Loss G: -1.0388,Loss D:  0.1189\n",
      "Epoch 921, Loss G: -0.8654,Loss D: -0.1195\n",
      "Epoch 922, Loss G: -1.0217,Loss D: -0.0003\n",
      "Epoch 923, Loss G: -0.8692,Loss D: -0.0699\n",
      "Epoch 924, Loss G: -0.6306,Loss D: -0.2879\n",
      "Epoch 925, Loss G: -0.7992,Loss D: -0.2265\n",
      "Epoch 926, Loss G: -1.0938,Loss D:  0.1257\n",
      "Epoch 927, Loss G: -1.1369,Loss D: -0.0880\n",
      "Epoch 928, Loss G: -1.2713,Loss D: -0.0192\n",
      "Epoch 929, Loss G: -0.8558,Loss D:  0.0724\n",
      "Epoch 930, Loss G: -0.7586,Loss D:  0.0020\n",
      "Epoch 931, Loss G: -0.8786,Loss D: -0.0266\n",
      "Epoch 932, Loss G: -1.1498,Loss D: -0.1574\n",
      "Epoch 933, Loss G: -1.3463,Loss D: -0.0839\n",
      "Epoch 934, Loss G: -1.2707,Loss D:  0.0456\n",
      "Epoch 935, Loss G: -1.3360,Loss D:  0.0374\n",
      "Epoch 936, Loss G: -1.0785,Loss D:  0.1490\n",
      "Epoch 937, Loss G: -0.6742,Loss D:  0.0955\n",
      "Epoch 938, Loss G: -1.2257,Loss D:  0.0255\n",
      "Epoch 939, Loss G: -1.1161,Loss D: -0.0542\n",
      "Epoch 940, Loss G: -1.4071,Loss D:  0.1348\n",
      "Epoch 941, Loss G: -1.5143,Loss D: -0.0569\n",
      "Epoch 942, Loss G: -1.0221,Loss D: -0.2433\n",
      "Epoch 943, Loss G: -1.0497,Loss D: -0.2752\n",
      "Epoch 944, Loss G: -1.2051,Loss D: -0.1339\n",
      "Epoch 945, Loss G: -1.1032,Loss D: -0.1175\n",
      "Epoch 946, Loss G: -1.2860,Loss D:  0.1592\n",
      "Epoch 947, Loss G: -1.4173,Loss D: -0.1160\n",
      "Epoch 948, Loss G: -1.2631,Loss D: -0.0149\n",
      "Epoch 949, Loss G: -1.1717,Loss D: -0.2252\n",
      "Epoch 950, Loss G: -1.0926,Loss D: -0.1123\n",
      "Epoch 951, Loss G: -1.2501,Loss D: -0.1964\n",
      "Epoch 952, Loss G: -1.3223,Loss D: -0.1011\n",
      "Epoch 953, Loss G: -1.2576,Loss D: -0.1524\n",
      "Epoch 954, Loss G: -1.0144,Loss D: -0.1835\n",
      "Epoch 955, Loss G: -0.9597,Loss D:  0.0116\n",
      "Epoch 956, Loss G: -0.8098,Loss D: -0.2713\n",
      "Epoch 957, Loss G: -0.9365,Loss D: -0.2371\n",
      "Epoch 958, Loss G: -1.0547,Loss D: -0.1052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 959, Loss G: -1.0650,Loss D: -0.1295\n",
      "Epoch 960, Loss G: -1.0062,Loss D:  0.0947\n",
      "Epoch 961, Loss G: -0.8254,Loss D: -0.3014\n",
      "Epoch 962, Loss G: -0.9839,Loss D:  0.1955\n",
      "Epoch 963, Loss G: -0.7913,Loss D:  0.0978\n",
      "Epoch 964, Loss G: -0.8883,Loss D: -0.1831\n",
      "Epoch 965, Loss G: -1.1874,Loss D: -0.1912\n",
      "Epoch 966, Loss G: -1.2684,Loss D: -0.2500\n",
      "Epoch 967, Loss G: -1.5281,Loss D: -0.0451\n",
      "Epoch 968, Loss G: -1.1028,Loss D: -0.0722\n",
      "Epoch 969, Loss G: -0.8787,Loss D:  0.1010\n",
      "Epoch 970, Loss G: -0.8333,Loss D:  0.0484\n",
      "Epoch 971, Loss G: -0.9467,Loss D: -0.1290\n",
      "Epoch 972, Loss G: -1.0436,Loss D: -0.1978\n",
      "Epoch 973, Loss G: -1.1014,Loss D: -0.0542\n",
      "Epoch 974, Loss G: -0.9574,Loss D: -0.1723\n",
      "Epoch 975, Loss G: -1.1253,Loss D: -0.1772\n",
      "Epoch 976, Loss G: -1.0274,Loss D: -0.1818\n",
      "Epoch 977, Loss G: -0.8541,Loss D: -0.0369\n",
      "Epoch 978, Loss G: -0.9807,Loss D: -0.0027\n",
      "Epoch 979, Loss G: -1.0477,Loss D:  0.1745\n",
      "Epoch 980, Loss G: -0.7736,Loss D:  0.0452\n",
      "Epoch 981, Loss G: -0.8210,Loss D:  0.1545\n",
      "Epoch 982, Loss G: -0.9365,Loss D: -0.0778\n",
      "Epoch 983, Loss G: -0.7512,Loss D: -0.3806\n",
      "Epoch 984, Loss G: -0.9217,Loss D:  0.0352\n",
      "Epoch 985, Loss G: -0.8206,Loss D: -0.0763\n",
      "Epoch 986, Loss G: -0.7409,Loss D: -0.0625\n",
      "Epoch 987, Loss G: -1.2509,Loss D: -0.0021\n",
      "Epoch 988, Loss G: -1.2190,Loss D:  0.0740\n",
      "Epoch 989, Loss G: -1.1697,Loss D: -0.0663\n",
      "Epoch 990, Loss G: -1.0302,Loss D: -0.0890\n",
      "Epoch 991, Loss G: -0.8018,Loss D:  0.1022\n",
      "Epoch 992, Loss G: -0.8264,Loss D: -0.2842\n",
      "Epoch 993, Loss G: -1.0614,Loss D:  0.1231\n",
      "Epoch 994, Loss G: -1.0651,Loss D: -0.1429\n",
      "Epoch 995, Loss G: -1.1308,Loss D: -0.0468\n",
      "Epoch 996, Loss G: -0.9919,Loss D:  0.0984\n",
      "Epoch 997, Loss G: -0.8971,Loss D: -0.0341\n",
      "Epoch 998, Loss G: -0.7564,Loss D: -0.4983\n",
      "Epoch 999, Loss G: -0.5074,Loss D: -0.0060\n",
      "Epoch 1000, Loss G: -0.6982,Loss D: -0.1988\n",
      "Wall time: 15min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ctgan.fit(df, discrete_columns, epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctgan.save(output_folder + 'trained.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
