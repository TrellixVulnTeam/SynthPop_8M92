{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gael/Applications/anaconda/lib/python3.8/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.utils.testing module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.utils. Anything that cannot be imported from sklearn.utils is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from ctgan import CTGANSynthesizer\n",
    "\n",
    "# For the Python notebook\n",
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/Chicago/full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>choice</th>\n",
       "      <th>travel_dow</th>\n",
       "      <th>trip_purpose</th>\n",
       "      <th>distance</th>\n",
       "      <th>hh_vehicles</th>\n",
       "      <th>hh_size</th>\n",
       "      <th>hh_bikes</th>\n",
       "      <th>hh_descr</th>\n",
       "      <th>hh_income</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>license</th>\n",
       "      <th>education_level</th>\n",
       "      <th>work_status</th>\n",
       "      <th>departure_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>drive</td>\n",
       "      <td>7</td>\n",
       "      <td>HOME_OTHER</td>\n",
       "      <td>23.42579</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>FTE</td>\n",
       "      <td>9.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>drive</td>\n",
       "      <td>7</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>1.71259</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>FTE</td>\n",
       "      <td>12.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>drive</td>\n",
       "      <td>7</td>\n",
       "      <td>HOME_OTHER</td>\n",
       "      <td>21.77887</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>FTE</td>\n",
       "      <td>15.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>drive</td>\n",
       "      <td>7</td>\n",
       "      <td>SHOPPING</td>\n",
       "      <td>2.02603</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>FTE</td>\n",
       "      <td>17.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>drive</td>\n",
       "      <td>7</td>\n",
       "      <td>SHOPPING</td>\n",
       "      <td>0.87691</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>FTE</td>\n",
       "      <td>18.250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  choice  travel_dow trip_purpose  distance  hh_vehicles  hh_size  hh_bikes  \\\n",
       "0  drive           7   HOME_OTHER  23.42579            2        2         0   \n",
       "1  drive           7        OTHER   1.71259            2        2         0   \n",
       "2  drive           7   HOME_OTHER  21.77887            2        2         0   \n",
       "3  drive           7     SHOPPING   2.02603            2        2         0   \n",
       "4  drive           7     SHOPPING   0.87691            2        2         0   \n",
       "\n",
       "   hh_descr  hh_income  gender  age  license  education_level work_status  \\\n",
       "0         2          6       1   66      1.0                6         FTE   \n",
       "1         2          6       1   66      1.0                6         FTE   \n",
       "2         2          6       1   66      1.0                6         FTE   \n",
       "3         2          6       1   66      1.0                6         FTE   \n",
       "4         2          6       1   66      1.0                6         FTE   \n",
       "\n",
       "   departure_time  \n",
       "0        9.333333  \n",
       "1       12.083333  \n",
       "2       15.500000  \n",
       "3       17.500000  \n",
       "4       18.250000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_columns = [\n",
    "    'choice',\n",
    "    'travel_dow',\n",
    "    'trip_purpose',\n",
    "    'hh_vehicles',\n",
    "    'hh_size',\n",
    "    'hh_bikes',\n",
    "    'hh_descr',\n",
    "    'hh_income',\n",
    "    'gender',\n",
    "    'license',\n",
    "    'education_level',\n",
    "    'work_status'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = './output_CTGAN/output/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gael/Applications/anaconda/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "ctgan = CTGANSynthesizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gael/Applications/anaconda/lib/python3.8/site-packages/sklearn/utils/validation.py:68: FutureWarning: Pass n_components=10 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "/home/gael/Applications/anaconda/lib/python3.8/site-packages/sklearn/utils/validation.py:68: FutureWarning: Pass n_components=10 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "/home/gael/Applications/anaconda/lib/python3.8/site-packages/sklearn/utils/validation.py:68: FutureWarning: Pass n_components=10 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss G: 0.3233, Loss D: -0.1176\n",
      "Epoch 2, Loss G: -0.4900, Loss D: -0.0574\n",
      "Epoch 3, Loss G: -1.0804, Loss D: -0.0385\n",
      "Epoch 4, Loss G: -0.8359, Loss D: -0.1887\n",
      "Epoch 5, Loss G: -1.0863, Loss D: -0.3240\n",
      "Epoch 6, Loss G: -0.8474, Loss D: 0.0151\n",
      "Epoch 7, Loss G: -1.0632, Loss D: -0.0593\n",
      "Epoch 8, Loss G: -0.8252, Loss D: -0.0665\n",
      "Epoch 9, Loss G: -1.2780, Loss D: -0.1498\n",
      "Epoch 10, Loss G: -0.9891, Loss D: 0.0390\n",
      "Epoch 11, Loss G: -1.1584, Loss D: -0.1613\n",
      "Epoch 12, Loss G: -1.1218, Loss D: -0.0759\n",
      "Epoch 13, Loss G: -1.0901, Loss D: -0.1151\n",
      "Epoch 14, Loss G: -1.0229, Loss D: -0.1129\n",
      "Epoch 15, Loss G: -1.1649, Loss D: -0.0664\n",
      "Epoch 16, Loss G: -0.8710, Loss D: -0.1789\n",
      "Epoch 17, Loss G: -0.8548, Loss D: -0.1209\n",
      "Epoch 18, Loss G: -0.8577, Loss D: -0.3294\n",
      "Epoch 19, Loss G: -0.6990, Loss D: -0.3976\n",
      "Epoch 20, Loss G: -0.6208, Loss D: -0.0642\n",
      "Epoch 21, Loss G: -0.8559, Loss D: -0.2855\n",
      "Epoch 22, Loss G: -0.9393, Loss D: 0.0282\n",
      "Epoch 23, Loss G: -0.7635, Loss D: -0.1057\n",
      "Epoch 24, Loss G: -1.0396, Loss D: 0.1906\n",
      "Epoch 25, Loss G: -0.9112, Loss D: -0.0536\n",
      "Epoch 26, Loss G: -0.7738, Loss D: -0.1078\n",
      "Epoch 27, Loss G: -0.8910, Loss D: -0.0542\n",
      "Epoch 28, Loss G: -0.7511, Loss D: -0.0422\n",
      "Epoch 29, Loss G: -0.8508, Loss D: 0.0174\n",
      "Epoch 30, Loss G: -0.7616, Loss D: -0.0103\n",
      "Epoch 31, Loss G: -1.2169, Loss D: -0.0657\n",
      "Epoch 32, Loss G: -0.8974, Loss D: -0.0515\n",
      "Epoch 33, Loss G: -1.0566, Loss D: -0.0360\n",
      "Epoch 34, Loss G: -0.8689, Loss D: 0.0363\n",
      "Epoch 35, Loss G: -1.3579, Loss D: 0.0036\n",
      "Epoch 36, Loss G: -1.0660, Loss D: -0.1060\n",
      "Epoch 37, Loss G: -0.9155, Loss D: 0.0114\n",
      "Epoch 38, Loss G: -0.6392, Loss D: -0.0938\n",
      "Epoch 39, Loss G: -0.9858, Loss D: -0.3228\n",
      "Epoch 40, Loss G: -1.5017, Loss D: 0.0443\n",
      "Epoch 41, Loss G: -1.2742, Loss D: -0.2681\n",
      "Epoch 42, Loss G: -1.4089, Loss D: -0.2833\n",
      "Epoch 43, Loss G: -1.1871, Loss D: -0.1961\n",
      "Epoch 44, Loss G: -0.8386, Loss D: -0.0654\n",
      "Epoch 45, Loss G: -1.0878, Loss D: 0.0382\n",
      "Epoch 46, Loss G: -1.3545, Loss D: -0.0320\n",
      "Epoch 47, Loss G: -1.0933, Loss D: 0.0204\n",
      "Epoch 48, Loss G: -1.3449, Loss D: -0.1066\n",
      "Epoch 49, Loss G: -1.1376, Loss D: -0.0180\n",
      "Epoch 50, Loss G: -1.1408, Loss D: -0.0911\n",
      "Epoch 51, Loss G: -0.8821, Loss D: 0.0173\n",
      "Epoch 52, Loss G: -0.9072, Loss D: -0.0719\n",
      "Epoch 53, Loss G: -1.0566, Loss D: 0.0205\n",
      "Epoch 54, Loss G: -0.8044, Loss D: -0.2209\n",
      "Epoch 55, Loss G: -1.0065, Loss D: -0.0834\n",
      "Epoch 56, Loss G: -0.7456, Loss D: -0.2185\n",
      "Epoch 57, Loss G: -1.0120, Loss D: -0.0304\n",
      "Epoch 58, Loss G: -1.1862, Loss D: 0.1532\n",
      "Epoch 59, Loss G: -0.7848, Loss D: -0.0875\n",
      "Epoch 60, Loss G: -0.8668, Loss D: 0.0003\n",
      "Epoch 61, Loss G: -0.8495, Loss D: -0.1641\n",
      "Epoch 62, Loss G: -0.9666, Loss D: 0.0352\n",
      "Epoch 63, Loss G: -0.9132, Loss D: -0.2953\n",
      "Epoch 64, Loss G: -0.8654, Loss D: -0.2635\n",
      "Epoch 65, Loss G: -0.9999, Loss D: -0.1894\n",
      "Epoch 66, Loss G: -1.0820, Loss D: -0.2433\n",
      "Epoch 67, Loss G: -1.0312, Loss D: -0.2037\n",
      "Epoch 68, Loss G: -1.1327, Loss D: -0.0656\n",
      "Epoch 69, Loss G: -0.6846, Loss D: -0.0381\n",
      "Epoch 70, Loss G: -1.1313, Loss D: 0.1058\n",
      "Epoch 71, Loss G: -0.7873, Loss D: -0.1127\n",
      "Epoch 72, Loss G: -1.0481, Loss D: -0.0347\n",
      "Epoch 73, Loss G: -1.0243, Loss D: 0.1847\n",
      "Epoch 74, Loss G: -0.9421, Loss D: -0.0478\n",
      "Epoch 75, Loss G: -0.7058, Loss D: -0.1626\n",
      "Epoch 76, Loss G: -0.9952, Loss D: -0.0942\n",
      "Epoch 77, Loss G: -0.9486, Loss D: 0.0451\n",
      "Epoch 78, Loss G: -0.8692, Loss D: -0.1481\n",
      "Epoch 79, Loss G: -0.9779, Loss D: -0.0434\n",
      "Epoch 80, Loss G: -0.8400, Loss D: 0.0395\n",
      "Epoch 81, Loss G: -0.8562, Loss D: -0.2083\n",
      "Epoch 82, Loss G: -0.8812, Loss D: -0.1425\n",
      "Epoch 83, Loss G: -0.9035, Loss D: 0.0509\n",
      "Epoch 84, Loss G: -0.9049, Loss D: -0.2359\n",
      "Epoch 85, Loss G: -0.4383, Loss D: -0.1484\n",
      "Epoch 86, Loss G: -0.7308, Loss D: -0.0576\n",
      "Epoch 87, Loss G: -0.7061, Loss D: 0.1826\n",
      "Epoch 88, Loss G: -0.7926, Loss D: 0.2232\n",
      "Epoch 89, Loss G: -0.7993, Loss D: 0.0879\n",
      "Epoch 90, Loss G: -0.8983, Loss D: -0.0785\n",
      "Epoch 91, Loss G: -0.8960, Loss D: -0.1944\n",
      "Epoch 92, Loss G: -1.1888, Loss D: 0.2392\n",
      "Epoch 93, Loss G: -1.1536, Loss D: -0.0842\n",
      "Epoch 94, Loss G: -1.1533, Loss D: 0.0483\n",
      "Epoch 95, Loss G: -0.4597, Loss D: -0.0284\n",
      "Epoch 96, Loss G: -0.9500, Loss D: -0.0815\n",
      "Epoch 97, Loss G: -0.7945, Loss D: -0.0315\n",
      "Epoch 98, Loss G: -1.0626, Loss D: -0.2267\n",
      "Epoch 99, Loss G: -0.7091, Loss D: -0.1317\n",
      "Epoch 100, Loss G: -0.8796, Loss D: -0.1223\n",
      "Epoch 101, Loss G: -0.7213, Loss D: -0.0210\n",
      "Epoch 102, Loss G: -1.0684, Loss D: -0.1545\n",
      "Epoch 103, Loss G: -1.0531, Loss D: -0.2240\n",
      "Epoch 104, Loss G: -0.8718, Loss D: -0.2077\n",
      "Epoch 105, Loss G: -0.6601, Loss D: 0.0592\n",
      "Epoch 106, Loss G: -1.7588, Loss D: 0.0501\n",
      "Epoch 107, Loss G: -0.9640, Loss D: 0.0225\n",
      "Epoch 108, Loss G: -0.6012, Loss D: 0.2285\n",
      "Epoch 109, Loss G: -0.6096, Loss D: 0.0464\n",
      "Epoch 110, Loss G: -1.1924, Loss D: -0.0271\n",
      "Epoch 111, Loss G: -1.1572, Loss D: 0.2077\n",
      "Epoch 112, Loss G: -1.2174, Loss D: -0.2086\n",
      "Epoch 113, Loss G: -1.2606, Loss D: 0.0284\n",
      "Epoch 114, Loss G: -1.0404, Loss D: -0.2839\n",
      "Epoch 115, Loss G: -0.8723, Loss D: -0.3025\n",
      "Epoch 116, Loss G: -0.9316, Loss D: -0.1520\n",
      "Epoch 117, Loss G: -0.6424, Loss D: -0.1611\n",
      "Epoch 118, Loss G: -0.7879, Loss D: -0.0380\n",
      "Epoch 119, Loss G: -0.9813, Loss D: -0.0950\n",
      "Epoch 120, Loss G: -0.6249, Loss D: -0.1090\n",
      "Epoch 121, Loss G: -0.7350, Loss D: 0.3240\n",
      "Epoch 122, Loss G: -0.5279, Loss D: 0.0010\n",
      "Epoch 123, Loss G: -0.7340, Loss D: 0.1493\n",
      "Epoch 124, Loss G: -0.7395, Loss D: -0.2561\n",
      "Epoch 125, Loss G: -0.8146, Loss D: -0.1878\n",
      "Epoch 126, Loss G: -1.0807, Loss D: -0.0258\n",
      "Epoch 127, Loss G: -1.0862, Loss D: -0.1387\n",
      "Epoch 128, Loss G: -0.7690, Loss D: 0.0153\n",
      "Epoch 129, Loss G: -0.8980, Loss D: -0.1502\n",
      "Epoch 130, Loss G: -0.6464, Loss D: -0.0303\n",
      "Epoch 131, Loss G: -0.4836, Loss D: 0.1644\n",
      "Epoch 132, Loss G: -1.1898, Loss D: -0.1443\n",
      "Epoch 133, Loss G: -0.5364, Loss D: -0.0876\n",
      "Epoch 134, Loss G: -0.7370, Loss D: 0.0134\n",
      "Epoch 135, Loss G: -0.9337, Loss D: 0.0390\n",
      "Epoch 136, Loss G: -0.9047, Loss D: 0.2556\n",
      "Epoch 137, Loss G: -0.9983, Loss D: -0.1070\n",
      "Epoch 138, Loss G: -1.0783, Loss D: 0.0011\n",
      "Epoch 139, Loss G: -0.8361, Loss D: -0.1687\n",
      "Epoch 140, Loss G: -0.4047, Loss D: -0.3076\n",
      "Epoch 141, Loss G: -0.6293, Loss D: 0.1032\n",
      "Epoch 142, Loss G: -0.6462, Loss D: 0.1160\n",
      "Epoch 143, Loss G: -0.7393, Loss D: -0.1247\n",
      "Epoch 144, Loss G: -1.3385, Loss D: -0.0694\n",
      "Epoch 145, Loss G: -1.1072, Loss D: 0.0236\n",
      "Epoch 146, Loss G: -0.9863, Loss D: -0.3250\n",
      "Epoch 147, Loss G: -1.2815, Loss D: -0.0769\n",
      "Epoch 148, Loss G: -1.3734, Loss D: 0.0071\n",
      "Epoch 149, Loss G: -1.2569, Loss D: 0.0671\n",
      "Epoch 150, Loss G: -1.2072, Loss D: -0.0153\n",
      "Epoch 151, Loss G: -0.7975, Loss D: -0.1116\n",
      "Epoch 152, Loss G: -0.9599, Loss D: -0.0336\n",
      "Epoch 153, Loss G: -1.0574, Loss D: -0.3423\n",
      "Epoch 154, Loss G: -0.8986, Loss D: -0.1149\n",
      "Epoch 155, Loss G: -1.0983, Loss D: -0.0811\n",
      "Epoch 156, Loss G: -0.9808, Loss D: 0.2335\n",
      "Epoch 157, Loss G: -1.6041, Loss D: 0.1597\n",
      "Epoch 158, Loss G: -1.0997, Loss D: 0.1365\n",
      "Epoch 159, Loss G: -1.0029, Loss D: 0.0236\n",
      "Epoch 160, Loss G: -0.9169, Loss D: 0.1312\n",
      "Epoch 161, Loss G: -1.2839, Loss D: -0.1833\n",
      "Epoch 162, Loss G: -0.7309, Loss D: -0.1127\n",
      "Epoch 163, Loss G: -0.8460, Loss D: 0.0954\n",
      "Epoch 164, Loss G: -1.5268, Loss D: -0.1554\n",
      "Epoch 165, Loss G: -0.9975, Loss D: 0.1280\n",
      "Epoch 166, Loss G: -1.0310, Loss D: -0.1121\n",
      "Epoch 167, Loss G: -1.2043, Loss D: -0.1785\n",
      "Epoch 168, Loss G: -1.0904, Loss D: -0.1012\n",
      "Epoch 169, Loss G: -1.3703, Loss D: 0.1342\n",
      "Epoch 170, Loss G: -1.4494, Loss D: -0.2265\n",
      "Epoch 171, Loss G: -1.1757, Loss D: 0.0615\n",
      "Epoch 172, Loss G: -0.9722, Loss D: 0.2666\n",
      "Epoch 173, Loss G: -0.8413, Loss D: 0.1116\n",
      "Epoch 174, Loss G: -1.2629, Loss D: -0.0856\n",
      "Epoch 175, Loss G: -1.1187, Loss D: -0.2186\n",
      "Epoch 176, Loss G: -1.0420, Loss D: -0.0971\n",
      "Epoch 177, Loss G: -1.0510, Loss D: -0.2690\n",
      "Epoch 178, Loss G: -1.3206, Loss D: -0.1112\n",
      "Epoch 179, Loss G: -1.3247, Loss D: 0.0568\n",
      "Epoch 180, Loss G: -1.1286, Loss D: -0.2502\n",
      "Epoch 181, Loss G: -1.3777, Loss D: 0.0933\n",
      "Epoch 182, Loss G: -1.1985, Loss D: 0.0534\n",
      "Epoch 183, Loss G: -0.9222, Loss D: 0.1316\n",
      "Epoch 184, Loss G: -1.0654, Loss D: -0.0252\n",
      "Epoch 185, Loss G: -1.0602, Loss D: -0.0937\n",
      "Epoch 186, Loss G: -1.0659, Loss D: 0.1568\n",
      "Epoch 187, Loss G: -0.5986, Loss D: -0.1760\n",
      "Epoch 188, Loss G: -1.0638, Loss D: 0.0732\n",
      "Epoch 189, Loss G: -1.4028, Loss D: -0.0157\n",
      "Epoch 190, Loss G: -0.9167, Loss D: 0.0382\n",
      "Epoch 191, Loss G: -0.6305, Loss D: 0.0269\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 192, Loss G: -0.9721, Loss D: 0.0992\n",
      "Epoch 193, Loss G: -1.0719, Loss D: -0.0113\n",
      "Epoch 194, Loss G: -1.0678, Loss D: 0.1014\n",
      "Epoch 195, Loss G: -0.9449, Loss D: 0.0175\n",
      "Epoch 196, Loss G: -0.6343, Loss D: 0.1869\n",
      "Epoch 197, Loss G: -0.7190, Loss D: 0.0293\n",
      "Epoch 198, Loss G: -0.7297, Loss D: 0.0359\n",
      "Epoch 199, Loss G: -0.6124, Loss D: -0.1891\n",
      "Epoch 200, Loss G: -0.8297, Loss D: 0.0055\n",
      "Epoch 201, Loss G: -0.5073, Loss D: 0.0676\n",
      "Epoch 202, Loss G: -0.5769, Loss D: 0.3051\n",
      "Epoch 203, Loss G: -0.5741, Loss D: -0.0853\n",
      "Epoch 204, Loss G: -0.6826, Loss D: -0.0849\n",
      "Epoch 205, Loss G: -0.6566, Loss D: -0.0214\n",
      "Epoch 206, Loss G: -0.5234, Loss D: -0.2258\n",
      "Epoch 207, Loss G: -0.6585, Loss D: 0.0441\n",
      "Epoch 208, Loss G: -0.7824, Loss D: -0.1934\n",
      "Epoch 209, Loss G: -0.8083, Loss D: 0.2428\n",
      "Epoch 210, Loss G: -0.7349, Loss D: 0.1000\n",
      "Epoch 211, Loss G: -0.7553, Loss D: -0.0390\n",
      "Epoch 212, Loss G: -0.9082, Loss D: -0.3287\n",
      "Epoch 213, Loss G: -0.4482, Loss D: -0.0246\n",
      "Epoch 214, Loss G: -0.8441, Loss D: -0.1588\n",
      "Epoch 215, Loss G: -1.0937, Loss D: -0.1018\n",
      "Epoch 216, Loss G: -0.8346, Loss D: -0.0502\n",
      "Epoch 217, Loss G: -1.3212, Loss D: -0.0218\n",
      "Epoch 218, Loss G: -1.2892, Loss D: -0.2372\n",
      "Epoch 219, Loss G: -0.8321, Loss D: 0.1897\n",
      "Epoch 220, Loss G: -0.9222, Loss D: 0.1771\n",
      "Epoch 221, Loss G: -1.2604, Loss D: -0.2615\n",
      "Epoch 222, Loss G: -0.7395, Loss D: 0.0764\n",
      "Epoch 223, Loss G: -0.7932, Loss D: 0.3172\n",
      "Epoch 224, Loss G: -0.5214, Loss D: -0.3611\n",
      "Epoch 225, Loss G: -0.9594, Loss D: 0.1742\n",
      "Epoch 226, Loss G: -1.0940, Loss D: -0.0057\n",
      "Epoch 227, Loss G: -1.0518, Loss D: -0.0721\n",
      "Epoch 228, Loss G: -0.9444, Loss D: -0.1108\n",
      "Epoch 229, Loss G: -1.0158, Loss D: -0.0566\n",
      "Epoch 230, Loss G: -1.0981, Loss D: 0.1542\n",
      "Epoch 231, Loss G: -0.9944, Loss D: -0.1536\n",
      "Epoch 232, Loss G: -0.8576, Loss D: 0.0108\n",
      "Epoch 233, Loss G: -1.2978, Loss D: -0.1413\n",
      "Epoch 234, Loss G: -0.9919, Loss D: 0.0441\n",
      "Epoch 235, Loss G: -0.7269, Loss D: -0.0804\n",
      "Epoch 236, Loss G: -0.8121, Loss D: -0.2213\n",
      "Epoch 237, Loss G: -0.5647, Loss D: -0.0326\n",
      "Epoch 238, Loss G: -0.7846, Loss D: -0.0305\n",
      "Epoch 239, Loss G: -0.7885, Loss D: -0.2076\n",
      "Epoch 240, Loss G: -0.9195, Loss D: 0.0165\n",
      "Epoch 241, Loss G: -0.9343, Loss D: -0.1597\n",
      "Epoch 242, Loss G: -0.8669, Loss D: -0.1861\n",
      "Epoch 243, Loss G: -0.6464, Loss D: -0.0332\n",
      "Epoch 244, Loss G: -1.1586, Loss D: 0.0527\n",
      "Epoch 245, Loss G: -1.3855, Loss D: 0.1436\n",
      "Epoch 246, Loss G: -1.0952, Loss D: -0.2965\n",
      "Epoch 247, Loss G: -0.9609, Loss D: 0.0114\n",
      "Epoch 248, Loss G: -0.9684, Loss D: -0.1369\n",
      "Epoch 249, Loss G: -0.7993, Loss D: 0.1610\n",
      "Epoch 250, Loss G: -0.8913, Loss D: 0.0482\n",
      "Epoch 251, Loss G: -1.4278, Loss D: 0.0945\n",
      "Epoch 252, Loss G: -0.5650, Loss D: -0.1252\n",
      "Epoch 253, Loss G: -0.8251, Loss D: -0.0568\n",
      "Epoch 254, Loss G: -0.7454, Loss D: -0.1865\n",
      "Epoch 255, Loss G: -0.6389, Loss D: -0.2099\n",
      "Epoch 256, Loss G: -0.6993, Loss D: 0.2092\n",
      "Epoch 257, Loss G: -0.7285, Loss D: 0.0002\n",
      "Epoch 258, Loss G: -0.7814, Loss D: -0.2731\n",
      "Epoch 259, Loss G: -1.1424, Loss D: -0.2414\n",
      "Epoch 260, Loss G: -0.9701, Loss D: -0.0760\n",
      "Epoch 261, Loss G: -1.1522, Loss D: 0.3921\n",
      "Epoch 262, Loss G: -1.0367, Loss D: 0.1707\n",
      "Epoch 263, Loss G: -0.7739, Loss D: -0.2831\n",
      "Epoch 264, Loss G: -0.4740, Loss D: 0.0270\n",
      "Epoch 265, Loss G: -0.7650, Loss D: -0.1957\n",
      "Epoch 266, Loss G: -0.1520, Loss D: 0.5786\n",
      "Epoch 267, Loss G: -1.1297, Loss D: -0.1848\n",
      "Epoch 268, Loss G: -1.2024, Loss D: 0.0801\n",
      "Epoch 269, Loss G: -0.8715, Loss D: 0.2042\n",
      "Epoch 270, Loss G: -0.5916, Loss D: -0.1028\n",
      "Epoch 271, Loss G: -0.7854, Loss D: 0.1128\n",
      "Epoch 272, Loss G: -1.3315, Loss D: 0.0996\n",
      "Epoch 273, Loss G: -0.6494, Loss D: 0.0494\n",
      "Epoch 274, Loss G: -1.1807, Loss D: -0.2729\n",
      "Epoch 275, Loss G: -0.9478, Loss D: -0.2091\n",
      "Epoch 276, Loss G: -0.6991, Loss D: -0.1348\n",
      "Epoch 277, Loss G: -0.8292, Loss D: -0.1801\n",
      "Epoch 278, Loss G: -1.0627, Loss D: -0.0504\n",
      "Epoch 279, Loss G: -0.9543, Loss D: -0.1456\n",
      "Epoch 280, Loss G: -0.6918, Loss D: 0.1602\n",
      "Epoch 281, Loss G: -0.8429, Loss D: 0.0279\n",
      "Epoch 282, Loss G: -0.8505, Loss D: 0.1849\n",
      "Epoch 283, Loss G: -0.5478, Loss D: 0.0909\n",
      "Epoch 284, Loss G: -0.8477, Loss D: -0.0227\n",
      "Epoch 285, Loss G: -0.5156, Loss D: -0.0875\n",
      "Epoch 286, Loss G: -0.8902, Loss D: 0.0943\n",
      "Epoch 287, Loss G: -0.8600, Loss D: -0.0454\n",
      "Epoch 288, Loss G: -1.0789, Loss D: -0.3278\n",
      "Epoch 289, Loss G: -0.5276, Loss D: 0.1365\n",
      "Epoch 290, Loss G: -1.0840, Loss D: -0.0246\n",
      "Epoch 291, Loss G: -0.9901, Loss D: -0.3163\n",
      "Epoch 292, Loss G: -0.2588, Loss D: -0.1249\n",
      "Epoch 293, Loss G: -0.8085, Loss D: 0.1382\n",
      "Epoch 294, Loss G: -0.9500, Loss D: -0.1885\n",
      "Epoch 295, Loss G: -0.8090, Loss D: 0.0891\n",
      "Epoch 296, Loss G: -0.5292, Loss D: 0.0609\n",
      "Epoch 297, Loss G: -0.6591, Loss D: -0.2777\n",
      "Epoch 298, Loss G: -0.9079, Loss D: 0.2081\n",
      "Epoch 299, Loss G: -0.3273, Loss D: -0.1866\n",
      "Epoch 300, Loss G: -0.6609, Loss D: -0.1968\n",
      "Epoch 301, Loss G: -1.1779, Loss D: 0.1669\n",
      "Epoch 302, Loss G: -1.1658, Loss D: 0.2072\n",
      "Epoch 303, Loss G: -0.7656, Loss D: 0.1072\n",
      "Epoch 304, Loss G: -1.1860, Loss D: -0.0729\n",
      "Epoch 305, Loss G: -1.4147, Loss D: -0.0747\n",
      "Epoch 306, Loss G: -1.2297, Loss D: -0.0013\n",
      "Epoch 307, Loss G: -0.9766, Loss D: -0.1681\n",
      "Epoch 308, Loss G: -1.4449, Loss D: -0.0620\n",
      "Epoch 309, Loss G: -0.8402, Loss D: -0.2441\n",
      "Epoch 310, Loss G: -1.4658, Loss D: -0.1527\n",
      "Epoch 311, Loss G: -1.7325, Loss D: -0.1614\n",
      "Epoch 312, Loss G: -1.3984, Loss D: -0.2526\n",
      "Epoch 313, Loss G: -1.2239, Loss D: 0.1451\n",
      "Epoch 314, Loss G: -1.1194, Loss D: -0.1595\n",
      "Epoch 315, Loss G: -1.3521, Loss D: -0.0880\n",
      "Epoch 316, Loss G: -1.5138, Loss D: 0.0400\n",
      "Epoch 317, Loss G: -1.6266, Loss D: 0.1826\n",
      "Epoch 318, Loss G: -1.3745, Loss D: -0.2331\n",
      "Epoch 319, Loss G: -1.5570, Loss D: -0.0332\n",
      "Epoch 320, Loss G: -1.3566, Loss D: -0.1076\n",
      "Epoch 321, Loss G: -1.2724, Loss D: 0.1151\n",
      "Epoch 322, Loss G: -1.3140, Loss D: -0.1422\n",
      "Epoch 323, Loss G: -1.1831, Loss D: -0.1766\n",
      "Epoch 324, Loss G: -1.3042, Loss D: 0.0133\n",
      "Epoch 325, Loss G: -1.8491, Loss D: 0.0289\n",
      "Epoch 326, Loss G: -1.5023, Loss D: -0.0938\n",
      "Epoch 327, Loss G: -1.3993, Loss D: -0.2205\n",
      "Epoch 328, Loss G: -1.1613, Loss D: 0.1311\n",
      "Epoch 329, Loss G: -1.2984, Loss D: -0.2074\n",
      "Epoch 330, Loss G: -1.3809, Loss D: -0.3494\n",
      "Epoch 331, Loss G: -1.3616, Loss D: -0.1926\n",
      "Epoch 332, Loss G: -1.9660, Loss D: -0.0342\n",
      "Epoch 333, Loss G: -1.5299, Loss D: -0.0918\n",
      "Epoch 334, Loss G: -1.4264, Loss D: 0.1392\n",
      "Epoch 335, Loss G: -1.5856, Loss D: -0.2273\n",
      "Epoch 336, Loss G: -1.4533, Loss D: -0.2783\n",
      "Epoch 337, Loss G: -1.7846, Loss D: -0.2206\n",
      "Epoch 338, Loss G: -1.5556, Loss D: -0.0152\n",
      "Epoch 339, Loss G: -1.1102, Loss D: 0.1816\n",
      "Epoch 340, Loss G: -1.9387, Loss D: -0.1388\n",
      "Epoch 341, Loss G: -1.4966, Loss D: 0.1766\n",
      "Epoch 342, Loss G: -1.2888, Loss D: 0.1377\n",
      "Epoch 343, Loss G: -1.5420, Loss D: 0.0670\n",
      "Epoch 344, Loss G: -1.5371, Loss D: 0.0070\n",
      "Epoch 345, Loss G: -1.4929, Loss D: 0.1558\n",
      "Epoch 346, Loss G: -1.8417, Loss D: -0.1418\n",
      "Epoch 347, Loss G: -1.4428, Loss D: -0.0151\n",
      "Epoch 348, Loss G: -1.7665, Loss D: -0.1382\n",
      "Epoch 349, Loss G: -1.7893, Loss D: -0.1930\n",
      "Epoch 350, Loss G: -1.9705, Loss D: -0.1377\n",
      "Epoch 351, Loss G: -1.3142, Loss D: -0.0878\n",
      "Epoch 352, Loss G: -1.2369, Loss D: -0.0492\n",
      "Epoch 353, Loss G: -1.7306, Loss D: -0.0699\n",
      "Epoch 354, Loss G: -1.6017, Loss D: -0.2695\n",
      "Epoch 355, Loss G: -1.3554, Loss D: -0.2246\n",
      "Epoch 356, Loss G: -1.5359, Loss D: 0.0881\n",
      "Epoch 357, Loss G: -1.8804, Loss D: 0.1899\n",
      "Epoch 358, Loss G: -1.9406, Loss D: 0.0433\n",
      "Epoch 359, Loss G: -1.6332, Loss D: -0.1726\n",
      "Epoch 360, Loss G: -1.2915, Loss D: 0.0497\n",
      "Epoch 361, Loss G: -1.4339, Loss D: -0.0577\n",
      "Epoch 362, Loss G: -1.5773, Loss D: -0.1208\n",
      "Epoch 363, Loss G: -1.2362, Loss D: -0.0127\n",
      "Epoch 364, Loss G: -1.6244, Loss D: -0.2879\n",
      "Epoch 365, Loss G: -1.5580, Loss D: -0.0931\n",
      "Epoch 366, Loss G: -1.2091, Loss D: -0.2695\n",
      "Epoch 367, Loss G: -1.5684, Loss D: -0.0971\n",
      "Epoch 368, Loss G: -1.4323, Loss D: 0.0506\n",
      "Epoch 369, Loss G: -1.7999, Loss D: 0.0556\n",
      "Epoch 370, Loss G: -1.6058, Loss D: 0.0151\n",
      "Epoch 371, Loss G: -1.4433, Loss D: -0.0629\n",
      "Epoch 372, Loss G: -1.4636, Loss D: -0.0109\n",
      "Epoch 373, Loss G: -1.1305, Loss D: -0.1749\n",
      "Epoch 374, Loss G: -1.5113, Loss D: -0.0854\n",
      "Epoch 375, Loss G: -1.6025, Loss D: -0.0254\n",
      "Epoch 376, Loss G: -1.6094, Loss D: 0.0836\n",
      "Epoch 377, Loss G: -1.5311, Loss D: -0.3859\n",
      "Epoch 378, Loss G: -1.5114, Loss D: 0.1717\n",
      "Epoch 379, Loss G: -1.4542, Loss D: -0.0094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 380, Loss G: -1.5354, Loss D: 0.0826\n",
      "Epoch 381, Loss G: -1.3614, Loss D: 0.1847\n",
      "Epoch 382, Loss G: -1.1209, Loss D: 0.1143\n",
      "Epoch 383, Loss G: -1.4137, Loss D: 0.0598\n",
      "Epoch 384, Loss G: -1.3994, Loss D: 0.0129\n",
      "Epoch 385, Loss G: -1.2682, Loss D: 0.0197\n",
      "Epoch 386, Loss G: -1.8371, Loss D: -0.2018\n",
      "Epoch 387, Loss G: -1.2237, Loss D: 0.2539\n",
      "Epoch 388, Loss G: -1.6501, Loss D: -0.0938\n",
      "Epoch 389, Loss G: -1.0928, Loss D: 0.0590\n",
      "Epoch 390, Loss G: -1.5077, Loss D: 0.0660\n",
      "Epoch 391, Loss G: -1.4968, Loss D: -0.2430\n",
      "Epoch 392, Loss G: -1.6310, Loss D: -0.0823\n",
      "Epoch 393, Loss G: -1.2393, Loss D: 0.1263\n",
      "Epoch 394, Loss G: -1.7444, Loss D: -0.0077\n",
      "Epoch 395, Loss G: -0.9451, Loss D: 0.1667\n",
      "Epoch 396, Loss G: -1.1943, Loss D: -0.1601\n",
      "Epoch 397, Loss G: -1.4551, Loss D: -0.4596\n",
      "Epoch 398, Loss G: -1.0889, Loss D: -0.0089\n",
      "Epoch 399, Loss G: -1.2438, Loss D: -0.0105\n",
      "Epoch 400, Loss G: -1.3391, Loss D: 0.1703\n",
      "Epoch 401, Loss G: -1.3255, Loss D: 0.2399\n",
      "Epoch 402, Loss G: -0.9434, Loss D: -0.4092\n",
      "Epoch 403, Loss G: -1.4675, Loss D: -0.0936\n",
      "Epoch 404, Loss G: -1.4165, Loss D: 0.1495\n",
      "Epoch 405, Loss G: -1.5391, Loss D: 0.4334\n",
      "Epoch 406, Loss G: -1.0976, Loss D: 0.0093\n",
      "Epoch 407, Loss G: -0.7567, Loss D: 0.0233\n",
      "Epoch 408, Loss G: -1.2142, Loss D: 0.0034\n",
      "Epoch 409, Loss G: -1.5959, Loss D: 0.2512\n",
      "Epoch 410, Loss G: -0.9518, Loss D: -0.2815\n",
      "Epoch 411, Loss G: -1.5379, Loss D: 0.1403\n",
      "Epoch 412, Loss G: -1.2496, Loss D: -0.3575\n",
      "Epoch 413, Loss G: -1.2909, Loss D: -0.2157\n",
      "Epoch 414, Loss G: -1.6014, Loss D: -0.4155\n",
      "Epoch 415, Loss G: -1.3982, Loss D: -0.1247\n",
      "Epoch 416, Loss G: -1.1379, Loss D: 0.2183\n",
      "Epoch 417, Loss G: -1.2403, Loss D: -0.1519\n",
      "Epoch 418, Loss G: -1.2159, Loss D: 0.1321\n",
      "Epoch 419, Loss G: -1.1683, Loss D: 0.1955\n",
      "Epoch 420, Loss G: -1.0826, Loss D: -0.1652\n",
      "Epoch 421, Loss G: -0.8614, Loss D: 0.0318\n",
      "Epoch 422, Loss G: -0.7056, Loss D: -0.0251\n",
      "Epoch 423, Loss G: -0.9209, Loss D: -0.3639\n",
      "Epoch 424, Loss G: -0.4854, Loss D: 0.0177\n",
      "Epoch 425, Loss G: -1.3563, Loss D: 0.1493\n",
      "Epoch 426, Loss G: -1.0028, Loss D: -0.1827\n",
      "Epoch 427, Loss G: -1.1105, Loss D: -0.0826\n",
      "Epoch 428, Loss G: -1.2477, Loss D: -0.2576\n",
      "Epoch 429, Loss G: -1.3395, Loss D: -0.0198\n",
      "Epoch 430, Loss G: -1.0641, Loss D: 0.0097\n",
      "Epoch 431, Loss G: -0.5352, Loss D: -0.3396\n",
      "Epoch 432, Loss G: -1.2692, Loss D: 0.2388\n",
      "Epoch 433, Loss G: -1.2517, Loss D: -0.1113\n",
      "Epoch 434, Loss G: -1.4108, Loss D: 0.1552\n",
      "Epoch 435, Loss G: -0.7886, Loss D: 0.1112\n",
      "Epoch 436, Loss G: -0.4440, Loss D: -0.0514\n",
      "Epoch 437, Loss G: -1.0773, Loss D: 0.0684\n",
      "Epoch 438, Loss G: -1.2620, Loss D: -0.0316\n",
      "Epoch 439, Loss G: -1.1762, Loss D: -0.0786\n",
      "Epoch 440, Loss G: -1.1318, Loss D: 0.0189\n",
      "Epoch 441, Loss G: -1.5217, Loss D: -0.2772\n",
      "Epoch 442, Loss G: -1.0679, Loss D: -0.0064\n",
      "Epoch 443, Loss G: -1.0665, Loss D: -0.0610\n",
      "Epoch 444, Loss G: -1.0698, Loss D: -0.0712\n",
      "Epoch 445, Loss G: -1.2749, Loss D: 0.2214\n",
      "Epoch 446, Loss G: -1.0710, Loss D: -0.0065\n",
      "Epoch 447, Loss G: -1.0101, Loss D: -0.2831\n",
      "Epoch 448, Loss G: -1.2827, Loss D: 0.1745\n",
      "Epoch 449, Loss G: -0.6567, Loss D: -0.0179\n",
      "Epoch 450, Loss G: -0.9464, Loss D: -0.3703\n",
      "Epoch 451, Loss G: -1.6589, Loss D: 0.4828\n",
      "Epoch 452, Loss G: -1.0139, Loss D: 0.1685\n",
      "Epoch 453, Loss G: -1.0801, Loss D: -0.0349\n",
      "Epoch 454, Loss G: -1.1704, Loss D: -0.0557\n",
      "Epoch 455, Loss G: -0.9896, Loss D: 0.0937\n",
      "Epoch 456, Loss G: -1.0715, Loss D: -0.0050\n",
      "Epoch 457, Loss G: -1.4845, Loss D: -0.2429\n",
      "Epoch 458, Loss G: -0.7567, Loss D: -0.0367\n",
      "Epoch 459, Loss G: -1.1718, Loss D: -0.0121\n",
      "Epoch 460, Loss G: -1.4716, Loss D: -0.0852\n",
      "Epoch 461, Loss G: -1.3550, Loss D: 0.1497\n",
      "Epoch 462, Loss G: -1.3281, Loss D: 0.0907\n",
      "Epoch 463, Loss G: -0.7941, Loss D: 0.1608\n",
      "Epoch 464, Loss G: -0.9403, Loss D: 0.0185\n",
      "Epoch 465, Loss G: -1.2226, Loss D: 0.0442\n",
      "Epoch 466, Loss G: -0.8298, Loss D: -0.1326\n",
      "Epoch 467, Loss G: -0.8776, Loss D: 0.4654\n",
      "Epoch 468, Loss G: -1.1137, Loss D: 0.0435\n",
      "Epoch 469, Loss G: -0.7855, Loss D: -0.1565\n",
      "Epoch 470, Loss G: -0.7803, Loss D: -0.0192\n",
      "Epoch 471, Loss G: -1.0001, Loss D: -0.0341\n",
      "Epoch 472, Loss G: -1.3656, Loss D: -0.0892\n",
      "Epoch 473, Loss G: -0.8514, Loss D: 0.2586\n",
      "Epoch 474, Loss G: -0.9767, Loss D: -0.0415\n",
      "Epoch 475, Loss G: -1.0121, Loss D: -0.3806\n",
      "Epoch 476, Loss G: -0.7721, Loss D: 0.1703\n",
      "Epoch 477, Loss G: -0.9748, Loss D: -0.4132\n",
      "Epoch 478, Loss G: -0.8052, Loss D: -0.0327\n",
      "Epoch 479, Loss G: -0.8697, Loss D: -0.3571\n",
      "Epoch 480, Loss G: 0.0808, Loss D: -0.1743\n",
      "Epoch 481, Loss G: -0.9987, Loss D: -0.0030\n",
      "Epoch 482, Loss G: -1.3144, Loss D: -0.0363\n",
      "Epoch 483, Loss G: -0.3242, Loss D: -0.2610\n",
      "Epoch 484, Loss G: -0.6495, Loss D: -0.0376\n",
      "Epoch 485, Loss G: -0.7011, Loss D: 0.1246\n",
      "Epoch 486, Loss G: -1.0897, Loss D: -0.3612\n",
      "Epoch 487, Loss G: -0.7836, Loss D: -0.1097\n",
      "Epoch 488, Loss G: -1.1292, Loss D: -0.2257\n",
      "Epoch 489, Loss G: -0.8798, Loss D: -0.2897\n",
      "Epoch 490, Loss G: -0.7237, Loss D: -0.0585\n",
      "Epoch 491, Loss G: -1.5559, Loss D: -0.0947\n",
      "Epoch 492, Loss G: -0.9347, Loss D: 0.0281\n",
      "Epoch 493, Loss G: -0.9951, Loss D: -0.2934\n",
      "Epoch 494, Loss G: -1.0142, Loss D: -0.1206\n",
      "Epoch 495, Loss G: -0.6619, Loss D: -0.0038\n",
      "Epoch 496, Loss G: -0.6716, Loss D: -0.0484\n",
      "Epoch 497, Loss G: -0.7954, Loss D: -0.2420\n",
      "Epoch 498, Loss G: -0.9386, Loss D: 0.0303\n",
      "Epoch 499, Loss G: -0.7029, Loss D: 0.1960\n",
      "Epoch 500, Loss G: -1.1795, Loss D: -0.0451\n",
      "Epoch 501, Loss G: -1.1781, Loss D: 0.0185\n",
      "Epoch 502, Loss G: -1.2037, Loss D: -0.3815\n",
      "Epoch 503, Loss G: -0.9086, Loss D: -0.0051\n",
      "Epoch 504, Loss G: -1.0740, Loss D: 0.1870\n",
      "Epoch 505, Loss G: -0.8358, Loss D: -0.0665\n",
      "Epoch 506, Loss G: -0.4691, Loss D: 0.0100\n",
      "Epoch 507, Loss G: -0.9248, Loss D: -0.1545\n",
      "Epoch 508, Loss G: -0.4454, Loss D: 0.0585\n",
      "Epoch 509, Loss G: -0.6346, Loss D: 0.2668\n",
      "Epoch 510, Loss G: -0.7336, Loss D: 0.0261\n",
      "Epoch 511, Loss G: -1.0352, Loss D: -0.3340\n",
      "Epoch 512, Loss G: -0.5685, Loss D: -0.2459\n",
      "Epoch 513, Loss G: -0.3388, Loss D: -0.0288\n",
      "Epoch 514, Loss G: -0.9277, Loss D: 0.0191\n",
      "Epoch 515, Loss G: -0.6838, Loss D: -0.1661\n",
      "Epoch 516, Loss G: -0.8639, Loss D: 0.0244\n",
      "Epoch 517, Loss G: -0.3929, Loss D: 0.2268\n",
      "Epoch 518, Loss G: -0.3118, Loss D: -0.1242\n",
      "Epoch 519, Loss G: -0.6518, Loss D: -0.1127\n",
      "Epoch 520, Loss G: -0.1789, Loss D: -0.2230\n",
      "Epoch 521, Loss G: -0.3747, Loss D: -0.2541\n",
      "Epoch 522, Loss G: -0.1511, Loss D: 0.0339\n",
      "Epoch 523, Loss G: -0.3009, Loss D: -0.0461\n",
      "Epoch 524, Loss G: -0.3617, Loss D: -0.0297\n",
      "Epoch 525, Loss G: -0.3880, Loss D: -0.1856\n",
      "Epoch 526, Loss G: -0.2864, Loss D: -0.2838\n",
      "Epoch 527, Loss G: -0.4897, Loss D: 0.3054\n",
      "Epoch 528, Loss G: -0.2454, Loss D: -0.0186\n",
      "Epoch 529, Loss G: -0.3155, Loss D: 0.0243\n",
      "Epoch 530, Loss G: -0.5220, Loss D: 0.0198\n",
      "Epoch 531, Loss G: -1.1900, Loss D: -0.1196\n",
      "Epoch 532, Loss G: -0.2299, Loss D: 0.1069\n",
      "Epoch 533, Loss G: -0.6912, Loss D: -0.2219\n",
      "Epoch 534, Loss G: -0.4468, Loss D: -0.0870\n",
      "Epoch 535, Loss G: -0.8124, Loss D: -0.0300\n",
      "Epoch 536, Loss G: -0.6289, Loss D: -0.1221\n",
      "Epoch 537, Loss G: -1.0103, Loss D: -0.0672\n",
      "Epoch 538, Loss G: -0.4645, Loss D: 0.0396\n",
      "Epoch 539, Loss G: -0.7914, Loss D: -0.0045\n",
      "Epoch 540, Loss G: -0.6811, Loss D: 0.0355\n",
      "Epoch 541, Loss G: -0.4729, Loss D: -0.0422\n",
      "Epoch 542, Loss G: -0.7116, Loss D: 0.0129\n",
      "Epoch 543, Loss G: -0.1539, Loss D: -0.0635\n",
      "Epoch 544, Loss G: -0.6760, Loss D: -0.1547\n",
      "Epoch 545, Loss G: -0.7311, Loss D: -0.0369\n",
      "Epoch 546, Loss G: -0.5484, Loss D: -0.0636\n",
      "Epoch 547, Loss G: -0.6170, Loss D: 0.3781\n",
      "Epoch 548, Loss G: -0.4017, Loss D: -0.1236\n",
      "Epoch 549, Loss G: 0.0317, Loss D: -0.2215\n",
      "Epoch 550, Loss G: -0.3957, Loss D: 0.0263\n",
      "Epoch 551, Loss G: -0.7078, Loss D: -0.4170\n",
      "Epoch 552, Loss G: -0.4984, Loss D: -0.2025\n",
      "Epoch 553, Loss G: -0.3764, Loss D: -0.1143\n",
      "Epoch 554, Loss G: -0.6588, Loss D: -0.1564\n",
      "Epoch 555, Loss G: -0.4773, Loss D: -0.1646\n",
      "Epoch 556, Loss G: -0.4503, Loss D: -0.2916\n",
      "Epoch 557, Loss G: -0.9209, Loss D: -0.1973\n",
      "Epoch 558, Loss G: -0.5941, Loss D: -0.0965\n",
      "Epoch 559, Loss G: -0.2080, Loss D: -0.1355\n",
      "Epoch 560, Loss G: -0.3282, Loss D: 0.2272\n",
      "Epoch 561, Loss G: -0.6267, Loss D: 0.1181\n",
      "Epoch 562, Loss G: -0.7667, Loss D: -0.0686\n",
      "Epoch 563, Loss G: -0.3659, Loss D: 0.1414\n",
      "Epoch 564, Loss G: -0.6353, Loss D: 0.0965\n",
      "Epoch 565, Loss G: -0.7314, Loss D: 0.0195\n",
      "Epoch 566, Loss G: -0.6324, Loss D: 0.1540\n",
      "Epoch 567, Loss G: -0.4670, Loss D: 0.0981\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 568, Loss G: -0.6226, Loss D: 0.1311\n",
      "Epoch 569, Loss G: -0.6193, Loss D: 0.0114\n",
      "Epoch 570, Loss G: 0.0793, Loss D: 0.1983\n",
      "Epoch 571, Loss G: -0.4885, Loss D: 0.2588\n",
      "Epoch 572, Loss G: -0.2618, Loss D: -0.1385\n",
      "Epoch 573, Loss G: -0.5747, Loss D: 0.0840\n",
      "Epoch 574, Loss G: -0.7633, Loss D: 0.1394\n",
      "Epoch 575, Loss G: -0.1967, Loss D: 0.2375\n",
      "Epoch 576, Loss G: -0.4620, Loss D: -0.0103\n",
      "Epoch 577, Loss G: -0.4336, Loss D: 0.0392\n",
      "Epoch 578, Loss G: -0.6505, Loss D: 0.0106\n",
      "Epoch 579, Loss G: -0.7766, Loss D: -0.0112\n",
      "Epoch 580, Loss G: -0.4575, Loss D: -0.1185\n",
      "Epoch 581, Loss G: -0.3069, Loss D: 0.0396\n",
      "Epoch 582, Loss G: -0.6254, Loss D: 0.0483\n",
      "Epoch 583, Loss G: -0.5183, Loss D: -0.0206\n",
      "Epoch 584, Loss G: -0.7855, Loss D: 0.0505\n",
      "Epoch 585, Loss G: -0.4607, Loss D: -0.1794\n",
      "Epoch 586, Loss G: -0.7401, Loss D: -0.0489\n",
      "Epoch 587, Loss G: -0.1697, Loss D: 0.0814\n",
      "Epoch 588, Loss G: -0.6219, Loss D: -0.0813\n",
      "Epoch 589, Loss G: -0.5448, Loss D: -0.2289\n",
      "Epoch 590, Loss G: -0.6106, Loss D: 0.2045\n",
      "Epoch 591, Loss G: -0.6620, Loss D: 0.2316\n",
      "Epoch 592, Loss G: -0.1079, Loss D: 0.1899\n",
      "Epoch 593, Loss G: -0.1114, Loss D: 0.3242\n",
      "Epoch 594, Loss G: -0.6637, Loss D: 0.0932\n",
      "Epoch 595, Loss G: -0.7713, Loss D: 0.1596\n",
      "Epoch 596, Loss G: -0.7050, Loss D: 0.0664\n",
      "Epoch 597, Loss G: -0.9406, Loss D: -0.1585\n",
      "Epoch 598, Loss G: -0.8660, Loss D: 0.3368\n",
      "Epoch 599, Loss G: -1.0619, Loss D: -0.3582\n",
      "Epoch 600, Loss G: -0.8151, Loss D: -0.0736\n",
      "Epoch 601, Loss G: -0.8439, Loss D: 0.1927\n",
      "Epoch 602, Loss G: -0.8176, Loss D: 0.2833\n",
      "Epoch 603, Loss G: -0.7258, Loss D: 0.2505\n",
      "Epoch 604, Loss G: -0.9438, Loss D: 0.1532\n",
      "Epoch 605, Loss G: -0.6027, Loss D: 0.2208\n",
      "Epoch 606, Loss G: -0.4008, Loss D: -0.1995\n",
      "Epoch 607, Loss G: -1.3035, Loss D: 0.2244\n",
      "Epoch 608, Loss G: -0.4688, Loss D: 0.1160\n",
      "Epoch 609, Loss G: -0.4530, Loss D: 0.6693\n",
      "Epoch 610, Loss G: -0.7726, Loss D: -0.1804\n",
      "Epoch 611, Loss G: -0.6502, Loss D: 0.0488\n",
      "Epoch 612, Loss G: -0.3119, Loss D: -0.0112\n",
      "Epoch 613, Loss G: -0.7166, Loss D: -0.5241\n",
      "Epoch 614, Loss G: -0.1971, Loss D: -0.0715\n",
      "Epoch 615, Loss G: -0.7072, Loss D: -0.2088\n",
      "Epoch 616, Loss G: -0.6494, Loss D: -0.1256\n",
      "Epoch 617, Loss G: -0.6893, Loss D: -0.0662\n",
      "Epoch 618, Loss G: -1.0001, Loss D: -0.2487\n",
      "Epoch 619, Loss G: -0.6963, Loss D: -0.1186\n",
      "Epoch 620, Loss G: -0.3874, Loss D: 0.1637\n",
      "Epoch 621, Loss G: -0.1994, Loss D: 0.6211\n",
      "Epoch 622, Loss G: -0.3279, Loss D: -0.3085\n",
      "Epoch 623, Loss G: 0.1238, Loss D: 0.2658\n",
      "Epoch 624, Loss G: -0.6520, Loss D: -0.1018\n",
      "Epoch 625, Loss G: -0.2956, Loss D: 0.1400\n",
      "Epoch 626, Loss G: -0.4271, Loss D: -0.3930\n",
      "Epoch 627, Loss G: -0.5260, Loss D: -0.0652\n",
      "Epoch 628, Loss G: -0.0641, Loss D: -0.2287\n",
      "Epoch 629, Loss G: -0.7022, Loss D: -0.1452\n",
      "Epoch 630, Loss G: -0.1057, Loss D: -0.0211\n",
      "Epoch 631, Loss G: -0.3459, Loss D: 0.1727\n",
      "Epoch 632, Loss G: -0.6480, Loss D: 0.0287\n",
      "Epoch 633, Loss G: -1.0681, Loss D: 0.2120\n",
      "Epoch 634, Loss G: -0.2903, Loss D: -0.3822\n",
      "Epoch 635, Loss G: -0.7386, Loss D: 0.0330\n",
      "Epoch 636, Loss G: -0.9695, Loss D: 0.0607\n",
      "Epoch 637, Loss G: -1.2675, Loss D: 0.1595\n",
      "Epoch 638, Loss G: -0.2223, Loss D: -0.2139\n",
      "Epoch 639, Loss G: -0.7889, Loss D: -0.1680\n",
      "Epoch 640, Loss G: -0.7282, Loss D: -0.2923\n",
      "Epoch 641, Loss G: -0.2959, Loss D: -0.0673\n",
      "Epoch 642, Loss G: -0.7357, Loss D: -0.0716\n",
      "Epoch 643, Loss G: -0.8883, Loss D: -0.3056\n",
      "Epoch 644, Loss G: 0.0396, Loss D: 0.0758\n",
      "Epoch 645, Loss G: -0.3452, Loss D: 0.1856\n",
      "Epoch 646, Loss G: -0.4881, Loss D: 0.3534\n",
      "Epoch 647, Loss G: -0.5856, Loss D: -0.0083\n",
      "Epoch 648, Loss G: -0.2310, Loss D: -0.0184\n",
      "Epoch 649, Loss G: -0.0573, Loss D: 0.1098\n",
      "Epoch 650, Loss G: -0.2220, Loss D: 0.1049\n",
      "Epoch 651, Loss G: -0.4592, Loss D: 0.0931\n",
      "Epoch 652, Loss G: 0.0734, Loss D: 0.1169\n",
      "Epoch 653, Loss G: -0.7188, Loss D: 0.0443\n",
      "Epoch 654, Loss G: -0.3090, Loss D: -0.3069\n",
      "Epoch 655, Loss G: -0.3257, Loss D: 0.1716\n",
      "Epoch 656, Loss G: 0.1279, Loss D: 0.2639\n",
      "Epoch 657, Loss G: -0.4948, Loss D: -0.4102\n",
      "Epoch 658, Loss G: -0.2584, Loss D: 0.0124\n",
      "Epoch 659, Loss G: -0.1127, Loss D: 0.3616\n",
      "Epoch 660, Loss G: -0.6705, Loss D: -0.0130\n",
      "Epoch 661, Loss G: -0.3462, Loss D: 0.2089\n",
      "Epoch 662, Loss G: -0.1580, Loss D: 0.1586\n",
      "Epoch 663, Loss G: -0.3580, Loss D: -0.3242\n",
      "Epoch 664, Loss G: -0.7013, Loss D: -0.0214\n",
      "Epoch 665, Loss G: -0.0968, Loss D: -0.4423\n",
      "Epoch 666, Loss G: 0.2218, Loss D: -0.1601\n",
      "Epoch 667, Loss G: -0.5117, Loss D: -0.0703\n",
      "Epoch 668, Loss G: -0.6134, Loss D: 0.0176\n",
      "Epoch 669, Loss G: -1.0986, Loss D: -0.0178\n",
      "Epoch 670, Loss G: -1.1810, Loss D: -0.0801\n",
      "Epoch 671, Loss G: -0.4906, Loss D: -0.0002\n",
      "Epoch 672, Loss G: -0.5520, Loss D: 0.1406\n",
      "Epoch 673, Loss G: -0.6501, Loss D: -0.1838\n",
      "Epoch 674, Loss G: -0.4715, Loss D: -0.1927\n",
      "Epoch 675, Loss G: -0.8556, Loss D: 0.1006\n",
      "Epoch 676, Loss G: -0.4376, Loss D: -0.0575\n",
      "Epoch 677, Loss G: -0.1901, Loss D: -0.3874\n",
      "Epoch 678, Loss G: -0.9001, Loss D: 0.2221\n",
      "Epoch 679, Loss G: -0.5643, Loss D: -0.0796\n",
      "Epoch 680, Loss G: -0.3585, Loss D: -0.2634\n",
      "Epoch 681, Loss G: -0.4894, Loss D: 0.1438\n",
      "Epoch 682, Loss G: -0.6420, Loss D: 0.0327\n",
      "Epoch 683, Loss G: -0.3848, Loss D: -0.0218\n",
      "Epoch 684, Loss G: -0.5708, Loss D: -0.0977\n",
      "Epoch 685, Loss G: -0.8946, Loss D: -0.0092\n",
      "Epoch 686, Loss G: -0.7217, Loss D: -0.3167\n",
      "Epoch 687, Loss G: -0.2788, Loss D: -0.2150\n",
      "Epoch 688, Loss G: -0.7883, Loss D: 0.3174\n",
      "Epoch 689, Loss G: -0.1829, Loss D: -0.1678\n",
      "Epoch 690, Loss G: -0.2491, Loss D: -0.1269\n",
      "Epoch 691, Loss G: -0.7614, Loss D: 0.0043\n",
      "Epoch 692, Loss G: -1.0666, Loss D: 0.0489\n",
      "Epoch 693, Loss G: -0.9333, Loss D: -0.0596\n",
      "Epoch 694, Loss G: -0.6355, Loss D: 0.1810\n",
      "Epoch 695, Loss G: -0.8664, Loss D: -0.1067\n",
      "Epoch 696, Loss G: -0.7736, Loss D: -0.0708\n",
      "Epoch 697, Loss G: -0.7551, Loss D: -0.4195\n",
      "Epoch 698, Loss G: -0.6710, Loss D: -0.1898\n",
      "Epoch 699, Loss G: -0.0998, Loss D: -0.2072\n",
      "Epoch 700, Loss G: -0.2806, Loss D: 0.3581\n",
      "Epoch 701, Loss G: -0.4109, Loss D: -0.2889\n",
      "Epoch 702, Loss G: -0.2101, Loss D: -0.5032\n",
      "Epoch 703, Loss G: -0.6813, Loss D: 0.3946\n",
      "Epoch 704, Loss G: -0.5831, Loss D: -0.0600\n",
      "Epoch 705, Loss G: -0.6102, Loss D: -0.0950\n",
      "Epoch 706, Loss G: -1.2239, Loss D: -0.4144\n",
      "Epoch 707, Loss G: -0.8306, Loss D: -0.0383\n",
      "Epoch 708, Loss G: -0.2893, Loss D: -0.0648\n",
      "Epoch 709, Loss G: -0.6417, Loss D: 0.0466\n",
      "Epoch 710, Loss G: -0.2718, Loss D: -0.1782\n",
      "Epoch 711, Loss G: -0.3571, Loss D: -0.0078\n",
      "Epoch 712, Loss G: -0.2536, Loss D: 0.1896\n",
      "Epoch 713, Loss G: -0.6202, Loss D: -0.1772\n",
      "Epoch 714, Loss G: -0.7502, Loss D: -0.5708\n",
      "Epoch 715, Loss G: -0.3829, Loss D: -0.2149\n",
      "Epoch 716, Loss G: -0.5696, Loss D: -0.0109\n",
      "Epoch 717, Loss G: -0.6156, Loss D: -0.1315\n",
      "Epoch 718, Loss G: -0.5213, Loss D: -0.2002\n",
      "Epoch 719, Loss G: -0.3778, Loss D: -0.0355\n",
      "Epoch 720, Loss G: -0.2581, Loss D: 0.0210\n",
      "Epoch 721, Loss G: -0.4981, Loss D: 0.1834\n",
      "Epoch 722, Loss G: -0.7038, Loss D: -0.1626\n",
      "Epoch 723, Loss G: -0.4002, Loss D: 0.2071\n",
      "Epoch 724, Loss G: -0.5274, Loss D: 0.2119\n",
      "Epoch 725, Loss G: -1.0066, Loss D: -0.0844\n",
      "Epoch 726, Loss G: -0.8751, Loss D: -0.1991\n",
      "Epoch 727, Loss G: -0.4363, Loss D: -0.4176\n",
      "Epoch 728, Loss G: -1.4128, Loss D: -0.2017\n",
      "Epoch 729, Loss G: -0.7657, Loss D: 0.0738\n",
      "Epoch 730, Loss G: -1.0829, Loss D: -0.1332\n",
      "Epoch 731, Loss G: -0.3985, Loss D: -0.1857\n",
      "Epoch 732, Loss G: -0.2597, Loss D: 0.0423\n",
      "Epoch 733, Loss G: -0.2775, Loss D: -0.3461\n",
      "Epoch 734, Loss G: -0.5644, Loss D: -0.3374\n",
      "Epoch 735, Loss G: -1.0050, Loss D: 0.1895\n",
      "Epoch 736, Loss G: -0.5119, Loss D: 0.2622\n",
      "Epoch 737, Loss G: -0.4867, Loss D: 0.0848\n",
      "Epoch 738, Loss G: -0.4660, Loss D: -0.2677\n",
      "Epoch 739, Loss G: -0.4914, Loss D: -0.0713\n",
      "Epoch 740, Loss G: -0.8772, Loss D: -0.0767\n",
      "Epoch 741, Loss G: -0.5003, Loss D: -0.1375\n",
      "Epoch 742, Loss G: -0.4153, Loss D: -0.1397\n",
      "Epoch 743, Loss G: -0.8477, Loss D: -0.1345\n",
      "Epoch 744, Loss G: -0.6033, Loss D: -0.0853\n",
      "Epoch 745, Loss G: -0.7142, Loss D: -0.0703\n",
      "Epoch 746, Loss G: -0.4537, Loss D: 0.1994\n",
      "Epoch 747, Loss G: -0.1232, Loss D: -0.0049\n",
      "Epoch 748, Loss G: -0.4193, Loss D: 0.1795\n",
      "Epoch 749, Loss G: -0.8663, Loss D: -0.0937\n",
      "Epoch 750, Loss G: -0.4469, Loss D: 0.1086\n",
      "Epoch 751, Loss G: -0.7435, Loss D: -0.0832\n",
      "Epoch 752, Loss G: -0.6606, Loss D: -0.0595\n",
      "Epoch 753, Loss G: -0.5329, Loss D: -0.0411\n",
      "Epoch 754, Loss G: -0.5116, Loss D: -0.1560\n",
      "Epoch 755, Loss G: -0.8564, Loss D: -0.0672\n",
      "Epoch 756, Loss G: -1.0999, Loss D: -0.1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 757, Loss G: -0.5756, Loss D: -0.1250\n",
      "Epoch 758, Loss G: -0.8852, Loss D: -0.1489\n",
      "Epoch 759, Loss G: -0.5600, Loss D: -0.1102\n",
      "Epoch 760, Loss G: -0.6609, Loss D: -0.1497\n",
      "Epoch 761, Loss G: -0.9203, Loss D: 0.0128\n",
      "Epoch 762, Loss G: -0.7107, Loss D: -0.1988\n",
      "Epoch 763, Loss G: -1.0044, Loss D: 0.0740\n",
      "Epoch 764, Loss G: -1.1743, Loss D: 0.0007\n",
      "Epoch 765, Loss G: -0.6787, Loss D: 0.2542\n",
      "Epoch 766, Loss G: -0.7404, Loss D: -0.0900\n",
      "Epoch 767, Loss G: -1.0251, Loss D: 0.0541\n",
      "Epoch 768, Loss G: -1.0048, Loss D: 0.0616\n",
      "Epoch 769, Loss G: -1.0242, Loss D: -0.1849\n",
      "Epoch 770, Loss G: -0.5165, Loss D: -0.2210\n",
      "Epoch 771, Loss G: -1.0488, Loss D: 0.0090\n",
      "Epoch 772, Loss G: -0.8316, Loss D: -0.0304\n",
      "Epoch 773, Loss G: -0.5362, Loss D: -0.3278\n",
      "Epoch 774, Loss G: -0.5971, Loss D: -0.1024\n",
      "Epoch 775, Loss G: -0.4214, Loss D: 0.1929\n",
      "Epoch 776, Loss G: -0.4895, Loss D: 0.0409\n",
      "Epoch 777, Loss G: -0.9896, Loss D: -0.1935\n",
      "Epoch 778, Loss G: -0.6671, Loss D: -0.0515\n",
      "Epoch 779, Loss G: -0.5404, Loss D: -0.0719\n",
      "Epoch 780, Loss G: -0.5473, Loss D: -0.3281\n",
      "Epoch 781, Loss G: -0.6038, Loss D: -0.1440\n",
      "Epoch 782, Loss G: -0.8674, Loss D: 0.1212\n",
      "Epoch 783, Loss G: -0.8678, Loss D: -0.0113\n",
      "Epoch 784, Loss G: -0.6860, Loss D: -0.3388\n",
      "Epoch 785, Loss G: -0.6364, Loss D: 0.1097\n",
      "Epoch 786, Loss G: -0.7393, Loss D: -0.1119\n",
      "Epoch 787, Loss G: -0.3188, Loss D: -0.2209\n",
      "Epoch 788, Loss G: -0.6995, Loss D: -0.0531\n",
      "Epoch 789, Loss G: -0.2374, Loss D: 0.1030\n",
      "Epoch 790, Loss G: -0.2489, Loss D: 0.0480\n",
      "Epoch 791, Loss G: -0.5512, Loss D: -0.2799\n",
      "Epoch 792, Loss G: -0.5296, Loss D: -0.3843\n",
      "Epoch 793, Loss G: -0.5459, Loss D: 0.0717\n",
      "Epoch 794, Loss G: -0.7485, Loss D: -0.2839\n",
      "Epoch 795, Loss G: -0.5629, Loss D: -0.0748\n",
      "Epoch 796, Loss G: -0.5500, Loss D: 0.0209\n",
      "Epoch 797, Loss G: -0.6545, Loss D: 0.0030\n",
      "Epoch 798, Loss G: -0.5998, Loss D: 0.0178\n",
      "Epoch 799, Loss G: -0.5502, Loss D: -0.1183\n",
      "Epoch 800, Loss G: -0.4818, Loss D: -0.1732\n",
      "Epoch 801, Loss G: -0.6908, Loss D: 0.1249\n",
      "Epoch 802, Loss G: -0.7207, Loss D: -0.1207\n",
      "Epoch 803, Loss G: -0.7584, Loss D: 0.0008\n",
      "Epoch 804, Loss G: -0.8781, Loss D: -0.1972\n",
      "Epoch 805, Loss G: -0.7415, Loss D: -0.1502\n",
      "Epoch 806, Loss G: -0.7541, Loss D: -0.0958\n",
      "Epoch 807, Loss G: -0.8577, Loss D: -0.0556\n",
      "Epoch 808, Loss G: -0.7657, Loss D: -0.2979\n",
      "Epoch 809, Loss G: -0.5451, Loss D: 0.2782\n",
      "Epoch 810, Loss G: -0.8883, Loss D: 0.2028\n",
      "Epoch 811, Loss G: -0.5589, Loss D: -0.0273\n",
      "Epoch 812, Loss G: -0.5402, Loss D: 0.0607\n",
      "Epoch 813, Loss G: -0.5224, Loss D: 0.2546\n",
      "Epoch 814, Loss G: -0.7132, Loss D: -0.0874\n",
      "Epoch 815, Loss G: -0.7502, Loss D: -0.4696\n",
      "Epoch 816, Loss G: -0.7698, Loss D: 0.0981\n",
      "Epoch 817, Loss G: -0.3566, Loss D: -0.0003\n",
      "Epoch 818, Loss G: -0.6476, Loss D: 0.0401\n",
      "Epoch 819, Loss G: -0.6497, Loss D: 0.1933\n",
      "Epoch 820, Loss G: -1.2933, Loss D: -0.1039\n",
      "Epoch 821, Loss G: -0.8790, Loss D: -0.0678\n",
      "Epoch 822, Loss G: -0.5347, Loss D: -0.1125\n",
      "Epoch 823, Loss G: -0.3835, Loss D: -0.0391\n",
      "Epoch 824, Loss G: -0.7618, Loss D: 0.0299\n",
      "Epoch 825, Loss G: -0.8564, Loss D: 0.4133\n",
      "Epoch 826, Loss G: -0.3897, Loss D: -0.2604\n",
      "Epoch 827, Loss G: -0.9901, Loss D: 0.0026\n",
      "Epoch 828, Loss G: -0.8305, Loss D: -0.3524\n",
      "Epoch 829, Loss G: -0.7475, Loss D: 0.1754\n",
      "Epoch 830, Loss G: -1.1731, Loss D: 0.2751\n",
      "Epoch 831, Loss G: -0.5600, Loss D: -0.0766\n",
      "Epoch 832, Loss G: -0.7061, Loss D: 0.3227\n",
      "Epoch 833, Loss G: -0.5483, Loss D: -0.0657\n",
      "Epoch 834, Loss G: -0.7580, Loss D: -0.2039\n",
      "Epoch 835, Loss G: -0.7464, Loss D: -0.3067\n",
      "Epoch 836, Loss G: -0.8049, Loss D: -0.1254\n",
      "Epoch 837, Loss G: -0.7999, Loss D: 0.1240\n",
      "Epoch 838, Loss G: -0.6946, Loss D: -0.0369\n",
      "Epoch 839, Loss G: -1.0477, Loss D: 0.3339\n",
      "Epoch 840, Loss G: -0.9433, Loss D: -0.1645\n",
      "Epoch 841, Loss G: -0.6858, Loss D: 0.4546\n",
      "Epoch 842, Loss G: -0.2786, Loss D: -0.2215\n",
      "Epoch 843, Loss G: -1.2373, Loss D: 0.1487\n",
      "Epoch 844, Loss G: -0.6390, Loss D: -0.2182\n",
      "Epoch 845, Loss G: -1.0663, Loss D: 0.2491\n",
      "Epoch 846, Loss G: -0.4667, Loss D: -0.0817\n",
      "Epoch 847, Loss G: -0.4481, Loss D: -0.0551\n",
      "Epoch 848, Loss G: -0.7005, Loss D: -0.0350\n",
      "Epoch 849, Loss G: -0.1852, Loss D: 0.1228\n",
      "Epoch 850, Loss G: -0.2782, Loss D: 0.0360\n",
      "Epoch 851, Loss G: -0.5894, Loss D: -0.3152\n",
      "Epoch 852, Loss G: -0.4746, Loss D: 0.0435\n",
      "Epoch 853, Loss G: -0.7554, Loss D: -0.0168\n",
      "Epoch 854, Loss G: -0.4197, Loss D: -0.0936\n",
      "Epoch 855, Loss G: -0.5720, Loss D: -0.0457\n",
      "Epoch 856, Loss G: -0.6980, Loss D: -0.0454\n",
      "Epoch 857, Loss G: -0.6413, Loss D: -0.0542\n",
      "Epoch 858, Loss G: -0.1479, Loss D: 0.1910\n",
      "Epoch 859, Loss G: -0.3865, Loss D: -0.0556\n",
      "Epoch 860, Loss G: -0.5184, Loss D: -0.5012\n",
      "Epoch 861, Loss G: -0.7200, Loss D: 0.0775\n",
      "Epoch 862, Loss G: -0.6171, Loss D: -0.1595\n",
      "Epoch 863, Loss G: -0.9595, Loss D: -0.1598\n",
      "Epoch 864, Loss G: -0.8358, Loss D: 0.0094\n",
      "Epoch 865, Loss G: -0.9208, Loss D: -0.2351\n",
      "Epoch 866, Loss G: -0.4354, Loss D: 0.1046\n",
      "Epoch 867, Loss G: -1.0191, Loss D: 0.0351\n",
      "Epoch 868, Loss G: -1.1242, Loss D: -0.1144\n",
      "Epoch 869, Loss G: -1.2658, Loss D: 0.0551\n",
      "Epoch 870, Loss G: -1.1291, Loss D: 0.0103\n",
      "Epoch 871, Loss G: -0.7065, Loss D: 0.0451\n",
      "Epoch 872, Loss G: -1.1813, Loss D: -0.2121\n",
      "Epoch 873, Loss G: -0.8351, Loss D: -0.1202\n",
      "Epoch 874, Loss G: -0.9975, Loss D: 0.2805\n",
      "Epoch 875, Loss G: -0.2222, Loss D: -0.0061\n",
      "Epoch 876, Loss G: -0.5841, Loss D: 0.1245\n",
      "Epoch 877, Loss G: -1.2529, Loss D: -0.2633\n",
      "Epoch 878, Loss G: -0.8426, Loss D: 0.2192\n",
      "Epoch 879, Loss G: -0.7723, Loss D: -0.1775\n",
      "Epoch 880, Loss G: -0.7052, Loss D: 0.0417\n",
      "Epoch 881, Loss G: -0.7267, Loss D: -0.0842\n",
      "Epoch 882, Loss G: -1.0862, Loss D: -0.0356\n",
      "Epoch 883, Loss G: -0.7599, Loss D: -0.0484\n",
      "Epoch 884, Loss G: -1.1834, Loss D: -0.3293\n",
      "Epoch 885, Loss G: -0.7141, Loss D: 0.3833\n",
      "Epoch 886, Loss G: -0.6203, Loss D: -0.2262\n",
      "Epoch 887, Loss G: -1.2815, Loss D: -0.0749\n",
      "Epoch 888, Loss G: -0.5310, Loss D: 0.2862\n",
      "Epoch 889, Loss G: -0.9997, Loss D: -0.0519\n",
      "Epoch 890, Loss G: -0.6526, Loss D: -0.1029\n",
      "Epoch 891, Loss G: -0.9769, Loss D: -0.0968\n",
      "Epoch 892, Loss G: -0.6186, Loss D: -0.2531\n",
      "Epoch 893, Loss G: -0.6159, Loss D: -0.2027\n",
      "Epoch 894, Loss G: -0.2839, Loss D: 0.0973\n",
      "Epoch 895, Loss G: -0.7925, Loss D: 0.0063\n",
      "Epoch 896, Loss G: -0.6180, Loss D: 0.0262\n",
      "Epoch 897, Loss G: -1.1295, Loss D: -0.1179\n",
      "Epoch 898, Loss G: -0.5371, Loss D: -0.1892\n",
      "Epoch 899, Loss G: -0.9111, Loss D: 0.0560\n",
      "Epoch 900, Loss G: -1.0240, Loss D: 0.0496\n",
      "Epoch 901, Loss G: -0.2246, Loss D: -0.1069\n",
      "Epoch 902, Loss G: -0.1241, Loss D: -0.3164\n",
      "Epoch 903, Loss G: -0.7251, Loss D: -0.0257\n",
      "Epoch 904, Loss G: -1.0527, Loss D: 0.1842\n",
      "Epoch 905, Loss G: -0.7804, Loss D: -0.3465\n",
      "Epoch 906, Loss G: -0.6600, Loss D: 0.2539\n",
      "Epoch 907, Loss G: -0.7876, Loss D: 0.3614\n",
      "Epoch 908, Loss G: -0.7333, Loss D: -0.0704\n",
      "Epoch 909, Loss G: -0.7098, Loss D: 0.1298\n",
      "Epoch 910, Loss G: -0.6698, Loss D: -0.0787\n",
      "Epoch 911, Loss G: -0.6096, Loss D: 0.1024\n",
      "Epoch 912, Loss G: -0.8700, Loss D: -0.2918\n",
      "Epoch 913, Loss G: -0.7554, Loss D: 0.1791\n",
      "Epoch 914, Loss G: -0.8406, Loss D: -0.0291\n",
      "Epoch 915, Loss G: -0.8897, Loss D: 0.0047\n",
      "Epoch 916, Loss G: -0.9386, Loss D: -0.2019\n",
      "Epoch 917, Loss G: -0.3820, Loss D: -0.0426\n",
      "Epoch 918, Loss G: -0.3667, Loss D: -0.0611\n",
      "Epoch 919, Loss G: -1.3264, Loss D: 0.0233\n",
      "Epoch 920, Loss G: -0.6637, Loss D: 0.1665\n",
      "Epoch 921, Loss G: -0.4108, Loss D: -0.0320\n",
      "Epoch 922, Loss G: -0.4182, Loss D: 0.1028\n",
      "Epoch 923, Loss G: -0.4569, Loss D: -0.0320\n",
      "Epoch 924, Loss G: -0.8069, Loss D: -0.1409\n",
      "Epoch 925, Loss G: -0.5264, Loss D: -0.1478\n",
      "Epoch 926, Loss G: -0.5742, Loss D: 0.1839\n",
      "Epoch 927, Loss G: -0.4267, Loss D: -0.3820\n",
      "Epoch 928, Loss G: -1.0891, Loss D: 0.1617\n",
      "Epoch 929, Loss G: -0.7666, Loss D: -0.1682\n",
      "Epoch 930, Loss G: -0.8985, Loss D: 0.0960\n",
      "Epoch 931, Loss G: -0.4379, Loss D: -0.2034\n",
      "Epoch 932, Loss G: -1.0098, Loss D: 0.0045\n",
      "Epoch 933, Loss G: -0.7072, Loss D: -0.1802\n",
      "Epoch 934, Loss G: -0.9053, Loss D: 0.0286\n",
      "Epoch 935, Loss G: -0.8780, Loss D: 0.1856\n",
      "Epoch 936, Loss G: -0.7411, Loss D: -0.0529\n",
      "Epoch 937, Loss G: -0.8952, Loss D: 0.1761\n",
      "Epoch 938, Loss G: -0.8055, Loss D: -0.1678\n",
      "Epoch 939, Loss G: -0.8410, Loss D: 0.0500\n",
      "Epoch 940, Loss G: -0.7072, Loss D: -0.2351\n",
      "Epoch 941, Loss G: -0.9147, Loss D: -0.1464\n",
      "Epoch 942, Loss G: -0.6475, Loss D: -0.0889\n",
      "Epoch 943, Loss G: -0.8361, Loss D: 0.2254\n",
      "Epoch 944, Loss G: -0.4757, Loss D: -0.3251\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 945, Loss G: -0.5721, Loss D: -0.1776\n",
      "Epoch 946, Loss G: -0.8386, Loss D: -0.1533\n",
      "Epoch 947, Loss G: -0.0134, Loss D: -0.0418\n",
      "Epoch 948, Loss G: -0.9156, Loss D: 0.0222\n",
      "Epoch 949, Loss G: -0.6073, Loss D: 0.0600\n",
      "Epoch 950, Loss G: -0.9514, Loss D: -0.0901\n",
      "Epoch 951, Loss G: -0.8648, Loss D: -0.0948\n",
      "Epoch 952, Loss G: -1.0479, Loss D: -0.1412\n",
      "Epoch 953, Loss G: -0.7835, Loss D: -0.0935\n",
      "Epoch 954, Loss G: -0.7829, Loss D: -0.0228\n",
      "Epoch 955, Loss G: -1.0082, Loss D: -0.1144\n",
      "Epoch 956, Loss G: -1.0098, Loss D: 0.2367\n",
      "Epoch 957, Loss G: -0.8100, Loss D: -0.0509\n",
      "Epoch 958, Loss G: -0.7733, Loss D: -0.0756\n",
      "Epoch 959, Loss G: -0.6751, Loss D: 0.1572\n",
      "Epoch 960, Loss G: -0.4760, Loss D: 0.0202\n",
      "Epoch 961, Loss G: -0.7569, Loss D: 0.0306\n",
      "Epoch 962, Loss G: -0.9405, Loss D: -0.1600\n",
      "Epoch 963, Loss G: -0.9592, Loss D: 0.2151\n",
      "Epoch 964, Loss G: -0.9010, Loss D: 0.0052\n",
      "Epoch 965, Loss G: -0.6206, Loss D: -0.1118\n",
      "Epoch 966, Loss G: -0.1511, Loss D: 0.0636\n",
      "Epoch 967, Loss G: -0.3250, Loss D: -0.1746\n",
      "Epoch 968, Loss G: -0.6862, Loss D: -0.1349\n",
      "Epoch 969, Loss G: -0.4485, Loss D: -0.3323\n",
      "Epoch 970, Loss G: -0.1420, Loss D: -0.0090\n",
      "Epoch 971, Loss G: -0.3297, Loss D: 0.2543\n",
      "Epoch 972, Loss G: -0.5215, Loss D: 0.0732\n",
      "Epoch 973, Loss G: -0.8272, Loss D: -0.3661\n",
      "Epoch 974, Loss G: -0.8466, Loss D: 0.1121\n",
      "Epoch 975, Loss G: -0.9020, Loss D: 0.0529\n",
      "Epoch 976, Loss G: -0.3477, Loss D: 0.0051\n",
      "Epoch 977, Loss G: -0.6851, Loss D: -0.3136\n",
      "Epoch 978, Loss G: -0.6013, Loss D: 0.0165\n",
      "Epoch 979, Loss G: -0.6546, Loss D: -0.4245\n",
      "Epoch 980, Loss G: -0.0280, Loss D: -0.4010\n",
      "Epoch 981, Loss G: 0.0354, Loss D: -0.2155\n",
      "Epoch 982, Loss G: -0.0488, Loss D: 0.1039\n",
      "Epoch 983, Loss G: -0.8626, Loss D: -0.3023\n",
      "Epoch 984, Loss G: -0.5865, Loss D: -0.2523\n",
      "Epoch 985, Loss G: -0.5159, Loss D: -0.2646\n",
      "Epoch 986, Loss G: -1.0619, Loss D: -0.2020\n",
      "Epoch 987, Loss G: -0.3808, Loss D: 0.0127\n",
      "Epoch 988, Loss G: -1.0383, Loss D: -0.0793\n",
      "Epoch 989, Loss G: -0.3430, Loss D: 0.2264\n",
      "Epoch 990, Loss G: -0.5807, Loss D: -0.0355\n",
      "Epoch 991, Loss G: -0.5613, Loss D: -0.1283\n",
      "Epoch 992, Loss G: -1.0833, Loss D: 0.0220\n",
      "Epoch 993, Loss G: -0.3486, Loss D: -0.2710\n",
      "Epoch 994, Loss G: -0.4866, Loss D: 0.2072\n",
      "Epoch 995, Loss G: -0.7857, Loss D: -0.0652\n",
      "Epoch 996, Loss G: -0.5707, Loss D: -0.1540\n",
      "Epoch 997, Loss G: -0.5651, Loss D: -0.1899\n",
      "Epoch 998, Loss G: -0.5618, Loss D: -0.1474\n",
      "Epoch 999, Loss G: -0.3605, Loss D: 0.2102\n",
      "Epoch 1000, Loss G: -0.6358, Loss D: 0.1047\n"
     ]
    }
   ],
   "source": [
    "ctgan.fit(df, discrete_columns, epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctgan.save(output_folder + 'trained_1000.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_synth = '../synth_data/Chicago/ctgan_1000.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = ctgan.sample(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples.age = np.round(samples.age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples.to_csv(output_synth, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
