{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plot\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "import glob\n",
    "\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from modules.ml_efficacy.LGBMOrdinal_base import LGBMOrdinal, LGBMRegressor, LGBMClassifier, LightGBMCV, emse, emae\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# For the Python notebook\n",
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_real_df(df, cat_cols=None, ord_cols=None, cont_cols=None, enc=None):\n",
    "    if cat_cols and cont_cols:\n",
    "        df[cat_cols+ord_cols] = enc.fit_transform(df[cat_cols+ord_cols])\n",
    "    else:\n",
    "        print('Automated inference of column types to be implemented!')\n",
    "    return df\n",
    "\n",
    "def process_syn_df(df, cat_cols, ord_cols, cont_cols, enc=None):\n",
    "    df[cat_cols+ord_cols] = enc.transform(df[cat_cols+ord_cols])\n",
    "\n",
    "    return df\n",
    "\n",
    "def is_a_DATGAN(name):\n",
    "    if any(x in name for x in ['TGAN', 'CTGAN', 'FULL', 'TRANSRED', 'LINEAR', 'NOLINKS', 'PREDICTION']):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "    \n",
    "def check_low_appearing_vars(df):\n",
    "    \n",
    "    for c in df.columns:\n",
    "        val = df[c].value_counts()\n",
    "        if len(val) < 20:\n",
    "            val = val/len(df)\n",
    "            if any(val < 0.01) and c != 'choice':\n",
    "                print('Variable {}: '.format(c))\n",
    "                for idx, v in zip(val.index, val):\n",
    "                    if v < 0.01:\n",
    "                        print('  {} - {:.2f}% ({:d})'.format(idx, 100*v, int(v*len(df))))\n",
    "                print()\n",
    "                \n",
    "def replace_low_appearing_values(df, dataset):\n",
    "    \n",
    "    if 'Chicago' in dataset:\n",
    "        dct_ = {}\n",
    "        for i in df['hh_vehicles'].unique():\n",
    "            if i >= 5:\n",
    "                dct_[i] = '5+'\n",
    "            else:\n",
    "                dct_[i] = str(i)        \n",
    "        df['hh_vehicles'].replace(dct_, inplace=True)\n",
    "        \n",
    "        dct_ = {}\n",
    "        for i in df['hh_size'].unique():\n",
    "            if i >= 6:\n",
    "                dct_[i] = '6+'\n",
    "            else:\n",
    "                dct_[i] = str(i)        \n",
    "        df['hh_size'].replace(dct_, inplace=True)\n",
    "        \n",
    "        dct_ = {}\n",
    "        for i in df['hh_bikes'].unique():\n",
    "            if i >= 6:\n",
    "                dct_[i] = '6+'\n",
    "            else:\n",
    "                dct_[i] = str(i)        \n",
    "        df['hh_bikes'].replace(dct_, inplace=True)       \n",
    "\n",
    "    elif 'LPMC' in dataset:\n",
    "        dct_ = {}\n",
    "        for i in df['pt_n_interchanges'].unique():\n",
    "            if i >= 2:\n",
    "                dct_[i] = '2+'\n",
    "            else:\n",
    "                dct_[i] = str(i)        \n",
    "        df['pt_n_interchanges'].replace(dct_, inplace=True) \n",
    "        \n",
    "        dct_ = {\n",
    "            'Diesel_LGV': 'LGV',\n",
    "            'Petrol_LGV': 'LGV',\n",
    "            'Hybrid_Car': 'Average_Car'\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get all models and associated files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'Chicago_DAG'\n",
    "input_folder = '../synth_data/{}/'.format(dataset)\n",
    "n_models = 5\n",
    "n_data = 5\n",
    "\n",
    "# Models for testing all DATGANS\n",
    "models = ['CTGAN', 'TGAN']\n",
    "\n",
    "for i in ['WGAN', 'SGAN', 'WGGP']:\n",
    "    for j in ['WI', 'OR', 'WO']:\n",
    "        for k in ['NO', 'BO', 'OD']:\n",
    "            models.append('{}_{}_{}'.format(i,j,k))\n",
    "            \n",
    "# Models for testing different DAGs\n",
    "models = ['FULL', 'TRANSRED', 'LINEAR', 'NOLINKS', 'PREDICTION']\n",
    "\n",
    "models.sort()\n",
    "\n",
    "files_ = {}\n",
    "\n",
    "for m in models:\n",
    "    tmp = []\n",
    "    if is_a_DATGAN(m):\n",
    "        spl = m.split('_')\n",
    "        for i in range(n_models):\n",
    "            for j in range(n_data):\n",
    "                tmp.append(input_folder + '{}_{}_{:0>2}_{}_{:0>2}.csv'.format(spl[0], spl[1], i+1,  spl[2], j+1))\n",
    "    else:\n",
    "        for i in range(n_models):\n",
    "            for j in range(n_data):\n",
    "                tmp.append(input_folder + '{}_{:0>2}_{:0>2}.csv'.format(m, i+1, j+1))\n",
    "    files_[m] = tmp\n",
    "\n",
    "\n",
    "models.append('original')\n",
    "\n",
    "files_['original'] = ['../data/' + dataset.split('_')[0] + '/data.csv' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orig = pd.read_csv('../data/' + dataset.split('_')[0] + '/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['choice', 'travel_dow', 'trip_purpose', 'distance', 'hh_vehicles',\n",
       "       'hh_size', 'hh_bikes', 'hh_descr', 'hh_income', 'gender', 'age',\n",
       "       'license', 'education_level', 'work_status', 'departure_time'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_orig.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_low_appearing_values(df_orig, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_low_appearing_vars(df_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Chicago' in dataset:\n",
    "    cont_cols = ['distance', 'age', 'departure_time']\n",
    "    ord_cols = ['hh_vehicles', 'hh_size', 'hh_bikes', 'hh_income', \n",
    "                'education_level']\n",
    "    cat_cols = [col for col in df_orig.columns if col not in cont_cols + ord_cols]\n",
    "elif 'LPMC' in dataset:\n",
    "    cont_cols = ['start_time_linear', 'age', 'distance', 'dur_walking', \n",
    "                 'dur_cycling', 'dur_pt_access', 'dur_pt_rail', 'dur_pt_bus', \n",
    "                 'dur_pt_int', 'dur_driving', 'cost_transit', \n",
    "                 'cost_driving_fuel', 'driving_traffic_percent']\n",
    "    ord_cols = ['survey_year', 'travel_year', 'travel_month', 'travel_date', \n",
    "                'day_of_week', 'pt_n_interchanges', 'car_ownership']\n",
    "    cat_cols = [col for col in df_orig.columns if col not in cont_cols + ord_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OrdinalEncoder()\n",
    "ori = process_real_df(df_orig, cat_cols, ord_cols, cont_cols, enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found previous pickel file, using that\n"
     ]
    }
   ],
   "source": [
    "filepath = './notebooks/results/{}/'.format(dataset)\n",
    "filename = 'cv_result_ml.pickle'\n",
    "cv_modelscores = {}\n",
    "params={'n_estimators': 5000}\n",
    "\n",
    "try:\n",
    "    cv_modelscores = pickle.load(open(f'{filepath}{filename}','rb'))\n",
    "    print('Found previous pickel file, using that')\n",
    "except:\n",
    "    print('No previous results found, starting fresh')\n",
    "    try:\n",
    "        os.makedirs(filepath)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model \u001b[1mFULL\u001b[0m (1/6) already exists\n",
      "Results for model \u001b[1mLINEAR\u001b[0m (2/6) already exists\n",
      "Results for model \u001b[1mNOLINKS\u001b[0m (3/6) already exists\n",
      "Results for model \u001b[1mPREDICTION\u001b[0m (4/6) already exists\n",
      "Results for model \u001b[1mTRANSRED\u001b[0m (5/6) already exists\n",
      "Results for model \u001b[1moriginal\u001b[0m (6/6) already exists\n",
      "\u001b[1mFINISHED!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "for i, model in enumerate(models):\n",
    "    \n",
    "    if model in cv_modelscores.keys():\n",
    "        print(\"Results for model \\033[1m{}\\033[0m ({}/{}) already exists\".format(model, i+1, len(models)))\n",
    "    else:\n",
    "        print(\"Getting results for model \\033[1m{}\\033[0m ({}/{})\".format(model, i+1, len(models)))\n",
    "        cv_modelscores[model] = []\n",
    "        \n",
    "    n_files_done = len(cv_modelscores[model])\n",
    "        \n",
    "    for j, f in enumerate(files_[model][n_files_done:]):\n",
    "        \n",
    "        print(\"  Processing file {}/{}\".format(j+1+n_files_done, len(files_[model])) + \" \"*20)\n",
    "        \n",
    "        tmp_df = pd.read_csv(f)\n",
    "        replace_low_appearing_values(tmp_df, dataset)\n",
    "        v_df = process_syn_df(tmp_df, cat_cols, ord_cols, cont_cols, enc)\n",
    "        \n",
    "        tmp = {}\n",
    "        for k, ycol in enumerate(ori.columns):\n",
    "            info = '    Column: {} ({}/{})'.format(ycol, k+1, len(ori.columns))\n",
    "            print(info, end=\"\")\n",
    "            sys.stdout.flush()\n",
    "            Xcols = [c for c in ori.columns if c!=ycol]\n",
    "\n",
    "            y_synth = v_df[ycol]\n",
    "            X_synth = v_df[Xcols]\n",
    "            y_real = ori[ycol]\n",
    "            X_real = ori[Xcols]\n",
    "\n",
    "\n",
    "            observe_sets = {'original': (X_real, y_real)}\n",
    "            ccols = [c for c in cat_cols if c!=ycol]\n",
    "\n",
    "\n",
    "            if ycol in cat_cols + ord_cols:\n",
    "                lgbm_type = 'LGBMClassifier'\n",
    "                kf = StratifiedKFold(shuffle=True, random_state=42)\n",
    "                eval_metric = ['error']\n",
    "            elif ycol in cont_cols:\n",
    "                lgbm_type = 'LGBMRegressor'\n",
    "                kf = KFold(shuffle=True, random_state=42)\n",
    "                eval_metric = ['l2', 'l1']\n",
    "            cv = LightGBMCV(lgbm_type=lgbm_type,\n",
    "                splitter = kf,\n",
    "                eval_metric = eval_metric,\n",
    "                observe_sets = observe_sets,\n",
    "                separate_observation_split = True,\n",
    "                early_stopping_rounds = 5,\n",
    "                return_cv_models = False,\n",
    "                refit_model = False,\n",
    "                verbose = True)\n",
    "            cv.fit(X_synth, y_synth, categorical_feature=ccols, params=params)\n",
    "            tmp[ycol] = cv.result_dict_\n",
    "            \n",
    "            print(' '*len(info), end='\\r')\n",
    "\n",
    "            if k == len(ori.columns):\n",
    "                print('', end='\\r')\n",
    "            \n",
    "        cv_modelscores[model].append(tmp)\n",
    "            \n",
    "        pickle.dump(cv_modelscores,open(f'{filepath}/{filename}','wb'))\n",
    "\n",
    "print(\"\\033[1mFINISHED!\\033[0m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_scores = {col: cv_modelscores['original'][0][col]['test_log_loss'] for col in cat_cols + ord_cols}\n",
    "ori_scores.update({col: cv_modelscores['original'][0][col]['test_l2'] for col in cont_cols})\n",
    "\n",
    "internal = {}\n",
    "external = {}\n",
    "external_normalised = {}\n",
    "cont_scores = {}\n",
    "cat_scores = {}\n",
    "\n",
    "for model in models:\n",
    "    \n",
    "    n_tests = len(cv_modelscores[model])\n",
    "    \n",
    "    internal[model] = {}\n",
    "    external[model] = {}\n",
    "    external_normalised[model] = {}\n",
    "    for col in cat_cols + ord_cols:\n",
    "        tmp = [cv_modelscores[model][i][col]['test_log_loss'] for i in range(n_tests)]\n",
    "        internal[model][col] = {'avg': np.mean(tmp), 'std': np.std(tmp)}\n",
    "        \n",
    "        tmp = [cv_modelscores[model][i][col]['original_log_loss'] for i in range(n_tests)]\n",
    "        external[model][col] = {'avg': np.mean(tmp), 'std': np.std(tmp)}\n",
    "        \n",
    "        external_normalised[model][col] = external[model][col]['avg'] - ori_scores[col]\n",
    "\n",
    "        \n",
    "    for col in cont_cols:\n",
    "        tmp = [cv_modelscores[model][i][col]['test_l2'] for i in range(n_tests)]\n",
    "        internal[model][col] = {'avg': np.mean(tmp), 'std': np.std(tmp)}\n",
    "        \n",
    "        tmp = [cv_modelscores[model][i][col]['original_l2'] for i in range(n_tests)]\n",
    "        external[model][col] = {'avg': np.mean(tmp), 'std': np.std(tmp)}\n",
    "        \n",
    "        external_normalised[model][col] = external[model][col]['avg'] - ori_scores[col]\n",
    "    \n",
    "    cont_scores[model] = sum([external[model][col]['avg']/ori_scores[col] for col in cont_cols])\n",
    "    cat_scores[model] = sum([external[model][col]['avg']-ori_scores[col] for col in cat_cols + ord_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_sorted = sorted(cat_scores.items(), key=lambda item: item[1])\n",
    "cont_sorted = sorted(cont_scores.items(), key=lambda item: item[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   | categorical                    | continuous                    \n",
      "-----------------------------------------------------------\n",
      " 1 | original    : -2.111           | original    : 2.559           \n",
      " 2 | FULL        : 0.869            | FULL        : 3.133           \n",
      " 3 | TRANSRED    : 0.917            | TRANSRED    : 3.135           \n",
      " 4 | LINEAR      : 1.114            | LINEAR      : 3.199           \n",
      " 5 | PREDICTION  : 3.618            | PREDICTION  : 6.077           \n",
      " 6 | NOLINKS     : 3.949            | NOLINKS     : 6.220           \n"
     ]
    }
   ],
   "source": [
    "i=1\n",
    "print('   | {:<30} | {:<30}'.format('categorical', 'continuous'))\n",
    "print('-----------------------------------------------------------')\n",
    "for a, b in zip(cat_sorted, cont_sorted):\n",
    "    print('{:>2} | {:<30} | {:<30}'.format(i, '{:<12}: {:.3f}'.format(a[0], a[1]), '{:<12}: {:.3f}'.format(b[0], b[1])))\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
