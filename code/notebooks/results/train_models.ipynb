{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.9\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chevron\n",
    "import sys\n",
    "import os\n",
    "import copy\n",
    "import logging\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from distutils.dir_util import copy_tree\n",
    "\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "import time\n",
    "\n",
    "# For the Python notebook\n",
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_modules = copy.deepcopy(list(sys.modules.keys()))\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class redirect_output(object):\n",
    "    \"\"\"context manager for reditrecting stdout/err to files\"\"\"\n",
    "\n",
    "\n",
    "    def __init__(self, out=''):\n",
    "        self.log = open(out, 'w')\n",
    "        \n",
    "        self.old_stdout = sys.stdout\n",
    "        self.old_stderr = sys.stderr\n",
    "                \n",
    "    def __enter__(self):\n",
    "        sys.stdout = self.log\n",
    "        sys.stderr = self.log\n",
    "        \n",
    "    def __exit__(self, exc_type, exc_value, traceback):\n",
    "        sys.stdout = self.old_stdout\n",
    "        sys.stderr = self.old_stderr\n",
    "        self.log.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_loaded_modules(init_modules):\n",
    "    to_del = []\n",
    "    for m in sys.modules.keys(  ):\n",
    "        if m not in init_modules:\n",
    "            to_del.append(m)\n",
    "        \n",
    "    for m in to_del:\n",
    "        del(sys.modules[m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_to_str(elapsed):\n",
    "    \n",
    "    hours, rem = divmod(elapsed, 3600)\n",
    "    minutes, seconds = divmod(rem, 60)\n",
    "    str_ = \"{:0>2} seconds\".format(int(seconds))\n",
    "    if minutes > 0 or hours > 0:\n",
    "        str_ = \"{:0>1} minutes and \".format(int(minutes)) + str_\n",
    "    if hours > 0:\n",
    "        str_ = \"{:0>1} hours \".format(int(hours)) + str_\n",
    "        \n",
    "    return str_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dag(dataset):\n",
    "\n",
    "    # personalised graph\n",
    "    graph = nx.DiGraph()\n",
    "\n",
    "    if dataset is 'Chicago':\n",
    "        graph.add_edges_from([\n",
    "            (\"age\", \"license\"),\n",
    "            (\"age\", \"education_level\"),\n",
    "            (\"gender\", \"work_status\"),\n",
    "            (\"education_level\", \"work_status\"),\n",
    "            (\"education_level\", \"hh_income\"),\n",
    "            (\"work_status\", \"hh_income\"),\n",
    "            (\"hh_income\", \"hh_descr\"),\n",
    "            (\"hh_income\", \"hh_size\"),\n",
    "            (\"hh_size\", \"hh_vehicles\"),\n",
    "            (\"hh_size\", \"hh_bikes\"),\n",
    "            (\"work_status\", \"trip_purpose\"),\n",
    "            (\"trip_purpose\", \"departure_time\"),\n",
    "            (\"trip_purpose\", \"distance\"),\n",
    "            (\"travel_dow\", \"choice\"),\n",
    "            (\"distance\", \"choice\"),\n",
    "            (\"departure_time\", \"choice\"),\n",
    "            (\"hh_vehicles\", \"choice\"),\n",
    "            (\"hh_bikes\", \"choice\"),\n",
    "            (\"license\", \"choice\"),\n",
    "            # Non necessary links\n",
    "            (\"education_level\", \"hh_size\"),\n",
    "            (\"work_status\", \"hh_descr\"),\n",
    "            (\"work_status\", \"hh_size\"),\n",
    "            (\"hh_income\", \"hh_bikes\"),\n",
    "            (\"hh_income\", \"hh_vehicles\"),\n",
    "            (\"trip_purpose\", \"choice\")\n",
    "        ])\n",
    "    elif dataset is 'LPMC':\n",
    "        graph.add_edges_from([\n",
    "            (\"travel_year\", \"survey_year\"),\n",
    "            (\"travel_date\", \"day_of_week\"),\n",
    "            (\"day_of_week\", \"purpose\"),\n",
    "            (\"purpose\", \"start_time_linear\"),\n",
    "            (\"purpose\", \"cost_driving_con_charge\"),\n",
    "            (\"purpose\", \"distance\"),\n",
    "            (\"day_of_week\", \"driving_traffic_percent\"),\n",
    "            (\"day_of_week\", \"cost_driving_con_charge\"),\n",
    "            (\"start_time_linear\", \"driving_traffic_percent\"),\n",
    "            (\"start_time_linear\", \"cost_driving_con_charge\"),\n",
    "            (\"driving_traffic_percent\", \"cost_driving_con_charge\"),\n",
    "            (\"female\", \"driving_license\"),\n",
    "            (\"age\", \"bus_scale\"),\n",
    "            (\"age\", \"car_ownership\"),\n",
    "            (\"age\", \"driving_license\"),\n",
    "            (\"age\", \"faretype\"),\n",
    "            (\"driving_license\", \"car_ownership\"),\n",
    "            (\"car_ownership\", \"fueltype\"),\n",
    "            (\"fueltype\", \"cost_driving_con_charge\"),\n",
    "            (\"fueltype\", \"cost_driving_fuel\"),\n",
    "            (\"distance\", \"cost_driving_fuel\"),\n",
    "            (\"distance\", \"dur_driving\"),\n",
    "            (\"distance\", \"dur_walking\"),\n",
    "            (\"distance\", \"dur_cycling\"),\n",
    "            (\"distance\", \"dur_pt_access\"),\n",
    "            (\"distance\", \"dur_pt_rail\"),\n",
    "            (\"distance\", \"dur_pt_bus\"),\n",
    "            (\"distance\", \"dur_pt_int\"),\n",
    "            (\"dur_pt_bus\", \"cost_transit\"),\n",
    "            (\"dur_pt_rail\", \"cost_transit\"),\n",
    "            (\"pt_n_interchanges\", \"dur_pt_int\"),\n",
    "            (\"pt_n_interchanges\", \"cost_transit\"),\n",
    "            (\"faretype\", \"cost_transit\"),\n",
    "            (\"bus_scale\", \"cost_transit\"),\n",
    "            (\"car_ownership\", \"travel_mode\"),\n",
    "            (\"age\", \"travel_mode\"),\n",
    "            (\"cost_driving_con_charge\", \"travel_mode\"),\n",
    "            (\"driving_traffic_percent\", \"travel_mode\"),\n",
    "            (\"female\", \"travel_mode\"),\n",
    "            (\"purpose\", \"travel_mode\"),\n",
    "            (\"cost_transit\", \"travel_mode\"),\n",
    "            (\"cost_driving_fuel\", \"travel_mode\"),\n",
    "            (\"dur_driving\", \"travel_mode\"),\n",
    "            (\"dur_walking\", \"travel_mode\"),\n",
    "            (\"dur_cycling\", \"travel_mode\"),\n",
    "            (\"dur_pt_access\", \"travel_mode\"),\n",
    "            (\"dur_pt_rail\", \"travel_mode\"),\n",
    "            (\"dur_pt_bus\", \"travel_mode\"),\n",
    "            (\"dur_pt_int\", \"travel_mode\")\n",
    "        ])\n",
    "        graph.add_node(\"travel_month\")\n",
    "        \n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_DATGAN(dataset, loss, name, nt='WI'):\n",
    "    \n",
    "    df = pd.read_csv('../data/{}/data.csv'.format(dataset), index_col=False)\n",
    "\n",
    "    if dataset is 'Chicago':\n",
    "        continuous_columns = [\"distance\", \"age\", \"departure_time\"]\n",
    "    elif dataset is 'LPMC':\n",
    "        continuous_columns = ['start_time_linear', 'age', 'distance', 'dur_walking', 'dur_cycling', 'dur_pt_access',\n",
    "                              'dur_pt_rail', 'dur_pt_bus', 'dur_pt_int', 'dur_driving', 'cost_transit',\n",
    "                              'cost_driving_fuel', 'driving_traffic_percent']\n",
    "    if loss == 'WGAN':\n",
    "        from modules.datgan import DATWGAN as LIB\n",
    "        lr = 2e-4\n",
    "    elif loss == 'SGAN':\n",
    "        from modules.datgan import DATSGAN as LIB\n",
    "        lr = 1e-3\n",
    "    elif loss == 'WGGP':\n",
    "        from modules.datgan import DATWGANGP as LIB\n",
    "        lr = 1e-4\n",
    "    else:\n",
    "        from modules.datgan import DATWGAN as LIB\n",
    "        lr = 2e-4\n",
    "\n",
    "    output_folder = '../output/{}/{}/'.format(dataset, name)\n",
    "\n",
    "    datgan = LIB(continuous_columns, max_epoch=1000, batch_size=500, output=output_folder, gpu=0,\n",
    "                     learning_rate=lr, noisy_training=nt)\n",
    "\n",
    "    datgan.fit(df, dag(dataset))\n",
    "\n",
    "    datgan.save('trained', force=True)\n",
    "    \n",
    "def train_TGAN(dataset, name):\n",
    "    \n",
    "    df = pd.read_csv('../data/{}/data.csv'.format(dataset), index_col=False)\n",
    "\n",
    "    if dataset is 'Chicago':\n",
    "        continuous_columns = [3, 10, 14]\n",
    "    elif dataset is 'LPMC':\n",
    "        continuous_columns = [10, 11, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 27]\n",
    "    \n",
    "    from tgan.model import TGANModel\n",
    "\n",
    "    output_folder = '../output/{}/{}/'.format(dataset, name)\n",
    "    \n",
    "    bs = 500\n",
    "    steps_per_epoch = max(len(df) // bs, 1)\n",
    "    \n",
    "    tgan = TGANModel(continuous_columns, max_epoch=1000, steps_per_epoch=steps_per_epoch, \n",
    "                     batch_size=bs, output=output_folder, gpu=0)\n",
    "\n",
    "    tgan.fit(df)\n",
    "\n",
    "    tgan.save(output_folder + 'trained.pickle', force=True)\n",
    "    \n",
    "def train_CTGAN(dataset, name):\n",
    "    \n",
    "    df = pd.read_csv('../data/{}/data.csv'.format(dataset), index_col=False)\n",
    "    \n",
    "    if dataset is 'Chicago':\n",
    "        discrete_columns = [\n",
    "            'choice',\n",
    "            'travel_dow',\n",
    "            'trip_purpose',\n",
    "            'hh_vehicles',\n",
    "            'hh_size',\n",
    "            'hh_bikes',\n",
    "            'hh_descr',\n",
    "            'hh_income',\n",
    "            'gender',\n",
    "            'license',\n",
    "            'education_level',\n",
    "            'work_status'\n",
    "        ]\n",
    "    elif dataset is 'LPMC':\n",
    "        discrete_columns = [\n",
    "            'travel_mode',\n",
    "            'purpose',\n",
    "            'fueltype',\n",
    "            'faretype',\n",
    "            'bus_scale',\n",
    "            'survey_year',\n",
    "            'travel_year',\n",
    "            'travel_month',\n",
    "            'travel_date',\n",
    "            'day_of_week',\n",
    "            'female',\n",
    "            'driving_license',\n",
    "            'car_ownership',\n",
    "            'pt_n_interchanges',\n",
    "            'cost_driving_con_charge'\n",
    "        ]\n",
    "        \n",
    "    from ctgan import CTGANSynthesizer\n",
    "        \n",
    "    output_folder = '../output/{}/{}/'.format(dataset, name)\n",
    "    os.makedirs(output_folder)\n",
    "    \n",
    "    ctgan = CTGANSynthesizer(verbose=True, cuda=True, batch_size=500)\n",
    "    \n",
    "    ctgan.fit(df, discrete_columns, epochs=1000)\n",
    "    \n",
    "    ctgan.save(output_folder + 'trained.pickle')\n",
    "    \n",
    "def is_a_DATGAN(name):\n",
    "    if 'TGAN' in name or 'CTGAN' in name:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "    \n",
    "def check_already_trained(dataset, name):\n",
    "    \n",
    "    return os.path.isfile('../output/{}/{}/trained.tar.gz'.format(dataset, name)) or os.path.isfile('../output/{}/{}/trained.pickle'.format(dataset, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'Chicago'\n",
    "n_models = 5\n",
    "\n",
    "models = ['TGAN', 'CTGAN']\n",
    "\n",
    "reuse_data = False\n",
    "\n",
    "for i in ['WGAN', 'SGAN', 'WGGP']:\n",
    "    for j in ['WI', 'OR', 'WO']:\n",
    "        models.append('{}_{}'.format(i,j))\n",
    "\n",
    "tmp = []\n",
    "        \n",
    "for i in range(n_models):\n",
    "    for m in models:\n",
    "        tmp.append(m + '_{:0>2d}'.format(i+1))\n",
    "        \n",
    "tmp.sort()\n",
    "models = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model \u001b[1mCTGAN_01\u001b[0m (1/55) has already been trained.\n",
      "Model \u001b[1mCTGAN_02\u001b[0m (2/55) has already been trained.\n",
      "Model \u001b[1mCTGAN_03\u001b[0m (3/55) has already been trained.\n",
      "Model \u001b[1mCTGAN_04\u001b[0m (4/55) has already been trained.\n",
      "Model \u001b[1mCTGAN_05\u001b[0m (5/55) has already been trained.\n",
      "Model \u001b[1mSGAN_OR_01\u001b[0m (6/55) has already been trained.\n",
      "Model \u001b[1mSGAN_OR_02\u001b[0m (7/55) has already been trained.\n",
      "Model \u001b[1mSGAN_OR_03\u001b[0m (8/55) has already been trained.\n",
      "Model \u001b[1mSGAN_OR_04\u001b[0m (9/55) has already been trained.\n",
      "Model \u001b[1mSGAN_OR_05\u001b[0m (10/55) has already been trained.\n",
      "Model \u001b[1mSGAN_WI_01\u001b[0m (11/55) has already been trained.\n",
      "Model \u001b[1mSGAN_WI_02\u001b[0m (12/55) has already been trained.\n",
      "Model \u001b[1mSGAN_WI_03\u001b[0m (13/55) has already been trained.\n",
      "Model \u001b[1mSGAN_WI_04\u001b[0m (14/55) has already been trained.\n",
      "Model \u001b[1mSGAN_WI_05\u001b[0m (15/55) has already been trained.\n",
      "Model \u001b[1mSGAN_WO_01\u001b[0m (16/55) has already been trained.\n",
      "Model \u001b[1mSGAN_WO_02\u001b[0m (17/55) has already been trained.\n",
      "Model \u001b[1mSGAN_WO_03\u001b[0m (18/55) has already been trained.\n",
      "Model \u001b[1mSGAN_WO_04\u001b[0m (19/55) has already been trained.\n",
      "Model \u001b[1mSGAN_WO_05\u001b[0m (20/55) has already been trained.\n",
      "Model \u001b[1mTGAN_01\u001b[0m (21/55) has already been trained.\n",
      "Model \u001b[1mTGAN_02\u001b[0m (22/55) has already been trained.\n",
      "Model \u001b[1mTGAN_03\u001b[0m (23/55) has already been trained.\n",
      "Model \u001b[1mTGAN_04\u001b[0m (24/55) has already been trained.\n",
      "Model \u001b[1mTGAN_05\u001b[0m (25/55) has already been trained.\n",
      "Model \u001b[1mWGAN_OR_01\u001b[0m (26/55) has already been trained.\n",
      "Model \u001b[1mWGAN_OR_02\u001b[0m (27/55) has already been trained.\n",
      "Model \u001b[1mWGAN_OR_03\u001b[0m (28/55) has already been trained.\n",
      "Model \u001b[1mWGAN_OR_04\u001b[0m (29/55) has already been trained.\n",
      "Model \u001b[1mWGAN_OR_05\u001b[0m (30/55) has already been trained.\n",
      "Model \u001b[1mWGAN_WI_01\u001b[0m (31/55) has already been trained.\n",
      "Model \u001b[1mWGAN_WI_02\u001b[0m (32/55) has already been trained.\n",
      "Model \u001b[1mWGAN_WI_03\u001b[0m (33/55) has already been trained.\n",
      "Model \u001b[1mWGAN_WI_04\u001b[0m (34/55) has already been trained.\n",
      "Model \u001b[1mWGAN_WI_05\u001b[0m (35/55) has already been trained.\n",
      "Model \u001b[1mWGAN_WO_01\u001b[0m (36/55) has already been trained.\n",
      "Training model \u001b[1mWGAN_WO_02\u001b[0m (37/55) ... Done in 1 minutes and 24 seconds.\n",
      "Training model \u001b[1mWGAN_WO_03\u001b[0m (38/55) ... Done in 11 minutes and 16 seconds.\n",
      "Training model \u001b[1mWGAN_WO_04\u001b[0m (39/55) ... Done in 11 minutes and 16 seconds.\n",
      "Training model \u001b[1mWGAN_WO_05\u001b[0m (40/55) ... Done in 11 minutes and 18 seconds.\n",
      "Training model \u001b[1mWGGP_OR_01\u001b[0m (41/55) ... Done in 13 minutes and 55 seconds.\n",
      "Training model \u001b[1mWGGP_OR_02\u001b[0m (42/55) ... Done in 13 minutes and 51 seconds.\n",
      "Training model \u001b[1mWGGP_OR_03\u001b[0m (43/55) ... Done in 13 minutes and 49 seconds.\n",
      "Training model \u001b[1mWGGP_OR_04\u001b[0m (44/55) ... Done in 13 minutes and 58 seconds.\n",
      "Training model \u001b[1mWGGP_OR_05\u001b[0m (45/55) ... Done in 13 minutes and 55 seconds.\n",
      "Training model \u001b[1mWGGP_WI_01\u001b[0m (46/55) ... Done in 13 minutes and 51 seconds.\n",
      "Training model \u001b[1mWGGP_WI_02\u001b[0m (47/55) ... Done in 13 minutes and 51 seconds.\n",
      "Training model \u001b[1mWGGP_WI_03\u001b[0m (48/55) ... Done in 13 minutes and 50 seconds.\n",
      "Training model \u001b[1mWGGP_WI_04\u001b[0m (49/55) ... Done in 13 minutes and 52 seconds.\n",
      "Training model \u001b[1mWGGP_WI_05\u001b[0m (50/55) ... Done in 14 minutes and 3 seconds.\n",
      "Training model \u001b[1mWGGP_WO_01\u001b[0m (51/55) ... Done in 13 minutes and 58 seconds.\n",
      "Training model \u001b[1mWGGP_WO_02\u001b[0m (52/55) ... Done in 13 minutes and 53 seconds.\n",
      "Training model \u001b[1mWGGP_WO_03\u001b[0m (53/55) ... Done in 14 minutes and 1 seconds.\n",
      "Training model \u001b[1mWGGP_WO_04\u001b[0m (54/55) ... Done in 14 minutes and 16 seconds.\n",
      "Training model \u001b[1mWGGP_WO_05\u001b[0m (55/55) ... Done in 14 minutes and 10 seconds.\n",
      "FINISHED!\n"
     ]
    }
   ],
   "source": [
    "for i, m in enumerate(models):\n",
    "    \n",
    "    if check_already_trained(dataset, m):\n",
    "        print(\"Model \\033[1m{}\\033[0m ({}/{}) has already been trained.\".format(m, i+1, len(models)))\n",
    "        \n",
    "    else:\n",
    "    \n",
    "        print(\"\\rTraining model \\033[1m{}\\033[0m ({}/{}) ... \".format(m, i+1, len(models)), end=\"\")\n",
    "        \n",
    "        # Cannot delete tensorflow modules sadly =(\n",
    "        tf.reset_default_graph()\n",
    "\n",
    "        delete_loaded_modules(init_modules)\n",
    "\n",
    "        if reuse_data and is_a_DATGAN(m):\n",
    "            copy_tree('../output/{}/{}/data'.format(dataset, 'WGAN_WI'), '../output/{}/{}/data'.format(dataset, m))\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        if 'CTGAN' in m:\n",
    "            with redirect_output('training.log'):\n",
    "                train_CTGAN(dataset, m)\n",
    "        elif 'TGAN' in m:\n",
    "            with redirect_output('training.log'):\n",
    "                train_TGAN(dataset, m)\n",
    "        elif is_a_DATGAN(m):\n",
    "            with redirect_output('training.log'):\n",
    "                train_DATGAN(dataset, m.split('_')[0], m, m.split('_')[1])\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "\n",
    "        time_taken = time_to_str(elapsed)\n",
    "\n",
    "        print(\"Done in {}.\".format(time_taken))\n",
    "\n",
    "        for handler in logging.getLogger('tensorpack').handlers:\n",
    "            handler.close()\n",
    "\n",
    "        logging.getLogger('tensorpack').handlers = []\n",
    "\n",
    "print(\"FINISHED!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
