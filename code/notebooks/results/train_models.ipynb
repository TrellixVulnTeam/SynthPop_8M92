{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.9\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chevron\n",
    "import sys\n",
    "import os\n",
    "import copy\n",
    "import logging\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "from distutils.dir_util import copy_tree\n",
    "\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "import time\n",
    "\n",
    "# For the Python notebook\n",
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_modules = copy.deepcopy(list(sys.modules.keys()))\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class redirect_output(object):\n",
    "    \"\"\"context manager for reditrecting stdout/err to files\"\"\"\n",
    "\n",
    "\n",
    "    def __init__(self, out=''):\n",
    "        self.log = open(out, 'w')\n",
    "        \n",
    "        self.old_stdout = sys.stdout\n",
    "        self.old_stderr = sys.stderr\n",
    "                \n",
    "    def __enter__(self):\n",
    "        sys.stdout = self.log\n",
    "        sys.stderr = self.log\n",
    "        \n",
    "    def __exit__(self, exc_type, exc_value, traceback):\n",
    "        sys.stdout = self.old_stdout\n",
    "        sys.stderr = self.old_stderr\n",
    "        self.log.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_loaded_modules(init_modules):\n",
    "    to_del = []\n",
    "    for m in sys.modules.keys(  ):\n",
    "        if m not in init_modules:\n",
    "            to_del.append(m)\n",
    "        \n",
    "    for m in to_del:\n",
    "        del(sys.modules[m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_to_str(elapsed):\n",
    "    \n",
    "    hours, rem = divmod(elapsed, 3600)\n",
    "    minutes, seconds = divmod(rem, 60)\n",
    "    str_ = \"{:0>2} seconds\".format(int(seconds))\n",
    "    if minutes > 0 or hours > 0:\n",
    "        str_ = \"{:0>1} minutes and \".format(int(minutes)) + str_\n",
    "    if hours > 0:\n",
    "        str_ = \"{:0>1} hours \".format(int(hours)) + str_\n",
    "        \n",
    "    return str_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_a_DATGAN(name):\n",
    "    if any(x in name for x in ['TGAN', 'CTGAN', 'TVAE', 'CTABGAN']):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "    \n",
    "def check_already_trained(dataset, name):\n",
    "    \n",
    "    return os.path.isfile('../output/{}/{}/trained.tar.gz'.format(dataset, name)) or os.path.isfile('../output/{}/{}/trained.pickle'.format(dataset, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dag(dataset):\n",
    "\n",
    "    # personalised graph\n",
    "    graph = nx.DiGraph()\n",
    "\n",
    "    if 'Chicago' in dataset:\n",
    "        graph.add_edges_from([\n",
    "            (\"age\", \"license\"),\n",
    "            (\"age\", \"education_level\"),\n",
    "            (\"gender\", \"work_status\"),\n",
    "            (\"education_level\", \"work_status\"),\n",
    "            (\"education_level\", \"hh_income\"),\n",
    "            (\"work_status\", \"hh_income\"),\n",
    "            (\"hh_income\", \"hh_descr\"),\n",
    "            (\"hh_income\", \"hh_size\"),\n",
    "            (\"hh_size\", \"hh_vehicles\"),\n",
    "            (\"hh_size\", \"hh_bikes\"),\n",
    "            (\"work_status\", \"trip_purpose\"),\n",
    "            (\"trip_purpose\", \"departure_time\"),\n",
    "            (\"trip_purpose\", \"distance\"),\n",
    "            (\"travel_dow\", \"choice\"),\n",
    "            (\"distance\", \"choice\"),\n",
    "            (\"departure_time\", \"choice\"),\n",
    "            (\"hh_vehicles\", \"choice\"),\n",
    "            (\"hh_bikes\", \"choice\"),\n",
    "            (\"license\", \"choice\"),\n",
    "            # Links removed when doing trans red\n",
    "            (\"education_level\", \"hh_size\"),\n",
    "            (\"work_status\", \"hh_descr\"),\n",
    "            (\"work_status\", \"hh_size\"),\n",
    "            (\"hh_income\", \"hh_bikes\"),\n",
    "            (\"hh_income\", \"hh_vehicles\"),\n",
    "            (\"trip_purpose\", \"choice\")\n",
    "        ])\n",
    "    elif 'LPMC' in dataset:\n",
    "        graph.add_edges_from([\n",
    "            (\"travel_year\", \"travel_month\"),\n",
    "            (\"travel_date\", \"day_of_week\"),\n",
    "            (\"travel_month\", \"travel_date\"),\n",
    "            (\"travel_month\", \"driving_traffic_percent\"),\n",
    "            (\"travel_month\", \"day_of_week\"),\n",
    "            (\"travel_month\", \"travel_mode\"),\n",
    "            (\"travel_date\", \"day_of_week\"),\n",
    "            (\"day_of_week\", \"driving_traffic_percent\"),\n",
    "            (\"day_of_week\", \"cost_driving_con_charge\"),\n",
    "            (\"day_of_week\", \"purpose\"),\n",
    "            (\"day_of_week\", \"start_time_linear\"),\n",
    "            (\"day_of_week\", \"travel_mode\"),\n",
    "            (\"purpose\", \"distance\"),\n",
    "            (\"purpose\", \"start_time_linear\"),\n",
    "            (\"purpose\", \"travel_mode\"),\n",
    "            (\"start_time_linear\", \"driving_traffic_percent\"),\n",
    "            (\"start_time_linear\", \"cost_driving_con_charge\"),\n",
    "            (\"start_time_linear\", \"travel_mode\"),\n",
    "            (\"car_ownership\", \"fueltype\"),\n",
    "            (\"car_ownership\", \"driving_license\"),\n",
    "            (\"car_ownership\", \"travel_mode\"),\n",
    "            (\"fueltype\", \"cost_driving_con_charge\"),\n",
    "            (\"fueltype\", \"cost_driving_fuel\"),\n",
    "            (\"female\", \"driving_license\"),\n",
    "            (\"female\", \"travel_mode\"),\n",
    "            (\"age\", \"bus_scale\"),\n",
    "            (\"age\", \"driving_license\"),\n",
    "            (\"age\", \"faretype\"),\n",
    "            (\"age\", \"travel_mode\"),\n",
    "            (\"driving_license\", \"travel_mode\"),\n",
    "            (\"faretype\", \"cost_transit\"),\n",
    "            (\"faretype\", \"bus_scale\"),\n",
    "            (\"faretype\", \"travel_mode\"),\n",
    "            (\"bus_scale\", \"cost_transit\"),\n",
    "            (\"distance\", \"cost_driving_fuel\"),\n",
    "            (\"distance\", \"dur_driving\"),\n",
    "            (\"distance\", \"dur_walking\"),\n",
    "            (\"distance\", \"dur_cycling\"),\n",
    "            (\"distance\", \"dur_pt_access\"),\n",
    "            (\"distance\", \"dur_pt_rail\"),\n",
    "            (\"distance\", \"dur_pt_bus\"),\n",
    "            (\"distance\", \"dur_pt_int\"),\n",
    "            (\"distance\", \"pt_n_interchanges\"),\n",
    "            (\"distance\", \"travel_mode\"),\n",
    "            (\"pt_n_interchanges\", \"dur_pt_rail\"),\n",
    "            (\"pt_n_interchanges\", \"dur_pt_bus\"),\n",
    "            (\"pt_n_interchanges\", \"dur_pt_int\"),\n",
    "            (\"pt_n_interchanges\", \"cost_transit\"),\n",
    "            (\"driving_traffic_percent\", \"cost_driving_con_charge\"),\n",
    "            (\"driving_traffic_percent\", \"travel_mode\"),\n",
    "            (\"cost_driving_fuel\", \"cost_driving_con_charge\"),\n",
    "            (\"cost_driving_fuel\", \"travel_mode\"),\n",
    "            (\"cost_driving_con_charge\", \"travel_mode\"),\n",
    "            (\"dur_driving\", \"travel_mode\"),\n",
    "            (\"dur_walking\", \"travel_mode\"),\n",
    "            (\"dur_cycling\", \"travel_mode\"),\n",
    "            (\"dur_pt_access\", \"travel_mode\"),\n",
    "            (\"dur_pt_rail\", \"cost_transit\"),\n",
    "            (\"dur_pt_rail\", \"travel_mode\"),\n",
    "            (\"dur_pt_bus\", \"cost_transit\"),\n",
    "            (\"dur_pt_bus\", \"travel_mode\"),\n",
    "            (\"dur_pt_int\", \"travel_mode\"),\n",
    "            (\"cost_transit\", \"travel_mode\")\n",
    "        ])\n",
    "    elif 'adult' in dataset:\n",
    "        graph.add_edges_from([\n",
    "            (\"age\", \"marital-status\"),\n",
    "            (\"age\", \"education\"),\n",
    "            (\"age\", \"income\"),\n",
    "            (\"age\", \"occupation\"),\n",
    "            (\"gender\", \"marital-status\"),\n",
    "            (\"gender\", \"education\"),\n",
    "            (\"gender\", \"income\"),\n",
    "            (\"native-country\", \"race\"),\n",
    "            (\"native-country\", \"marital-status\"),\n",
    "            (\"native-country\", \"education\"),\n",
    "            (\"marital-status\", \"relationship\"),\n",
    "            (\"relationship\", \"occupation\"),\n",
    "            (\"race\", \"education\"),\n",
    "            (\"race\", \"income\"),\n",
    "            (\"race\", \"occupation\"),\n",
    "            (\"education\", \"income\"),\n",
    "            (\"education\", \"educational-num\"),\n",
    "            (\"education\", \"occupation\"),\n",
    "            (\"educational-num\", \"income\"),\n",
    "            (\"occupation\", \"hours-per-week\"),\n",
    "            (\"occupation\", \"workclass\"),\n",
    "            (\"occupation\", \"capital-gain\"),\n",
    "            (\"occupation\", \"capital-loss\"),\n",
    "            (\"occupation\", \"income\"),\n",
    "            (\"workclass\", \"hours-per-week\"),\n",
    "            (\"workclass\", \"capital-gain\"),\n",
    "            (\"workclass\", \"capital-loss\"),\n",
    "            (\"hours-per-week\", \"income\"),\n",
    "            (\"capital-gain\", \"income\"),\n",
    "            (\"capital-loss\", \"income\")\n",
    "        ])\n",
    "        \n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_DATGAN(dataset, loss, name, nt='WI'):\n",
    "    \n",
    "    df = pd.read_csv('../data/{}/data.csv'.format(dataset), index_col=False)\n",
    "\n",
    "    if 'Chicago' in dataset:\n",
    "        continuous_columns = [\"distance\", \"age\", \"departure_time\"]\n",
    "    elif 'LPMC' in dataset:\n",
    "        continuous_columns = ['start_time_linear', 'age', 'distance', 'dur_walking', 'dur_cycling', 'dur_pt_access',\n",
    "                              'dur_pt_rail', 'dur_pt_bus', 'dur_pt_int', 'dur_driving', 'cost_transit',\n",
    "                              'cost_driving_fuel', 'driving_traffic_percent']\n",
    "    elif 'adult' in dataset:\n",
    "        continuous_columns = ['age', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
    "    elif 'covertype' in dataset:\n",
    "        continuous_columns = ['Elevation', 'Aspect', 'Slope', \n",
    "                              'Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology',\n",
    "                              'Horizontal_Distance_To_Roadways', 'Hillshade_9am', 'Hillshade_Noon', \n",
    "                              'Hillshade_3pm', 'Horizontal_Distance_To_Fire_Points']\n",
    "\n",
    "    if loss == 'WGAN':\n",
    "        from modules.datgan import DATWGAN as LIB\n",
    "    elif loss == 'SGAN':\n",
    "        from modules.datgan import DATSGAN as LIB\n",
    "    elif loss == 'WGGP':\n",
    "        from modules.datgan import DATWGANGP as LIB\n",
    "\n",
    "    output_folder = '../output/{}/{}/'.format(dataset, name)\n",
    "\n",
    "    datgan = LIB(continuous_columns, max_epoch=1000, batch_size=500, \n",
    "                 output=output_folder, gpu=0, noisy_training=nt)\n",
    "    \n",
    "    if 'LINEAR' in name or 'covertype' in dataset:\n",
    "        graph = nx.DiGraph()\n",
    "        list_ = []\n",
    "        for i in range(len(df.columns)-1):\n",
    "            list_.append((df.columns[i], df.columns[i+1]))\n",
    "        graph.add_edges_from(list_)\n",
    "        datgan.fit(df, graph)\n",
    "        \n",
    "    else:\n",
    "        datgan.fit(df, dag(dataset))\n",
    "\n",
    "    datgan.save('trained', force=True)\n",
    "    \n",
    "def train_TGAN(dataset, name):\n",
    "    \n",
    "    df = pd.read_csv('../data/{}/data.csv'.format(dataset), index_col=False)\n",
    "\n",
    "    if 'Chicago' in dataset:\n",
    "        continuous_columns = [3, 10, 14]\n",
    "    elif 'LPMC' in dataset:\n",
    "        continuous_columns = [9, 10, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 26]\n",
    "    elif 'adult' in dataset:\n",
    "        continuous_columns = [0, 9, 10, 11]\n",
    "    elif 'covertype' in dataset:\n",
    "        continuous_columns = list(range(10))\n",
    "        \n",
    "    from tgan.model import TGANModel\n",
    "\n",
    "    output_folder = '../output/{}/{}/'.format(dataset, name)\n",
    "    \n",
    "    bs = 500\n",
    "    steps_per_epoch = max(len(df) // bs, 1)\n",
    "    \n",
    "    tgan = TGANModel(continuous_columns, max_epoch=1000, steps_per_epoch=steps_per_epoch, \n",
    "                     batch_size=bs, output=output_folder, gpu=0)\n",
    "\n",
    "    tgan.fit(df)\n",
    "\n",
    "    tgan.save(output_folder + 'trained.pickle', force=True)\n",
    "    \n",
    "def train_CTGAN(dataset, name):\n",
    "    \n",
    "    df = pd.read_csv('../data/{}/data.csv'.format(dataset), index_col=False)\n",
    "    \n",
    "    if 'Chicago' in dataset:\n",
    "        discrete_columns = [\n",
    "            'choice',\n",
    "            'travel_dow',\n",
    "            'trip_purpose',\n",
    "            'hh_vehicles',\n",
    "            'hh_size',\n",
    "            'hh_bikes',\n",
    "            'hh_descr',\n",
    "            'hh_income',\n",
    "            'gender',\n",
    "            'license',\n",
    "            'education_level',\n",
    "            'work_status'\n",
    "        ]\n",
    "    elif 'LPMC' in dataset:\n",
    "        discrete_columns = [\n",
    "            'travel_mode',\n",
    "             'purpose',\n",
    "             'fueltype',\n",
    "             'faretype',\n",
    "             'bus_scale',\n",
    "             'travel_year',\n",
    "             'travel_month',\n",
    "             'travel_date',\n",
    "             'day_of_week',\n",
    "             'female',\n",
    "             'driving_license',\n",
    "             'car_ownership',\n",
    "             'pt_n_interchanges',\n",
    "             'cost_driving_con_charge'\n",
    "        ]\n",
    "    elif 'adult' in dataset:\n",
    "        discrete_columns = [\n",
    "            'race',\n",
    "            'workclass',\n",
    "            'income',\n",
    "            'marital-status',\n",
    "            'relationship',\n",
    "            'gender',\n",
    "            'education',\n",
    "            'native-country',\n",
    "            'occupation',\n",
    "            'educational-num'\n",
    "        ]\n",
    "    elif 'covertype' in dataset:\n",
    "        continuous_cols = ['Elevation', 'Aspect', 'Slope', \n",
    "                           'Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology',\n",
    "                           'Horizontal_Distance_To_Roadways', 'Hillshade_9am', 'Hillshade_Noon', \n",
    "                           'Hillshade_3pm', 'Horizontal_Distance_To_Fire_Points']\n",
    "        discrete_columns = list(set(df.columns) - set(continuous_cols))\n",
    "    \n",
    "    from ctgan import CTGANSynthesizer\n",
    "        \n",
    "    output_folder = '../output/{}/{}/'.format(dataset, name)\n",
    "    os.makedirs(output_folder)\n",
    "    \n",
    "    ctgan = CTGANSynthesizer(verbose=True, cuda=True, batch_size=500)\n",
    "    \n",
    "    ctgan.fit(df, discrete_columns, epochs=1000)\n",
    "    \n",
    "    ctgan.save(output_folder + 'trained.pickle')\n",
    "    \n",
    "def train_TVAE(dataset, name):\n",
    "    df = pd.read_csv('../data/{}/data.csv'.format(dataset), index_col=False)\n",
    "    \n",
    "    if 'Chicago' in dataset:\n",
    "        discrete_columns = [\n",
    "            'choice',\n",
    "            'travel_dow',\n",
    "            'trip_purpose',\n",
    "            'hh_vehicles',\n",
    "            'hh_size',\n",
    "            'hh_bikes',\n",
    "            'hh_descr',\n",
    "            'hh_income',\n",
    "            'gender',\n",
    "            'license',\n",
    "            'education_level',\n",
    "            'work_status'\n",
    "        ]\n",
    "    elif 'LPMC' in dataset:\n",
    "        discrete_columns = [\n",
    "            'travel_mode',\n",
    "             'purpose',\n",
    "             'fueltype',\n",
    "             'faretype',\n",
    "             'bus_scale',\n",
    "             'travel_year',\n",
    "             'travel_month',\n",
    "             'travel_date',\n",
    "             'day_of_week',\n",
    "             'female',\n",
    "             'driving_license',\n",
    "             'car_ownership',\n",
    "             'pt_n_interchanges',\n",
    "             'cost_driving_con_charge'\n",
    "        ]\n",
    "    elif 'adult' in dataset:\n",
    "        discrete_columns = [\n",
    "            'race',\n",
    "            'workclass',\n",
    "            'income',\n",
    "            'marital-status',\n",
    "            'relationship',\n",
    "            'gender',\n",
    "            'education',\n",
    "            'native-country',\n",
    "            'occupation',\n",
    "            'educational-num'\n",
    "        ]\n",
    "    elif 'covertype' in dataset:\n",
    "        continuous_cols = ['Elevation', 'Aspect', 'Slope', \n",
    "                           'Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology',\n",
    "                           'Horizontal_Distance_To_Roadways', 'Hillshade_9am', 'Hillshade_Noon', \n",
    "                           'Hillshade_3pm', 'Horizontal_Distance_To_Fire_Points']\n",
    "        discrete_columns = list(set(df.columns) - set(continuous_cols))\n",
    "        \n",
    "    from ctgan import TVAESynthesizer\n",
    "        \n",
    "    output_folder = '../output/{}/{}/'.format(dataset, name)\n",
    "    os.makedirs(output_folder)\n",
    "    \n",
    "    tvae = TVAESynthesizer(epochs=1000, cuda=True, batch_size=500)\n",
    "    \n",
    "    tvae.fit(df, discrete_columns)\n",
    "    \n",
    "    tvae.save(output_folder + 'trained.pickle')\n",
    "    \n",
    "def train_CTABGAN(dataset, name):\n",
    "    df = pd.read_csv('../data/{}/data.csv'.format(dataset), index_col=False)\n",
    "    \n",
    "    if 'Chicago' in dataset:\n",
    "        discrete_columns = [\n",
    "            'choice',\n",
    "            'travel_dow',\n",
    "            'trip_purpose',\n",
    "            'hh_vehicles',\n",
    "            'hh_size',\n",
    "            'hh_bikes',\n",
    "            'hh_descr',\n",
    "            'hh_income',\n",
    "            'gender',\n",
    "            'license',\n",
    "            'education_level',\n",
    "            'work_status'\n",
    "        ]\n",
    "    elif 'LPMC' in dataset:\n",
    "        discrete_columns = [\n",
    "            'travel_mode',\n",
    "             'purpose',\n",
    "             'fueltype',\n",
    "             'faretype',\n",
    "             'bus_scale',\n",
    "             'travel_year',\n",
    "             'travel_month',\n",
    "             'travel_date',\n",
    "             'day_of_week',\n",
    "             'female',\n",
    "             'driving_license',\n",
    "             'car_ownership',\n",
    "             'pt_n_interchanges',\n",
    "             'cost_driving_con_charge'\n",
    "        ]\n",
    "    elif 'adult' in dataset:\n",
    "        discrete_columns = [\n",
    "            'race',\n",
    "            'workclass',\n",
    "            'income',\n",
    "            'marital-status',\n",
    "            'relationship',\n",
    "            'gender',\n",
    "            'education',\n",
    "            'native-country',\n",
    "            'occupation',\n",
    "            'educational-num'\n",
    "        ]\n",
    "    elif 'covertype' in dataset:\n",
    "        continuous_cols = ['Elevation', 'Aspect', 'Slope', \n",
    "                           'Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology',\n",
    "                           'Horizontal_Distance_To_Roadways', 'Hillshade_9am', 'Hillshade_Noon', \n",
    "                           'Hillshade_3pm', 'Horizontal_Distance_To_Fire_Points']\n",
    "        discrete_columns = list(set(df.columns) - set(continuous_cols))\n",
    "        \n",
    "    from CTABGAN.model.ctabgan import CTABGAN\n",
    "    \n",
    "    output_folder = '../output/{}/{}/'.format(dataset, name)\n",
    "    os.makedirs(output_folder)\n",
    "    \n",
    "    if 'Chicago' in dataset:\n",
    "        synthesizer =  CTABGAN(raw_csv_path = '../data/{}/data.csv'.format(dataset),\n",
    "                         test_ratio = 0.2,\n",
    "                         categorical_columns = discrete_columns, \n",
    "                         log_columns = [],\n",
    "                         mixed_columns= {},\n",
    "                         integer_columns = ['age'],\n",
    "                         problem_type= {'Classification': 'choice'},\n",
    "                         epochs = 1000)\n",
    "    elif 'LPMC' in dataset:\n",
    "        synthesizer =  CTABGAN(raw_csv_path = '../data/{}/data.csv'.format(dataset),\n",
    "                     test_ratio = 0.2,\n",
    "                     categorical_columns = discrete_columns, \n",
    "                     log_columns = [],\n",
    "                     mixed_columns= {'dur_pt_rail': [0.0], 'dur_pt_bus': [0.0], 'dur_pt_int': [0.0], 'cost_transit': [0.0, 1.5]},\n",
    "                     integer_columns = ['age', 'distance'],\n",
    "                     problem_type= {'Classification': 'travel_mode'},\n",
    "                     epochs = 1000)\n",
    "    elif 'adult' in dataset:\n",
    "        synthesizer =  CTABGAN(raw_csv_path = '../data/{}/data.csv'.format(dataset),\n",
    "                     test_ratio = 0.2,\n",
    "                     categorical_columns = discrete_columns, \n",
    "                     log_columns = [],\n",
    "                     mixed_columns= {'capital-loss':[0.0],'capital-gain':[0.0]},\n",
    "                     integer_columns = ['age', 'capital-gain', 'capital-loss','hours-per-week'],\n",
    "                     problem_type= {\"Classification\": 'income'},\n",
    "                     epochs = 1000) \n",
    "    elif 'covertype' in dataset:\n",
    "        synthesizer =  CTABGAN(raw_csv_path = '../data/{}/data.csv'.format(dataset),\n",
    "                     test_ratio = 0.2,\n",
    "                     categorical_columns = discrete_columns, \n",
    "                     log_columns = [],\n",
    "                     mixed_columns= {},\n",
    "                     integer_columns = continuous_cols,\n",
    "                     problem_type= {\"Classification\": 'Cover_Type'},\n",
    "                     epochs = 1000) \n",
    "        \n",
    "    synthesizer.fit()\n",
    "    \n",
    "    with open(output_folder + 'trained.pickle', 'wb') as handle:\n",
    "        pickle.dump(synthesizer, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'adult'\n",
    "n_models = 5\n",
    "\n",
    "if 'adult' in dataset:\n",
    "    models = ['TGAN', 'CTGAN', 'TVAE', 'CTABGAN', 'WGGP_WI', 'WGAN_WI', 'LINEAR']\n",
    "elif 'covertype' in dataset:\n",
    "    models = ['TGAN', 'CTGAN', 'TVAE', 'CTABGAN']\n",
    "else:\n",
    "    models = ['TGAN', 'CTGAN', 'TVAE', 'CTABGAN']\n",
    "\n",
    "    for i in ['WGAN', 'WGGP', 'SGAN']:\n",
    "        for j in ['WI', 'OR', 'WO']:\n",
    "            models.append('{}_{}'.format(i,j))\n",
    "\n",
    "reuse_data = False\n",
    "        \n",
    "if n_models > 1:\n",
    "    tmp = []\n",
    "    \n",
    "    for i in range(n_models):\n",
    "        for m in models:\n",
    "            tmp.append(m + '_{:0>2d}'.format(i+1))\n",
    "        \n",
    "    tmp.sort()\n",
    "    models = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model \u001b[1mCTABGAN_01\u001b[0m (1/35) has already been trained.\n",
      "Model \u001b[1mCTABGAN_02\u001b[0m (2/35) has already been trained.\n",
      "Model \u001b[1mCTABGAN_03\u001b[0m (3/35) has already been trained.\n",
      "Model \u001b[1mCTABGAN_04\u001b[0m (4/35) has already been trained.\n",
      "Model \u001b[1mCTABGAN_05\u001b[0m (5/35) has already been trained.\n",
      "Model \u001b[1mCTGAN_01\u001b[0m (6/35) has already been trained.\n",
      "Model \u001b[1mCTGAN_02\u001b[0m (7/35) has already been trained.\n",
      "Model \u001b[1mCTGAN_03\u001b[0m (8/35) has already been trained.\n",
      "Model \u001b[1mCTGAN_04\u001b[0m (9/35) has already been trained.\n",
      "Model \u001b[1mCTGAN_05\u001b[0m (10/35) has already been trained.\n",
      "Training model \u001b[1mLINEAR_01\u001b[0m (11/35) ... Done in 41 minutes and 25 seconds.\n",
      "Training model \u001b[1mLINEAR_02\u001b[0m (12/35) ... Done in 41 minutes and 15 seconds.\n",
      "Training model \u001b[1mLINEAR_03\u001b[0m (13/35) ... Done in 41 minutes and 03 seconds.\n",
      "Training model \u001b[1mLINEAR_04\u001b[0m (14/35) ... Done in 41 minutes and 32 seconds.\n",
      "Training model \u001b[1mLINEAR_05\u001b[0m (15/35) ... Done in 41 minutes and 19 seconds.\n",
      "Model \u001b[1mTGAN_01\u001b[0m (16/35) has already been trained.\n",
      "Model \u001b[1mTGAN_02\u001b[0m (17/35) has already been trained.\n",
      "Model \u001b[1mTGAN_03\u001b[0m (18/35) has already been trained.\n",
      "Model \u001b[1mTGAN_04\u001b[0m (19/35) has already been trained.\n",
      "Model \u001b[1mTGAN_05\u001b[0m (20/35) has already been trained.\n",
      "Model \u001b[1mTVAE_01\u001b[0m (21/35) has already been trained.\n",
      "Model \u001b[1mTVAE_02\u001b[0m (22/35) has already been trained.\n",
      "Model \u001b[1mTVAE_03\u001b[0m (23/35) has already been trained.\n",
      "Model \u001b[1mTVAE_04\u001b[0m (24/35) has already been trained.\n",
      "Model \u001b[1mTVAE_05\u001b[0m (25/35) has already been trained.\n",
      "Model \u001b[1mWGAN_WI_01\u001b[0m (26/35) has already been trained.\n",
      "Model \u001b[1mWGAN_WI_02\u001b[0m (27/35) has already been trained.\n",
      "Model \u001b[1mWGAN_WI_03\u001b[0m (28/35) has already been trained.\n",
      "Model \u001b[1mWGAN_WI_04\u001b[0m (29/35) has already been trained.\n",
      "Model \u001b[1mWGAN_WI_05\u001b[0m (30/35) has already been trained.\n",
      "Model \u001b[1mWGGP_WI_01\u001b[0m (31/35) has already been trained.\n",
      "Model \u001b[1mWGGP_WI_02\u001b[0m (32/35) has already been trained.\n",
      "Model \u001b[1mWGGP_WI_03\u001b[0m (33/35) has already been trained.\n",
      "Model \u001b[1mWGGP_WI_04\u001b[0m (34/35) has already been trained.\n",
      "Model \u001b[1mWGGP_WI_05\u001b[0m (35/35) has already been trained.\n",
      "FINISHED!\n"
     ]
    }
   ],
   "source": [
    "for i, m in enumerate(models):\n",
    "    \n",
    "    if check_already_trained(dataset, m):\n",
    "        print(\"Model \\033[1m{}\\033[0m ({}/{}) has already been trained.\".format(m, i+1, len(models)))\n",
    "        \n",
    "    else:\n",
    "    \n",
    "        print(\"\\rTraining model \\033[1m{}\\033[0m ({}/{}) ... \".format(m, i+1, len(models)), end=\"\")\n",
    "        \n",
    "        # Cannot delete tensorflow modules sadly =(\n",
    "        tf.reset_default_graph()\n",
    "\n",
    "        delete_loaded_modules(init_modules)\n",
    "\n",
    "        if reuse_data and is_a_DATGAN(m):\n",
    "            copy_tree('../output/{}/{}/data'.format(dataset, 'WGAN_WI'), '../output/{}/{}/data'.format(dataset, m))\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        if 'CTGAN' in m:\n",
    "            with redirect_output('training.log'):\n",
    "                train_CTGAN(dataset, m)\n",
    "        elif 'TGAN' in m:\n",
    "            with redirect_output('training.log'):\n",
    "                train_TGAN(dataset, m)\n",
    "        elif 'TVAE' in m:\n",
    "            with redirect_output('training.log'):\n",
    "                train_TVAE(dataset, m) \n",
    "        elif 'CTABGAN' in m:\n",
    "            with redirect_output('training.log'):\n",
    "                train_CTABGAN(dataset, m)   \n",
    "        elif is_a_DATGAN(m):\n",
    "            with redirect_output('training.log'):\n",
    "                if 'LINEAR' in m:\n",
    "                    train_DATGAN(dataset, 'WGAN', m)\n",
    "                else:\n",
    "                    train_DATGAN(dataset, m.split('_')[0], m, m.split('_')[1])\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "\n",
    "        time_taken = time_to_str(elapsed)\n",
    "\n",
    "        print(\"Done in {}.\".format(time_taken))\n",
    "\n",
    "        for handler in logging.getLogger('tensorpack').handlers:\n",
    "            handler.close()\n",
    "\n",
    "        logging.getLogger('tensorpack').handlers = []\n",
    "\n",
    "print(\"FINISHED!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
