{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plot\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "import glob\n",
    "\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from modules.ml_efficacy.LGBMOrdinal_base import LGBMOrdinal, LGBMRegressor, LGBMClassifier, LightGBMCV, emse, emae\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# For the Python notebook\n",
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_real_df(df, cat_cols=None, ord_cols=None, cont_cols=None, enc=None):\n",
    "    if cat_cols and cont_cols:\n",
    "        df[cat_cols+ord_cols] = enc.fit_transform(df[cat_cols+ord_cols])\n",
    "    else:\n",
    "        print('Automated inference of column types to be implemented!')\n",
    "    return df\n",
    "\n",
    "def process_syn_df(df, cat_cols, ord_cols, cont_cols, enc=None):\n",
    "    df[cat_cols+ord_cols] = enc.transform(df[cat_cols+ord_cols])\n",
    "\n",
    "    return df\n",
    "\n",
    "def check_low_appearing_vars(df):\n",
    "    \n",
    "    for c in df.columns:\n",
    "        val = df[c].value_counts()\n",
    "        if len(val) < 20:\n",
    "            val = val/len(df)\n",
    "            if any(val < 0.01) and c != 'choice':\n",
    "                print(c)\n",
    "                print(val)\n",
    "                print()\n",
    "                \n",
    "def replace_low_appearing_values(df, dataset):\n",
    "    \n",
    "    if 'Chicago' in dataset:\n",
    "        dct_ = {}\n",
    "        for i in df['hh_vehicles'].unique():\n",
    "            if i >= 5:\n",
    "                dct_[i] = '5+'\n",
    "            else:\n",
    "                dct_[i] = str(i)        \n",
    "        df['hh_vehicles'].replace(dct_, inplace=True)\n",
    "        \n",
    "        dct_ = {}\n",
    "        for i in df['hh_size'].unique():\n",
    "            if i >= 6:\n",
    "                dct_[i] = '6+'\n",
    "            else:\n",
    "                dct_[i] = str(i)        \n",
    "        df['hh_size'].replace(dct_, inplace=True)\n",
    "        \n",
    "        dct_ = {}\n",
    "        for i in df['hh_bikes'].unique():\n",
    "            if i >= 6:\n",
    "                dct_[i] = '6+'\n",
    "            else:\n",
    "                dct_[i] = str(i)        \n",
    "        df['hh_bikes'].replace(dct_, inplace=True)   \n",
    "    \n",
    "    elif 'LPMC' in dataset:\n",
    "        dct_ = {}\n",
    "        for i in df['pt_n_interchanges'].unique():\n",
    "            if i >= 2:\n",
    "                dct_[i] = '2+'\n",
    "            else:\n",
    "                dct_[i] = str(i)        \n",
    "        df['pt_n_interchanges'].replace(dct_, inplace=True) \n",
    "        \n",
    "        dct_ = {\n",
    "            'Diesel_LGV': 'LGV',\n",
    "            'Petrol_LGV': 'LGV',\n",
    "            'Hybrid_Car': 'Average_Car'\n",
    "        }\n",
    "        df['fueltype'].replace(dct_, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'Chicago'\n",
    "\n",
    "input_folder = '../synth_data/{}/'.format(dataset)\n",
    "\n",
    "files_ = {}\n",
    "models = []\n",
    "\n",
    "for f in listdir(input_folder):\n",
    "    if isfile(join(input_folder, f)):\n",
    "        m = f.split('.')[0]\n",
    "        models.append(m)\n",
    "        files_[m] = join(input_folder, f)\n",
    "        \n",
    "models = ['WGAN_WI_01_NO_01', 'TEST']\n",
    "files_ = {}\n",
    "for m in models:\n",
    "    files_[m] = join(input_folder, m) + '.csv'\n",
    "        \n",
    "models.append('original')\n",
    "files_['original'] = '../data/' + dataset.split('_')[0] + '/data.csv' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['WGAN_WI_01_NO_01', 'TEST', 'original']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orig = pd.read_csv('../data/' + dataset.split('_')[0] + '/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_low_appearing_values(df_orig, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_low_appearing_vars(df_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Chicago' in dataset:\n",
    "    cont_cols = ['distance', 'age', 'departure_time']\n",
    "    ord_cols = ['hh_vehicles', 'hh_size', 'hh_bikes', 'hh_income', 'education_level']\n",
    "    cat_cols = [col for col in df_orig.columns if col not in cont_cols + ord_cols]\n",
    "elif 'LPMC' in dataset:\n",
    "    cont_cols = ['start_time_linear', 'age', 'distance', 'dur_walking', \n",
    "                 'dur_cycling', 'dur_pt_access', 'dur_pt_rail', 'dur_pt_bus', \n",
    "                 'dur_pt_int', 'dur_driving', 'cost_transit', \n",
    "                 'cost_driving_fuel', 'driving_traffic_percent']\n",
    "    ord_cols = ['travel_year', 'travel_month', 'travel_date', \n",
    "                'day_of_week', 'pt_n_interchanges', 'car_ownership']\n",
    "    cat_cols = [col for col in df_orig.columns if col not in cont_cols + ord_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OrdinalEncoder()\n",
    "ori = process_real_df(df_orig, cat_cols, ord_cols, cont_cols, enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No previous results found, starting fresh\n"
     ]
    }
   ],
   "source": [
    "filepath = './notebooks/tests/ml_efficacy/'\n",
    "filename = 'cv_result_{}.pickle'.format(dataset)\n",
    "cv_modelscores = {}\n",
    "params={'n_estimators': 5000}\n",
    "\n",
    "try:\n",
    "    cv_modelscores = pickle.load(open(f'{filepath}{filename}','rb'))\n",
    "    print('Found previous pickel file, using that')\n",
    "except:\n",
    "    print('No previous results found, starting fresh')\n",
    "    try:\n",
    "        os.makedirs(filepath)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting results for WGAN_WI_01_NO_01\n",
      "Getting results for TEST           \n",
      "Getting results for original       \n",
      "\u001b[1mFINISHED!\u001b[0m                  \n"
     ]
    }
   ],
   "source": [
    "for i, model in enumerate(models):\n",
    "    \n",
    "    tmp_df = pd.read_csv(files_[model])\n",
    "    replace_low_appearing_values(tmp_df, dataset)\n",
    "    v_df = process_syn_df(tmp_df, cat_cols, ord_cols, cont_cols, enc)\n",
    "        \n",
    "    if model in cv_modelscores:\n",
    "        print(f'Previous results for {model}')\n",
    "    else:\n",
    "        print(f'Getting results for {model}')\n",
    "        cv_modelscores[model] = {}\n",
    "        for j, ycol in enumerate(ori.columns):\n",
    "            info = '    Column: {} ({}/{})'.format(ycol, j+1, len(ori.columns))\n",
    "            print(info, end=\"\")\n",
    "            sys.stdout.flush()\n",
    "            \n",
    "            Xcols = [c for c in ori.columns if c!=ycol]\n",
    "\n",
    "            y_synth = v_df[ycol]\n",
    "            X_synth = v_df[Xcols]\n",
    "            y_real = ori[ycol]\n",
    "            X_real = ori[Xcols]\n",
    "\n",
    "\n",
    "            observe_sets = {'original': (X_real, y_real)}\n",
    "            ccols = [c for c in cat_cols if c!=ycol]\n",
    "\n",
    "\n",
    "            if ycol in cat_cols + ord_cols:\n",
    "                lgbm_type = 'LGBMClassifier'\n",
    "                kf = StratifiedKFold(shuffle=True, random_state=42)\n",
    "                eval_metric = ['error']\n",
    "            elif ycol in cont_cols:\n",
    "                lgbm_type = 'LGBMRegressor'\n",
    "                kf = KFold(shuffle=True, random_state=42)\n",
    "                eval_metric = ['l2', 'l1']\n",
    "            cv = LightGBMCV(lgbm_type=lgbm_type,\n",
    "                splitter = kf,\n",
    "                eval_metric = eval_metric,\n",
    "                observe_sets = observe_sets,\n",
    "                separate_observation_split = True,\n",
    "                early_stopping_rounds = 5,\n",
    "                return_cv_models = False,\n",
    "                refit_model = False,\n",
    "                verbose = True)\n",
    "            cv.fit(X_synth, y_synth, categorical_feature=ccols, params=params)\n",
    "            cv_modelscores[model][ycol] = cv.result_dict_\n",
    "            \n",
    "            print(' '*len(info), end='\\r')\n",
    "\n",
    "            if j == len(ori.columns):\n",
    "                print('', end='\\r')\n",
    "            \n",
    "        pickle.dump(cv_modelscores,open(f'{filepath}/{filename}','wb'))\n",
    "\n",
    "        \n",
    "print(\"\\033[1mFINISHED!\\033[0m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "internal = {}\n",
    "external = {}\n",
    "external_normalised = {}\n",
    "cont_scores = {}\n",
    "cat_scores = {}\n",
    "ori_scores = {col: cv_modelscores['original'][col]['test_log_loss'] for col in cat_cols + ord_cols}\n",
    "ori_scores.update({col: cv_modelscores['original'][col]['test_l2'] for col in cont_cols})\n",
    "for model in models:\n",
    "    internal[model] = {col: cv_modelscores[model][col]['test_log_loss'] for col in cat_cols + ord_cols}\n",
    "    external[model] = {col: cv_modelscores[model][col]['original_log_loss'] for col in cat_cols + ord_cols}\n",
    "    external_normalised[model] = {col: external[model][col]-ori_scores[col] for col in cat_cols + ord_cols}\n",
    "    \n",
    "    internal[model].update({col: cv_modelscores[model][col]['test_l2'] for col in cont_cols})\n",
    "    external[model].update({col: cv_modelscores[model][col]['original_l2'] for col in cont_cols})\n",
    "    external_normalised[model].update({col: external[model][col]/ori_scores[col] for col in cont_cols})\n",
    "    \n",
    "    cont_scores[model] = sum([external[model][col]/ori_scores[col] for col in cont_cols])\n",
    "    cat_scores[model] = sum([external[model][col]-ori_scores[col] for col in cat_cols + ord_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(external_normalised).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('{}/model_scores_external_{}.csv'.format(filepath, dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_sorted = sorted(cat_scores.items(), key=lambda item: item[1])\n",
    "cont_sorted = sorted(cont_scores.items(), key=lambda item: item[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   | categorical                    | continuous                    \n",
      "-----------------------------------------------------------\n",
      " 1 | original    : -2.111           | original    : 2.559           \n",
      " 2 | TEST        : 0.730            | TEST        : 3.061           \n",
      " 3 | WGAN_WI_01_NO_01: 0.875        | WGAN_WI_01_NO_01: 3.117       \n"
     ]
    }
   ],
   "source": [
    "i=1\n",
    "print('   | {:<30} | {:<30}'.format('categorical', 'continuous'))\n",
    "print('-----------------------------------------------------------')\n",
    "for a, b in zip(cat_sorted, cont_sorted):\n",
    "    print('{:>2} | {:<30} | {:<30}'.format(i, '{:<12}: {:.3f}'.format(a[0], a[1]), '{:<12}: {:.3f}'.format(b[0], b[1])))\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
