{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plot\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "import glob\n",
    "\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from modules.ml_efficacy.LGBMOrdinal_base import LGBMOrdinal, LGBMRegressor, LGBMClassifier, LightGBMCV, emse, emae\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# For the Python notebook\n",
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_real_df(df, cat_cols=None, ord_cols=None, cont_cols=None, enc=None):\n",
    "    if cat_cols and cont_cols:\n",
    "        df[cat_cols+ord_cols] = enc.fit_transform(df[cat_cols+ord_cols])\n",
    "    else:\n",
    "        print('Automated inference of column types to be implemented!')\n",
    "    return df\n",
    "\n",
    "def process_syn_df(df, cat_cols, ord_cols, cont_cols, enc=None):\n",
    "    df[cat_cols+ord_cols] = enc.transform(df[cat_cols+ord_cols])\n",
    "\n",
    "    return df\n",
    "\n",
    "def check_low_appearing_vars(df):\n",
    "    \n",
    "    for c in df.columns:\n",
    "        val = df[c].value_counts()\n",
    "        if len(val) < 20:\n",
    "            val = val/len(df)\n",
    "            if any(val < 0.01) and c != 'choice':\n",
    "                print(c)\n",
    "                print(val)\n",
    "                print()\n",
    "                \n",
    "def replace_low_appearing_values(df, dataset):\n",
    "    \n",
    "    if 'Chicago' in dataset:\n",
    "        dct_ = {}\n",
    "        for i in df['hh_vehicles'].unique():\n",
    "            if i >= 5:\n",
    "                dct_[i] = '5+'\n",
    "            else:\n",
    "                dct_[i] = str(i)        \n",
    "        df['hh_vehicles'].replace(dct_, inplace=True)\n",
    "        \n",
    "        dct_ = {}\n",
    "        for i in df['hh_size'].unique():\n",
    "            if i >= 6:\n",
    "                dct_[i] = '6+'\n",
    "            else:\n",
    "                dct_[i] = str(i)        \n",
    "        df['hh_size'].replace(dct_, inplace=True)\n",
    "        \n",
    "        dct_ = {}\n",
    "        for i in df['hh_bikes'].unique():\n",
    "            if i >= 6:\n",
    "                dct_[i] = '6+'\n",
    "            else:\n",
    "                dct_[i] = str(i)        \n",
    "        df['hh_bikes'].replace(dct_, inplace=True)   \n",
    "    \n",
    "    elif 'LPMC' in dataset:\n",
    "        dct_ = {}\n",
    "        for i in df['pt_n_interchanges'].unique():\n",
    "            if i >= 2:\n",
    "                dct_[i] = '2+'\n",
    "            else:\n",
    "                dct_[i] = str(i)        \n",
    "        df['pt_n_interchanges'].replace(dct_, inplace=True) \n",
    "        \n",
    "        dct_ = {\n",
    "            'Diesel_LGV': 'LGV',\n",
    "            'Petrol_LGV': 'LGV',\n",
    "            'Hybrid_Car': 'Average_Car'\n",
    "        }\n",
    "        df['fueltype'].replace(dct_, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'LPMC'\n",
    "\n",
    "input_folder = '../synth_data/TEST/'\n",
    "\n",
    "files_ = {}\n",
    "models = []\n",
    "\n",
    "for f in listdir(input_folder):\n",
    "    if isfile(join(input_folder, f)):\n",
    "        m = f.split('.')[0]\n",
    "        models.append(m)\n",
    "        files_[m] = join(input_folder, f)\n",
    "        \n",
    "models.append('original')\n",
    "files_['original'] = '../data/' + dataset.split('_')[0] + '/data.csv' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CTABGAN', 'CTGAN', 'DATGAN', 'original']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orig = pd.read_csv('../data/' + dataset.split('_')[0] + '/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>travel_mode</th>\n",
       "      <th>purpose</th>\n",
       "      <th>fueltype</th>\n",
       "      <th>faretype</th>\n",
       "      <th>bus_scale</th>\n",
       "      <th>travel_year</th>\n",
       "      <th>travel_month</th>\n",
       "      <th>travel_date</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>start_time_linear</th>\n",
       "      <th>...</th>\n",
       "      <th>dur_pt_access</th>\n",
       "      <th>dur_pt_rail</th>\n",
       "      <th>dur_pt_bus</th>\n",
       "      <th>dur_pt_int</th>\n",
       "      <th>pt_n_interchanges</th>\n",
       "      <th>dur_driving</th>\n",
       "      <th>cost_transit</th>\n",
       "      <th>cost_driving_fuel</th>\n",
       "      <th>cost_driving_con_charge</th>\n",
       "      <th>driving_traffic_percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>drive</td>\n",
       "      <td>HBO</td>\n",
       "      <td>Petrol_Car</td>\n",
       "      <td>child</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2012</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.134444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.052222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.111702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>drive</td>\n",
       "      <td>HBO</td>\n",
       "      <td>Petrol_Car</td>\n",
       "      <td>free</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2012</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>17.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.241389</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.122222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.132222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.065126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>drive</td>\n",
       "      <td>HBO</td>\n",
       "      <td>Petrol_Car</td>\n",
       "      <td>full</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2012</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.257500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.873889</td>\n",
       "      <td>0.089444</td>\n",
       "      <td>1</td>\n",
       "      <td>0.508333</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.356831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pt</td>\n",
       "      <td>HBW</td>\n",
       "      <td>Average_Car</td>\n",
       "      <td>full</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2012</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>21.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.123889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.208056</td>\n",
       "      <td>0.091667</td>\n",
       "      <td>1</td>\n",
       "      <td>0.115556</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pt</td>\n",
       "      <td>HBO</td>\n",
       "      <td>Average_Car</td>\n",
       "      <td>free</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2012</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>8.916667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.171389</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.334444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.196389</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.035361</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  travel_mode purpose     fueltype faretype  bus_scale  travel_year  \\\n",
       "0       drive     HBO   Petrol_Car    child        0.0         2012   \n",
       "1       drive     HBO   Petrol_Car     free        0.0         2012   \n",
       "2       drive     HBO   Petrol_Car     full        1.0         2012   \n",
       "3          pt     HBW  Average_Car     full        1.0         2012   \n",
       "4          pt     HBO  Average_Car     free        0.0         2012   \n",
       "\n",
       "   travel_month  travel_date  day_of_week  start_time_linear  ...  \\\n",
       "0             4            1            7          10.000000  ...   \n",
       "1             4            1            7          17.666667  ...   \n",
       "2             4            1            7          13.000000  ...   \n",
       "3             4            1            7          21.500000  ...   \n",
       "4             4            1            7           8.916667  ...   \n",
       "\n",
       "   dur_pt_access  dur_pt_rail  dur_pt_bus  dur_pt_int  pt_n_interchanges  \\\n",
       "0       0.134444          0.0    0.016667    0.000000                  0   \n",
       "1       0.241389          0.0    0.122222    0.000000                  0   \n",
       "2       0.257500          0.0    0.873889    0.089444                  1   \n",
       "3       0.123889          0.0    0.208056    0.091667                  1   \n",
       "4       0.171389          0.0    0.334444    0.000000                  0   \n",
       "\n",
       "   dur_driving  cost_transit  cost_driving_fuel  cost_driving_con_charge  \\\n",
       "0     0.052222           0.0               0.14                      0.0   \n",
       "1     0.132222           0.0               0.50                      0.0   \n",
       "2     0.508333           3.0               1.59                      0.0   \n",
       "3     0.115556           3.0               0.33                      0.0   \n",
       "4     0.196389           0.0               0.53                      0.0   \n",
       "\n",
       "   driving_traffic_percent  \n",
       "0                 0.111702  \n",
       "1                 0.065126  \n",
       "2                 0.356831  \n",
       "3                 0.033654  \n",
       "4                 0.035361  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_orig.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_low_appearing_values(df_orig, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_low_appearing_vars(df_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Chicago' in dataset:\n",
    "    cont_cols = ['distance', 'age', 'departure_time']\n",
    "    ord_cols = ['hh_vehicles', 'hh_size', 'hh_bikes', 'hh_income', 'education_level']\n",
    "    cat_cols = [col for col in df_orig.columns if col not in cont_cols + ord_cols]\n",
    "elif 'LPMC' in dataset:\n",
    "    cont_cols = ['start_time_linear', 'age', 'distance', 'dur_walking', \n",
    "                 'dur_cycling', 'dur_pt_access', 'dur_pt_rail', 'dur_pt_bus', \n",
    "                 'dur_pt_int', 'dur_driving', 'cost_transit', \n",
    "                 'cost_driving_fuel', 'driving_traffic_percent']\n",
    "    ord_cols = ['travel_year', 'travel_month', 'travel_date', \n",
    "                'day_of_week', 'pt_n_interchanges', 'car_ownership']\n",
    "    cat_cols = [col for col in df_orig.columns if col not in cont_cols + ord_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OrdinalEncoder()\n",
    "ori = process_real_df(df_orig, cat_cols, ord_cols, cont_cols, enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No previous results found, starting fresh\n"
     ]
    }
   ],
   "source": [
    "filepath = './notebooks/tests/ml_efficacy/'\n",
    "filename = 'cv_result.pickle'\n",
    "cv_modelscores = {}\n",
    "params={'n_estimators': 5000}\n",
    "\n",
    "try:\n",
    "    cv_modelscores = pickle.load(open(f'{filepath}{filename}','rb'))\n",
    "    print('Found previous pickel file, using that')\n",
    "except:\n",
    "    print('No previous results found, starting fresh')\n",
    "    try:\n",
    "        os.makedirs(filepath)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting results for CTABGAN\n",
      "Getting results for CTGAN                  \n",
      "Getting results for DATGAN                 \n",
      "Getting results for original               \n",
      "\u001b[1mFINISHED!\u001b[0m                          \n"
     ]
    }
   ],
   "source": [
    "for i, model in enumerate(models):\n",
    "    \n",
    "    tmp_df = pd.read_csv(files_[model])\n",
    "    replace_low_appearing_values(tmp_df, dataset)\n",
    "    v_df = process_syn_df(tmp_df, cat_cols, ord_cols, cont_cols, enc)\n",
    "        \n",
    "    if model in cv_modelscores:\n",
    "        print(f'Previous results for {model}')\n",
    "    else:\n",
    "        print(f'Getting results for {model}')\n",
    "        cv_modelscores[model] = {}\n",
    "        for j, ycol in enumerate(ori.columns):\n",
    "            info = '    Column: {} ({}/{})'.format(ycol, j+1, len(ori.columns))\n",
    "            print(info, end=\"\")\n",
    "            sys.stdout.flush()\n",
    "            \n",
    "            Xcols = [c for c in ori.columns if c!=ycol]\n",
    "\n",
    "            y_synth = v_df[ycol]\n",
    "            X_synth = v_df[Xcols]\n",
    "            y_real = ori[ycol]\n",
    "            X_real = ori[Xcols]\n",
    "\n",
    "\n",
    "            observe_sets = {'original': (X_real, y_real)}\n",
    "            ccols = [c for c in cat_cols if c!=ycol]\n",
    "\n",
    "\n",
    "            if ycol in cat_cols + ord_cols:\n",
    "                lgbm_type = 'LGBMClassifier'\n",
    "                kf = StratifiedKFold(shuffle=True, random_state=42)\n",
    "                eval_metric = ['error']\n",
    "            elif ycol in cont_cols:\n",
    "                lgbm_type = 'LGBMRegressor'\n",
    "                kf = KFold(shuffle=True, random_state=42)\n",
    "                eval_metric = ['l2', 'l1']\n",
    "            cv = LightGBMCV(lgbm_type=lgbm_type,\n",
    "                splitter = kf,\n",
    "                eval_metric = eval_metric,\n",
    "                observe_sets = observe_sets,\n",
    "                separate_observation_split = True,\n",
    "                early_stopping_rounds = 5,\n",
    "                return_cv_models = False,\n",
    "                refit_model = False,\n",
    "                verbose = True)\n",
    "            cv.fit(X_synth, y_synth, categorical_feature=ccols, params=params)\n",
    "            cv_modelscores[model][ycol] = cv.result_dict_\n",
    "            \n",
    "            print(' '*len(info), end='\\r')\n",
    "\n",
    "            if j == len(ori.columns):\n",
    "                print('', end='\\r')\n",
    "            \n",
    "        pickle.dump(cv_modelscores,open(f'{filepath}/{filename}','wb'))\n",
    "\n",
    "        \n",
    "print(\"\\033[1mFINISHED!\\033[0m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cv_modelscores.pop('CTABGAN')\n",
    "#pickle.dump(cv_modelscores,open(f'{filepath}/{filename}','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "internal = {}\n",
    "external = {}\n",
    "external_normalised = {}\n",
    "cont_scores = {}\n",
    "cat_scores = {}\n",
    "ori_scores = {col: cv_modelscores['original'][col]['test_log_loss'] for col in cat_cols + ord_cols}\n",
    "ori_scores.update({col: cv_modelscores['original'][col]['test_l2'] for col in cont_cols})\n",
    "for model in models:\n",
    "    internal[model] = {col: cv_modelscores[model][col]['test_log_loss'] for col in cat_cols + ord_cols}\n",
    "    external[model] = {col: cv_modelscores[model][col]['original_log_loss'] for col in cat_cols + ord_cols}\n",
    "    external_normalised[model] = {col: external[model][col]-ori_scores[col] for col in cat_cols + ord_cols}\n",
    "    \n",
    "    internal[model].update({col: cv_modelscores[model][col]['test_l2'] for col in cont_cols})\n",
    "    external[model].update({col: cv_modelscores[model][col]['original_l2'] for col in cont_cols})\n",
    "    external_normalised[model].update({col: external[model][col]/ori_scores[col] for col in cont_cols})\n",
    "    \n",
    "    cont_scores[model] = sum([external[model][col]/ori_scores[col] for col in cont_cols])\n",
    "    cat_scores[model] = sum([external[model][col]-ori_scores[col] for col in cat_cols + ord_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_sorted = sorted(cat_scores.items(), key=lambda item: item[1])\n",
    "cont_sorted = sorted(cont_scores.items(), key=lambda item: item[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   | categorical                    | continuous                    \n",
      "-----------------------------------------------------------\n",
      " 1 | original    : -3.596           | original    : 9.249           \n",
      " 2 | DATGAN      : 2.243            | DATGAN      : 21.907          \n",
      " 3 | CTGAN       : 2.904            | CTABGAN     : 33.756          \n",
      " 4 | CTABGAN     : 5.595            | CTGAN       : 39.943          \n"
     ]
    }
   ],
   "source": [
    "i=1\n",
    "print('   | {:<30} | {:<30}'.format('categorical', 'continuous'))\n",
    "print('-----------------------------------------------------------')\n",
    "for a, b in zip(cat_sorted, cont_sorted):\n",
    "    print('{:>2} | {:<30} | {:<30}'.format(i, '{:<12}: {:.3f}'.format(a[0], a[1]), '{:<12}: {:.3f}'.format(b[0], b[1])))\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
