{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\glede\\anaconda3\\envs\\py37\\lib\\site-packages\\ipykernel_launcher.py:6: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from collections import Iterable\n",
    "import random\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import matplotlib.patches as mpatches\n",
    "import pickle\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# For the Python notebook\n",
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculations for stats and plots are based on: https://github.com/stasmix/popsynth/blob/master/pop-synth-vae.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_a_DATGAN(name):\n",
    "    if 'TGAN' in name or 'CTGAN' in name:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "def compute_stats(freq_list_orig, freq_list_synth):\n",
    "    \"\"\"\n",
    "    Different statistics computed on the frequency list\n",
    "    \n",
    "    \"\"\"\n",
    "    freq_list_orig, freq_list_synth = np.array(freq_list_orig), np.array(freq_list_synth)\n",
    "    corr_mat = np.corrcoef(freq_list_orig, freq_list_synth)\n",
    "    corr = corr_mat[0, 1]\n",
    "    if np.isnan(corr): corr = 0.0\n",
    "    # MAE\n",
    "    mae = np.absolute(freq_list_orig - freq_list_synth).mean()\n",
    "    # RMSE\n",
    "    rmse = np.linalg.norm(freq_list_orig - freq_list_synth) / np.sqrt(len(freq_list_orig))\n",
    "    # SRMSE\n",
    "    freq_list_orig_avg = freq_list_orig.mean()\n",
    "    srmse = rmse / freq_list_orig_avg\n",
    "    # r-square\n",
    "    u = np.sum((freq_list_synth - freq_list_orig)**2)\n",
    "    v = np.sum((freq_list_orig - freq_list_orig_avg)**2)\n",
    "    r2 = 1.0 - u / v\n",
    "    stat = {'mae': mae, 'rmse': rmse, 'r2': r2, 'srmse': srmse, 'corr': corr}\n",
    "    \n",
    "    return stat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'LPMC'\n",
    "\n",
    "input_folder = '../synth_data/TEST/'\n",
    "\n",
    "files_ = {}\n",
    "models = []\n",
    "\n",
    "for f in listdir(input_folder):\n",
    "    if isfile(join(input_folder, f)):\n",
    "        m = f.split('.')[0]\n",
    "        models.append(m)\n",
    "        files_[m] = join(input_folder, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_orig = pd.read_csv('../data/' + dataset + '/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "travel_mode                  object\n",
       "purpose                      object\n",
       "fueltype                     object\n",
       "faretype                     object\n",
       "bus_scale                   float64\n",
       "travel_year                   int64\n",
       "travel_month                  int64\n",
       "travel_date                   int64\n",
       "day_of_week                   int64\n",
       "start_time_linear          category\n",
       "age                        category\n",
       "female                        int64\n",
       "driving_license               int64\n",
       "car_ownership                 int64\n",
       "distance                   category\n",
       "dur_walking                category\n",
       "dur_cycling                category\n",
       "dur_pt_access              category\n",
       "dur_pt_rail                category\n",
       "dur_pt_bus                 category\n",
       "dur_pt_int                 category\n",
       "pt_n_interchanges             int64\n",
       "dur_driving                category\n",
       "cost_transit               category\n",
       "cost_driving_fuel          category\n",
       "cost_driving_con_charge     float64\n",
       "driving_traffic_percent    category\n",
       "dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_orig.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset is 'Chicago':\n",
    "    continuous_cols = ['distance', 'age', 'departure_time']\n",
    "elif dataset is 'LPMC':\n",
    "    continuous_cols = ['start_time_linear', 'age', 'distance', 'dur_walking', 'dur_cycling', 'dur_pt_access', 'dur_pt_rail', 'dur_pt_bus', 'dur_pt_int', 'dur_driving', 'cost_transit', 'cost_driving_fuel', 'driving_traffic_percent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins_cont = {}\n",
    "\n",
    "for c in continuous_cols:\n",
    "    #bins_cont[c] = pd.qcut(df_orig[c], q=10, retbins=True)[1]\n",
    "    bins_cont[c] = pd.cut(df_orig[c], bins=10, retbins=True)[1]\n",
    "    bins_cont[c][0] = -np.inf\n",
    "    bins_cont[c][-1] = np.inf\n",
    "    df_orig[c] = pd.cut(df_orig[c], bins=bins_cont[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>travel_mode</th>\n",
       "      <th>purpose</th>\n",
       "      <th>fueltype</th>\n",
       "      <th>faretype</th>\n",
       "      <th>bus_scale</th>\n",
       "      <th>travel_year</th>\n",
       "      <th>travel_month</th>\n",
       "      <th>travel_date</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>start_time_linear</th>\n",
       "      <th>...</th>\n",
       "      <th>dur_pt_access</th>\n",
       "      <th>dur_pt_rail</th>\n",
       "      <th>dur_pt_bus</th>\n",
       "      <th>dur_pt_int</th>\n",
       "      <th>pt_n_interchanges</th>\n",
       "      <th>dur_driving</th>\n",
       "      <th>cost_transit</th>\n",
       "      <th>cost_driving_fuel</th>\n",
       "      <th>cost_driving_con_charge</th>\n",
       "      <th>driving_traffic_percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>drive</td>\n",
       "      <td>HBO</td>\n",
       "      <td>Petrol_Car</td>\n",
       "      <td>child</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2012</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>(9.567, 11.958]</td>\n",
       "      <td>...</td>\n",
       "      <td>(0.106, 0.212]</td>\n",
       "      <td>(-inf, 0.137]</td>\n",
       "      <td>(-inf, 0.215]</td>\n",
       "      <td>(-inf, 0.0567]</td>\n",
       "      <td>0</td>\n",
       "      <td>(-inf, 0.183]</td>\n",
       "      <td>(-inf, 1.17]</td>\n",
       "      <td>(-inf, 1.027]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(0.104, 0.208]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>drive</td>\n",
       "      <td>HBO</td>\n",
       "      <td>Petrol_Car</td>\n",
       "      <td>free</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2012</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>(16.742, 19.133]</td>\n",
       "      <td>...</td>\n",
       "      <td>(0.212, 0.318]</td>\n",
       "      <td>(-inf, 0.137]</td>\n",
       "      <td>(-inf, 0.215]</td>\n",
       "      <td>(-inf, 0.0567]</td>\n",
       "      <td>0</td>\n",
       "      <td>(-inf, 0.183]</td>\n",
       "      <td>(-inf, 1.17]</td>\n",
       "      <td>(-inf, 1.027]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(-inf, 0.104]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>drive</td>\n",
       "      <td>HBO</td>\n",
       "      <td>Petrol_Car</td>\n",
       "      <td>full</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2012</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>(11.958, 14.35]</td>\n",
       "      <td>...</td>\n",
       "      <td>(0.212, 0.318]</td>\n",
       "      <td>(-inf, 0.137]</td>\n",
       "      <td>(0.859, 1.074]</td>\n",
       "      <td>(0.0567, 0.113]</td>\n",
       "      <td>1</td>\n",
       "      <td>(0.362, 0.54]</td>\n",
       "      <td>(2.34, 3.51]</td>\n",
       "      <td>(1.027, 2.034]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(0.313, 0.417]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pt</td>\n",
       "      <td>HBW</td>\n",
       "      <td>Average_Car</td>\n",
       "      <td>full</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2012</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>(19.133, 21.525]</td>\n",
       "      <td>...</td>\n",
       "      <td>(0.106, 0.212]</td>\n",
       "      <td>(-inf, 0.137]</td>\n",
       "      <td>(-inf, 0.215]</td>\n",
       "      <td>(0.0567, 0.113]</td>\n",
       "      <td>1</td>\n",
       "      <td>(-inf, 0.183]</td>\n",
       "      <td>(2.34, 3.51]</td>\n",
       "      <td>(-inf, 1.027]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(-inf, 0.104]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pt</td>\n",
       "      <td>HBO</td>\n",
       "      <td>Average_Car</td>\n",
       "      <td>free</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2012</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>(7.175, 9.567]</td>\n",
       "      <td>...</td>\n",
       "      <td>(0.106, 0.212]</td>\n",
       "      <td>(-inf, 0.137]</td>\n",
       "      <td>(0.215, 0.429]</td>\n",
       "      <td>(-inf, 0.0567]</td>\n",
       "      <td>0</td>\n",
       "      <td>(0.183, 0.362]</td>\n",
       "      <td>(-inf, 1.17]</td>\n",
       "      <td>(-inf, 1.027]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(-inf, 0.104]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  travel_mode purpose     fueltype faretype  bus_scale  travel_year  \\\n",
       "0       drive     HBO   Petrol_Car    child        0.0         2012   \n",
       "1       drive     HBO   Petrol_Car     free        0.0         2012   \n",
       "2       drive     HBO   Petrol_Car     full        1.0         2012   \n",
       "3          pt     HBW  Average_Car     full        1.0         2012   \n",
       "4          pt     HBO  Average_Car     free        0.0         2012   \n",
       "\n",
       "   travel_month  travel_date  day_of_week start_time_linear  ...  \\\n",
       "0             4            1            7   (9.567, 11.958]  ...   \n",
       "1             4            1            7  (16.742, 19.133]  ...   \n",
       "2             4            1            7   (11.958, 14.35]  ...   \n",
       "3             4            1            7  (19.133, 21.525]  ...   \n",
       "4             4            1            7    (7.175, 9.567]  ...   \n",
       "\n",
       "    dur_pt_access    dur_pt_rail      dur_pt_bus       dur_pt_int  \\\n",
       "0  (0.106, 0.212]  (-inf, 0.137]   (-inf, 0.215]   (-inf, 0.0567]   \n",
       "1  (0.212, 0.318]  (-inf, 0.137]   (-inf, 0.215]   (-inf, 0.0567]   \n",
       "2  (0.212, 0.318]  (-inf, 0.137]  (0.859, 1.074]  (0.0567, 0.113]   \n",
       "3  (0.106, 0.212]  (-inf, 0.137]   (-inf, 0.215]  (0.0567, 0.113]   \n",
       "4  (0.106, 0.212]  (-inf, 0.137]  (0.215, 0.429]   (-inf, 0.0567]   \n",
       "\n",
       "  pt_n_interchanges     dur_driving  cost_transit cost_driving_fuel  \\\n",
       "0                 0   (-inf, 0.183]  (-inf, 1.17]     (-inf, 1.027]   \n",
       "1                 0   (-inf, 0.183]  (-inf, 1.17]     (-inf, 1.027]   \n",
       "2                 1   (0.362, 0.54]  (2.34, 3.51]    (1.027, 2.034]   \n",
       "3                 1   (-inf, 0.183]  (2.34, 3.51]     (-inf, 1.027]   \n",
       "4                 0  (0.183, 0.362]  (-inf, 1.17]     (-inf, 1.027]   \n",
       "\n",
       "  cost_driving_con_charge driving_traffic_percent  \n",
       "0                     0.0          (0.104, 0.208]  \n",
       "1                     0.0           (-inf, 0.104]  \n",
       "2                     0.0          (0.313, 0.417]  \n",
       "3                     0.0           (-inf, 0.104]  \n",
       "4                     0.0           (-inf, 0.104]  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_orig.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_str = ['mae', 'rmse', 'r2', 'srmse', 'corr']\n",
    "orig_str = 'random-original'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stats per individual column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No previous results found, starting fresh\n"
     ]
    }
   ],
   "source": [
    "filepath = './notebooks/tests/stats/'\n",
    "filename = 'single_columns.pickle'.format(dataset)\n",
    "\n",
    "all_stats = {}\n",
    "\n",
    "try:\n",
    "    all_stats = pickle.load(open(filepath + filename, 'rb'))\n",
    "    print('Found previous pickel file, using that')\n",
    "except:\n",
    "    print('No previous results found, starting fresh')\n",
    "    try:\n",
    "        os.makedirs(filepath)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing stats for model \u001b[1mCTABGAN\u001b[0m (1/3)\n",
      "Preparing stats for model \u001b[1mCTGAN\u001b[0m (2/3)\n",
      "Preparing stats for model \u001b[1mDATGAN\u001b[0m (3/3)\n",
      "\u001b[1mFINISHED!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Go through each model\n",
    "for i, m in enumerate(models):\n",
    "    \n",
    "    if m in all_stats:\n",
    "        print(\"Results for model \\033[1m{}\\033[0m ({}/{}) already exists!\".format(m, i+1, len(models)))\n",
    "\n",
    "    else:\n",
    "        print(\"Preparing stats for model \\033[1m{}\\033[0m ({}/{})\".format(m, i+1, len(models)))\n",
    "\n",
    "        all_stats[m] = {}\n",
    "\n",
    "        # Load all dataframes for current model\n",
    "        df = pd.read_csv(files_[m])\n",
    "\n",
    "        # Discretize continuous columns\n",
    "        for c in continuous_cols:\n",
    "            df[c] = pd.cut(df[c], bins=bins_cont[c])\n",
    "\n",
    "        # Go through each columns\n",
    "        for c in df_orig.columns:\n",
    "\n",
    "            agg_vars = [c]\n",
    "\n",
    "            real = df_orig.copy()\n",
    "            real['count'] = 1\n",
    "            real = real.groupby(agg_vars, observed=True).count()\n",
    "            real /= len(df_orig)\n",
    "\n",
    "            synth = df.copy()\n",
    "            synth['count'] = 1\n",
    "            synth = synth.groupby(agg_vars, observed=True).count()\n",
    "            synth /= len(df)\n",
    "\n",
    "            real_and_sampled = pd.merge(real, synth, suffixes=['_real', '_sampled'], on=agg_vars, how='outer', indicator=True)\n",
    "            real_and_sampled = real_and_sampled[['count_real', 'count_sampled']].fillna(0)\n",
    "\n",
    "            sts = compute_stats(real_and_sampled['count_real'], real_and_sampled['count_sampled'])\n",
    "\n",
    "            all_stats[m][c] = sts\n",
    "            \n",
    "        pickle.dump(all_stats, open(filepath + filename, 'wb'))\n",
    "\n",
    "print(\"\\033[1mFINISHED!\\033[0m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_orig = {}\n",
    "\n",
    "train = df_orig.sample(int(len(df_orig) * 0.5))\n",
    "train.index = range(len(train))\n",
    "test = df_orig[~df_orig.index.isin(train.index)]\n",
    "test.index = range(len(test))\n",
    "\n",
    "# Go through each columns\n",
    "for c in df_orig.columns:\n",
    "\n",
    "    agg_vars = [c]\n",
    "\n",
    "    real = train.copy()\n",
    "    real['count'] = 1\n",
    "    real = real.groupby(agg_vars, observed=True).count()\n",
    "    real /= len(df_orig)\n",
    "\n",
    "    synth = test.copy()\n",
    "    synth['count'] = 1\n",
    "    synth = synth.groupby(agg_vars, observed=True).count()\n",
    "    synth /= len(df)\n",
    "\n",
    "    real_and_sampled = pd.merge(real, synth, suffixes=['_real', '_sampled'], on=agg_vars, how='outer', indicator=True)\n",
    "    real_and_sampled = real_and_sampled[['count_real', 'count_sampled']].fillna(0)\n",
    "\n",
    "    sts = compute_stats(real_and_sampled['count_real'], real_and_sampled['count_sampled'])\n",
    "    \n",
    "    stats_orig[c] = sts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stats[orig_str] = stats_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = {}\n",
    "\n",
    "for test in ['all', 'cont', 'cat']:\n",
    "    \n",
    "    res[test] = {}\n",
    "    \n",
    "    if test == 'all':\n",
    "        cols = df_orig.columns\n",
    "    elif test == 'cont':\n",
    "        cols = continuous_cols\n",
    "    elif test == 'cat':\n",
    "        cols = set(df_orig.columns) - set(continuous_cols)\n",
    "        \n",
    "    for s in stats_str:\n",
    "        res[test][s] = {}\n",
    "\n",
    "    for m in all_stats.keys():\n",
    "\n",
    "        for s in stats_str:\n",
    "            \n",
    "            tmp = []\n",
    "            for c in cols:\n",
    "                tmp.append(all_stats[m][c][s])\n",
    "            \n",
    "            res[test][s][m] = np.mean(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranking on all columns based on SRMSE:\n",
      "   1. random-original      - 8.04e-02\n",
      "   2. DATGAN               - 8.09e-02\n",
      "   3. CTGAN                - 2.21e-01\n",
      "   4. CTABGAN              - 2.69e-01\n",
      "\n",
      "Ranking on continuous columns based on SRMSE:\n",
      "   1. random-original      - 4.25e-02\n",
      "   2. DATGAN               - 1.25e-01\n",
      "   3. CTGAN                - 2.17e-01\n",
      "   4. CTABGAN              - 2.71e-01\n",
      "\n",
      "Ranking on categorical columns based on SRMSE:\n",
      "   1. DATGAN               - 3.97e-02\n",
      "   2. random-original      - 1.16e-01\n",
      "   3. CTGAN                - 2.25e-01\n",
      "   4. CTABGAN              - 2.67e-01\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for test in ['all', 'cont', 'cat']:\n",
    "    \n",
    "    if test == 'all':\n",
    "        str_ = 'on all columns'\n",
    "    elif test == 'cont':\n",
    "        str_ = 'on continuous columns'\n",
    "    elif test == 'cat':\n",
    "        str_ = 'on categorical columns'\n",
    "        \n",
    "    for s in ['srmse']:#stats_str:\n",
    "        print('Ranking {} based on {}:'.format(str_, s.upper()))\n",
    "\n",
    "        if s in ['r2', 'corr']:\n",
    "            sorted_dct = {k: v for k, v in sorted(res[test][s].items(), key=lambda item: item[1])[::-1]}\n",
    "        else:\n",
    "            sorted_dct = {k: v for k, v in sorted(res[test][s].items(), key=lambda item: item[1])}\n",
    "\n",
    "        for i, item in enumerate(sorted_dct):\n",
    "            print('  {:>2}. {:<20} - {:.2e}'.format(i+1, item, sorted_dct[item]))\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stats per couple columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 351 combinations!\n"
     ]
    }
   ],
   "source": [
    "combs = []\n",
    "\n",
    "for k in combinations(df_orig.columns, 2):\n",
    "    combs.append(k[0] + '::' + k[1])\n",
    "    \n",
    "print('There are {} combinations!'.format(len(combs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No previous results found, starting fresh\n"
     ]
    }
   ],
   "source": [
    "filepath = './notebooks/tests/stats/'\n",
    "filename = 'couple_columns.pickle'.format(dataset)\n",
    "\n",
    "all_stats = {}\n",
    "\n",
    "try:\n",
    "    all_stats = pickle.load(open(filepath + filename, 'rb'))\n",
    "    print('Found previous pickel file, using that')\n",
    "except:\n",
    "    print('No previous results found, starting fresh')\n",
    "    try:\n",
    "        os.makedirs(filepath)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing stats for model \u001b[1mCTABGAN\u001b[0m (1/3)\n",
      "Preparing stats for model \u001b[1mCTGAN\u001b[0m (2/3)\n",
      "Preparing stats for model \u001b[1mDATGAN\u001b[0m (3/3)\n",
      "\u001b[1mFINISHED!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Go through each model\n",
    "for i, m in enumerate(models):\n",
    "    \n",
    "    if m in all_stats:\n",
    "        print(\"Results for model \\033[1m{}\\033[0m ({}/{}) already exists!\".format(m, i+1, len(models)))\n",
    "\n",
    "    else:\n",
    "    \n",
    "        print(\"Preparing stats for model \\033[1m{}\\033[0m ({}/{})\".format(m, i+1, len(models)))\n",
    "\n",
    "        all_stats[m] = {}\n",
    "\n",
    "        # Load all dataframes for current model\n",
    "        df = pd.read_csv(files_[m])\n",
    "\n",
    "        # Discretize continuous columns\n",
    "        for c in continuous_cols:\n",
    "            df[c] = pd.cut(df[c], bins=bins_cont[c])\n",
    "\n",
    "        # Go through each columns\n",
    "        for c in combs:\n",
    "\n",
    "            agg_vars = c.split('::')\n",
    "\n",
    "            real = df_orig.copy()\n",
    "            real['count'] = 1\n",
    "            real = real.groupby(agg_vars, observed=True).count()\n",
    "            real /= len(df_orig)\n",
    "\n",
    "            synth = df.copy()\n",
    "            synth['count'] = 1\n",
    "            synth = synth.groupby(agg_vars, observed=True).count()\n",
    "            synth /= len(df)\n",
    "\n",
    "            real_and_sampled = pd.merge(real, synth, suffixes=['_real', '_sampled'], on=agg_vars, how='outer', indicator=True)\n",
    "            real_and_sampled = real_and_sampled[['count_real', 'count_sampled']].fillna(0)\n",
    "\n",
    "            sts = compute_stats(real_and_sampled['count_real'], real_and_sampled['count_sampled'])\n",
    "\n",
    "            all_stats[m][c] = sts\n",
    "            \n",
    "        pickle.dump(all_stats, open(filepath + filename, 'wb'))\n",
    "\n",
    "print(\"\\033[1mFINISHED!\\033[0m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_orig = {}\n",
    "\n",
    "train = df_orig.sample(int(len(df_orig) * 0.5))\n",
    "train.index = range(len(train))\n",
    "test = df_orig[~df_orig.index.isin(train.index)]\n",
    "test.index = range(len(test))\n",
    "\n",
    "# Go through each columns\n",
    "for c in combs:\n",
    "\n",
    "    agg_vars = c.split('::')\n",
    "\n",
    "    real = train.copy()\n",
    "    real['count'] = 1\n",
    "    real = real.groupby(agg_vars, observed=True).count()\n",
    "    real /= len(df_orig)\n",
    "\n",
    "    synth = test.copy()\n",
    "    synth['count'] = 1\n",
    "    synth = synth.groupby(agg_vars, observed=True).count()\n",
    "    synth /= len(df)\n",
    "\n",
    "    real_and_sampled = pd.merge(real, synth, suffixes=['_real', '_sampled'], on=agg_vars, how='outer', indicator=True)\n",
    "    real_and_sampled = real_and_sampled[['count_real', 'count_sampled']].fillna(0)\n",
    "\n",
    "    sts = compute_stats(real_and_sampled['count_real'], real_and_sampled['count_sampled'])\n",
    "    \n",
    "    stats_orig[c] = sts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stats[orig_str] = stats_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = {}\n",
    "\n",
    "for s in stats_str:\n",
    "    res[s] = {}\n",
    "                    \n",
    "for m in all_stats.keys():\n",
    "\n",
    "    for s in stats_str:\n",
    "\n",
    "        tmp = []\n",
    "        for c in combs:\n",
    "            tmp.append(all_stats[m][c][s])\n",
    "\n",
    "        res[s][m] = np.mean(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranking on all coupled combinations based on SRMSE:\n",
      "   1. random-original      - 1.98e-01\n",
      "   2. DATGAN               - 2.13e-01\n",
      "   3. CTGAN                - 5.28e-01\n",
      "   4. CTABGAN              - 6.37e-01\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for s in ['srmse']:#stats_str:\n",
    "    print('Ranking on all coupled combinations based on {}:'.format(s.upper()))\n",
    "\n",
    "    if s in ['r2', 'corr']:\n",
    "        sorted_dct = {k: v for k, v in sorted(res[s].items(), key=lambda item: item[1])[::-1]}\n",
    "    else:\n",
    "        sorted_dct = {k: v for k, v in sorted(res[s].items(), key=lambda item: item[1])}\n",
    "\n",
    "    for i, item in enumerate(sorted_dct):\n",
    "        print('  {:>2}. {:<20} - {:.2e}'.format(i+1, item, sorted_dct[item]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
